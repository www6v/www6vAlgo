<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Diffusion on LLM 算法</title>
    <link>https://www6v.github.io/www6vAlgo/categories/Diffusion/</link>
    <description>Recent content in Diffusion on LLM 算法</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Sun, 27 Aug 2023 10:21:28 +0000</lastBuildDate>
    <atom:link href="https://www6v.github.io/www6vAlgo/categories/Diffusion/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>(原理)unCLIP</title>
      <link>https://www6v.github.io/www6vAlgo/docs/Vision/Diffusion/gptDiffusionunCLIP/</link>
      <pubDate>Sun, 27 Aug 2023 10:21:28 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/Vision/Diffusion/gptDiffusionunCLIP/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;unclip&#34;&gt;&#xA;  unCLIP&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#unclip&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://candied-skunk-1ca.notion.site/unCLIP-7603f64564a54cb4af08a1cf38c890e1?pvs=4&#34;&gt;(原理)unCLIP&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>(原理|实战)T2I-Adapter</title>
      <link>https://www6v.github.io/www6vAlgo/docs/Vision/Controllable/gptDiffusionT2IAdapter/</link>
      <pubDate>Tue, 22 Aug 2023 18:26:35 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/Vision/Controllable/gptDiffusionT2IAdapter/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;论文t2i-adapter&#34;&gt;&#xA;  论文[T2I-Adapter]&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e8%ae%ba%e6%96%87t2i-adapter&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;论文地址&#xA;&lt;a href=&#34;https://arxiv.org/pdf/2302.08453&#34;&gt;T2I-Adapter&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;开源地址&#xA;&lt;a href=&#34;https://github.com/TencentARC/T2I-Adapter&#34;&gt;T2I-Adapter&lt;/a&gt; git&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;t2i-adapter&#34;&gt;&#xA;  &lt;strong&gt;T2I-Adapter[10]&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#t2i-adapter&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://hf.co/papers/2302.08453&#34;&gt;T2I-Adapter&lt;/a&gt; is a lightweight adapter for controlling and providing more accurate&#xA;structure guidance for text-to-image models. It works by learning an alignment between the internal knowledge of the&#xA;text-to-image model and an external control signal, such as edge detection or depth estimation.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://hf.co/papers/2302.08453&#34;&gt;T2I-Adapter&lt;/a&gt; 是一种&lt;strong&gt;轻量级&lt;/strong&gt;适配器，用于控制&lt;strong&gt;文本到图像&lt;/strong&gt;模型并提供更准确的&lt;strong&gt;结构指导&lt;/strong&gt;。它的工作原理是学习文本到图像模型的&lt;strong&gt;内部知识与外部控制信号&lt;/strong&gt;（如边缘检测或深度估计）之间的&lt;strong&gt;对齐&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;p&gt;The T2I-Adapter design is simple, the condition is passed to four feature extraction blocks and three downsample blocks. This makes it fast and easy to train different adapters for different conditions which can be plugged into the text-to-image model. T2I-Adapter is similar to &lt;a href=&#34;https://huggingface.co/docs/diffusers/main/en/using-diffusers/controlnet&#34;&gt;ControlNet&lt;/a&gt; except it is smaller (~77M parameters) and faster because it only runs once during the diffusion process. The downside is that performance may be slightly worse than ControlNet.&lt;/p&gt;</description>
    </item>
    <item>
      <title>(原理|实战)ControlNet</title>
      <link>https://www6v.github.io/www6vAlgo/docs/Vision/Controllable/gptDiffusionControlNet/</link>
      <pubDate>Tue, 22 Aug 2023 18:26:17 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/Vision/Controllable/gptDiffusionControlNet/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;论文controlnet&#34;&gt;&#xA;  论文[ControlNet]&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e8%ae%ba%e6%96%87controlnet&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;论文地址&#xA;&lt;a href=&#34;https://arxiv.org/abs/2302.05543&#34;&gt;Adding Conditional Control to Text-to-Image Diffusion Models&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;开源地址&#xA;&lt;a href=&#34;https://github.com/lllyasviel/ControlNet&#34;&gt;ControlNet&lt;/a&gt; git&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;controlnet10&#34;&gt;&#xA;  ControlNet[10]&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#controlnet10&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;ControlNet is a type of model for controlling image diffusion models by&#xA;conditioning the model with an additional input image. There are many&#xA;types of conditioning inputs (canny edge, user sketching, human pose,&#xA;depth, and more) you can use to control a diffusion model. This is&#xA;hugely useful because it affords you greater control over image&#xA;generation, making it easier to generate specific images without&#xA;experimenting with different text prompts or denoising values as much.&lt;/p&gt;</description>
    </item>
    <item>
      <title>(原理)Guidance</title>
      <link>https://www6v.github.io/www6vAlgo/docs/Vision/Diffusion/gptDiffusionGuidance/</link>
      <pubDate>Tue, 01 Aug 2023 19:19:40 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/Vision/Diffusion/gptDiffusionGuidance/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;guidance&#34;&gt;&#xA;  Guidance&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#guidance&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://candied-skunk-1ca.notion.site/Guidance-bcb0b5a85b5f454fa84875eaeb518983?pvs=4&#34;&gt;Guidance&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>(原理)SD XL</title>
      <link>https://www6v.github.io/www6vAlgo/docs/Vision/Diffusion/gptDiffusionXL/</link>
      <pubDate>Tue, 01 Aug 2023 19:12:57 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/Vision/Diffusion/gptDiffusionXL/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;sdxl&#34;&gt;&#xA;  SDXL&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#sdxl&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://candied-skunk-1ca.notion.site/SDXL-0446aba46c8e400d8583fde17d8df264?pvs=4&#34;&gt;SDXL&lt;/a&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
