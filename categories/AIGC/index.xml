<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AIGC on LLM 算法</title>
    <link>https://www6v.github.io/www6vAlgo/categories/AIGC/</link>
    <description>Recent content in AIGC on LLM 算法</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Mon, 22 Jul 2024 16:14:51 +0000</lastBuildDate>
    <atom:link href="https://www6v.github.io/www6vAlgo/categories/AIGC/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Search-R1</title>
      <link>https://www6v.github.io/www6vAlgo/docs/RL/Agentic-RL/Search/Search-R1/</link>
      <pubDate>Tue, 26 Mar 2024 12:13:50 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/RL/Agentic-RL/Search/Search-R1/</guid>
      <description>&lt;h1 id=&#34;论文&#34;&gt;&#xA;  论文&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e8%ae%ba%e6%96%87&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2503.09516v1&#34;&gt;Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/PeterGriffinJin/Search-R1&#34;&gt;https://github.com/PeterGriffinJin/Search-R1&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;methods&#34;&gt;&#xA;  &lt;strong&gt;Methods&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#methods&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;strong&gt;详细方法和步骤:&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;./images/s-r1.png&#34; alt=&#34;s-r1.png&#34; /&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;将搜索引擎建模为环境的一部分：&lt;/strong&gt; SEARCH-R1将搜索引起作为环境的一部分， 让模型与环境交互，从而得到 reward。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;img src=&#34;./images/s-r1-1.png&#34; alt=&#34;s-r1-1.png&#34; /&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;支持多轮检索和推理：&lt;/strong&gt; SEARCH-R1通过特定的标签（&lt;code&gt;&amp;lt;search&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;lt;/search&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;lt;information&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;lt;/information&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;lt;think&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;lt;/think&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;lt;answer&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;lt;/answer&amp;gt;&lt;/code&gt;）来支持多轮检索和推理。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;img src=&#34;./images/l6gmzlwi.png&#34; alt=&#34;l6gmzlwi.png&#34; /&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;优化算法兼容性：&lt;/strong&gt; SEARCH-R1 与各种 RL 算法兼容，包括 PPO 和 GRPO。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;简单结果奖励函数：&lt;/strong&gt; 避免复杂的基于过程的奖励, 采用简单的基于结果的奖励函数 &lt;strong&gt;（字符串匹配作为reward!!!）。&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;img src=&#34;./images/g0ew6gx4.png&#34; alt=&#34;g0ew6gx4.png&#34; /&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;总结&#34;&gt;&#xA;  &lt;strong&gt;总结&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e6%80%bb%e7%bb%93&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;strong&gt;结论1: SEARCH-R1 显著提升了LLM在需要实时外部知识的复杂推理任务中的能力。&lt;/strong&gt; 通过强化学习，LLM可以自主生成查询并有效利用检索到的信息，优于传统的RAG方法。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;结论2: SEARCH-R1在不同LLM架构和训练方法上具有广泛的适用性。&lt;/strong&gt; 实验结果表明，无论使用基础模型还是指令调整模型，SEARCH-R1都能带来显著的性能提升，且对不同的RL算法（如PPO和GRPO）具有兼容性。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;结论3: SEARCH-R1有很强的实用价值。&lt;/strong&gt; SEARCH-R1能够显著提高LLM在需要实时外部知识的复杂推理任务中的能力。 可以用于智能问答，智能助手等领域。&lt;/p&gt;&#xA;&lt;h1 id=&#34;参考&#34;&gt;&#xA;  参考&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e5%8f%82%e8%80%83&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/rPza0-KB4Rpc_vXyYa8xSw&#34;&gt;Search-R1：让大模型学会“检索+推理”的新范式&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;1xx. &lt;a href=&#34;https://zhuanlan.zhihu.com/p/30784344002&#34;&gt;【论文解读】Search-R1：强化学习如何教会 LLM 自主搜索？&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>(实战)GRPO</title>
      <link>https://www6v.github.io/www6vAlgo/docs/RL/core/GRPODeepseek/</link>
      <pubDate>Wed, 28 Feb 2024 01:29:48 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/RL/core/GRPODeepseek/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;grpo&#34;&gt;&#xA;  GRPO&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#grpo&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://candied-skunk-1ca.notion.site/GRPO-1a7bfe211084808086d9df62f186af6d?pvs=4&#34;&gt;(实战)GRPO&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>(原理)学习率</title>
      <link>https://www6v.github.io/www6vAlgo/docs/DeepLearning/%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96/DeeplearningLearningRate/</link>
      <pubDate>Mon, 08 Jan 2024 19:28:50 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/DeepLearning/%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96/DeeplearningLearningRate/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;学习率&#34;&gt;&#xA;  学习率&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e5%ad%a6%e4%b9%a0%e7%8e%87&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://candied-skunk-1ca.notion.site/172bfe211084806f8de8cdd5a9b249ad?pvs=4&#34;&gt;(原理)学习率&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>(原理&amp;实战)权重衰减</title>
      <link>https://www6v.github.io/www6vAlgo/docs/DeepLearning/%E6%AD%A3%E5%88%99%E5%8C%96/WeightDecay/</link>
      <pubDate>Mon, 08 Jan 2024 19:13:59 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/DeepLearning/%E6%AD%A3%E5%88%99%E5%8C%96/WeightDecay/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;权重衰减-weightdecay&#34;&gt;&#xA;  权重衰减 WeightDecay&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e6%9d%83%e9%87%8d%e8%a1%b0%e5%87%8f-weightdecay&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://candied-skunk-1ca.notion.site/16fbfe21108480ea8682d89d64f5b00c?pvs=4&#34;&gt;(原理&amp;amp;实战)权重衰减&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>机器学习-数据</title>
      <link>https://www6v.github.io/www6vAlgo/docs/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/MLData/</link>
      <pubDate>Tue, 21 Nov 2023 22:44:57 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/MLData/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;机器学习-数据&#34;&gt;&#xA;  机器学习-数据&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0-%e6%95%b0%e6%8d%ae&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://candied-skunk-1ca.notion.site/ML-216bfe2110848076a892e11e7144828c?source=copy_link&#34;&gt;机器学习-数据&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>(原理)Transformer</title>
      <link>https://www6v.github.io/www6vAlgo/docs/DeepLearning/Transformer/Transformer/</link>
      <pubDate>Wed, 30 Nov 2022 16:44:11 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/DeepLearning/Transformer/Transformer/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xD;&#xA;&lt;!-- more --&gt;&#xD;&#xA;&lt;h1 id=&#34;原理transformer&#34;&gt;&#xA;  (原理)Transformer&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e5%8e%9f%e7%90%86transformer&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://candied-skunk-1ca.notion.site/Transformer-b1b9836f9c244db3acda7869f64ff860?pvs=4&#34;&gt;(原理)Transformer&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Deep Learning</title>
      <link>https://www6v.github.io/www6vAlgo/docs/DeepLearning/basic/DeepLearning/</link>
      <pubDate>Sat, 11 Jun 2022 15:57:10 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/DeepLearning/basic/DeepLearning/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xD;&#xA;&lt;!-- more --&gt;&#xD;&#xA;&lt;h1 id=&#34;deep-learning&#34;&gt;&#xA;  Deep Learning&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#deep-learning&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://candied-skunk-1ca.notion.site/Deep-Learning-10dbfe21108480b9affbf52a3b5bb13e?pvs=4&#34;&gt;Deep Learning&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>(原理)PPO</title>
      <link>https://www6v.github.io/www6vAlgo/docs/RL/core/PPO/</link>
      <pubDate>Sat, 01 Jun 2024 22:12:32 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/RL/core/PPO/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;ppo&#34;&gt;&#xA;  PPO&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#ppo&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://candied-skunk-1ca.notion.site/PPO-204bfe21108480b2aba0ce27d7d5e761?pvs=4&#34;&gt;(原理)PPO&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>(原理)Batchsize</title>
      <link>https://www6v.github.io/www6vAlgo/docs/DeepLearning/%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96/DeeplearningBatchsize/</link>
      <pubDate>Wed, 17 Jan 2024 18:45:59 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/DeepLearning/%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96/DeeplearningBatchsize/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;最佳实践&#34;&gt;&#xA;  最佳实践&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e6%9c%80%e4%bd%b3%e5%ae%9e%e8%b7%b5&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h3 id=&#34;batchsize&#34;&gt;&#xA;  batchsize&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#batchsize&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;batchsize  下限 [1]&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;别太小的限制在于，&lt;strong&gt;batch size太小，会来不及收敛。&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;所以在常见的setting（～100 epochs），batch size一般不会低于16。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;batchsize 上限   [1]&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;batch size别太大的限制在于两个点，&lt;/p&gt;&#xA;&lt;p&gt;1）batch size太大，memory容易不够用。这个很显然，就不多说了。&lt;/p&gt;&#xA;&lt;p&gt;2）&lt;strong&gt;batch size太大，深度学习的优化（training loss降不下去）和泛化（generalization gap很大）都会出问题。&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;learning-rate--batch-size&#34;&gt;&#xA;  &lt;strong&gt;learning rate &amp;amp; batch size&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#learning-rate--batch-size&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;总之，可以证明，&lt;strong&gt;learning rate/batch size的比值对深度学习是有指数级的影响&lt;/strong&gt;[3]，所以非常重要，没事别瞎调。[1]&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;这也是为什么大的batch_size往往建议可以相应取大点&lt;a href=&#34;https://zhida.zhihu.com/search?content_id=462989051&amp;amp;content_type=Answer&amp;amp;match_order=1&amp;amp;q=learning_rate&amp;amp;zhida_source=entity&#34;&gt;learning_rate&lt;/a&gt;, 因为梯度震荡小，大&lt;/strong&gt;learning_rate&lt;strong&gt;可以加速收敛过程，也可以防止陷入到局部最小值，而小batch_size用小learning_rate迭代，防止错过最优点，一直上下震荡没法收敛（这也是一个小trick）&lt;/strong&gt;。[2]&lt;/p&gt;&#xA;&lt;h1 id=&#34;参考&#34;&gt;&#xA;  参考&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e5%8f%82%e8%80%83&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/61607442/answer/1875700191&#34;&gt;怎么选取训练神经网络时的Batch size?&lt;/a&gt;  Summer Clover&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/456600260/answer/2380983385&#34;&gt;训练神经网络时batchsize扩大一倍的同时需要增加epoch数量吗?&lt;/a&gt; 新一&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.notion.so/7-1-174bfe21108480a7a702e4ebed99f68f?pvs=21&#34;&gt;7.1 批大小调整实验&lt;/a&gt; 百度邱&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://aistudio.baidu.com/education/lessonvideo/3048883&#34;&gt;7.1 批大小调整实验&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/148267858&#34;&gt;设置BatchSize&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.zhihu.com/question/32673260/answer/3356342576&#34;&gt;深度学习中的batch的大小对学习效果有何影响？&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>(原理&amp;实战)前向/反向传播</title>
      <link>https://www6v.github.io/www6vAlgo/docs/DeepLearning/basic/DeeplearningForwardBackward/</link>
      <pubDate>Tue, 09 Jan 2024 12:22:12 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/DeepLearning/basic/DeeplearningForwardBackward/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;前向反向传播&#34;&gt;&#xA;  前向/反向传播&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e5%89%8d%e5%90%91%e5%8f%8d%e5%90%91%e4%bc%a0%e6%92%ad&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://candied-skunk-1ca.notion.site/164bfe211084800d80dbe868719ce79a?pvs=4&#34;&gt;(原理&amp;amp;实战)前向/反向传播&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>(原理&amp;实战)Dropout</title>
      <link>https://www6v.github.io/www6vAlgo/docs/DeepLearning/%E6%AD%A3%E5%88%99%E5%8C%96/Dropout/</link>
      <pubDate>Mon, 08 Jan 2024 19:19:59 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/DeepLearning/%E6%AD%A3%E5%88%99%E5%8C%96/Dropout/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;dropout&#34;&gt;&#xA;  Dropout&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#dropout&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://candied-skunk-1ca.notion.site/Dropout-16fbfe21108480259446f7c7feb39aca?pvs=4&#34;&gt;(原理&amp;amp;实战)Dropout&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>机器学习-模型</title>
      <link>https://www6v.github.io/www6vAlgo/docs/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/MLModel/</link>
      <pubDate>Tue, 21 Nov 2023 22:44:57 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/MLModel/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;机器学习-模型&#34;&gt;&#xA;  机器学习-模型&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0-%e6%a8%a1%e5%9e%8b&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://candied-skunk-1ca.notion.site/216bfe21108480868a4cf3a485dd48e6?source=copy_link&#34;&gt;机器学习-模型&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>(原理)Self-Attention</title>
      <link>https://www6v.github.io/www6vAlgo/docs/DeepLearning/Transformer/SelfAttention/</link>
      <pubDate>Sun, 19 Nov 2023 14:19:46 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/DeepLearning/Transformer/SelfAttention/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;self-attention&#34;&gt;&#xA;  Self-Attention&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#self-attention&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://candied-skunk-1ca.notion.site/Self-Attention-142bfe21108480f6a0c0cdbf9262a7e3?pvs=4&#34;&gt;(原理)Self-Attention&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>(原理|实现)PPO-RewardModel</title>
      <link>https://www6v.github.io/www6vAlgo/docs/RL/core/RewardModel/</link>
      <pubDate>Sat, 01 Jun 2024 22:12:51 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/RL/core/RewardModel/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;ppo-rewardmodel&#34;&gt;&#xA;  PPO-RewardModel&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#ppo-rewardmodel&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://candied-skunk-1ca.notion.site/PPO-RM-205bfe21108480a39b78d82696d1ede4?pvs=4&#34;&gt;(原理|实现)PPO-RewardModel&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>(原理&amp;实战)交叉熵损失</title>
      <link>https://www6v.github.io/www6vAlgo/docs/DeepLearning/basic/DeeplearningLoss/</link>
      <pubDate>Fri, 12 Jan 2024 19:06:59 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/DeepLearning/basic/DeeplearningLoss/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;交叉熵损失&#34;&gt;&#xA;  交叉熵损失&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e4%ba%a4%e5%8f%89%e7%86%b5%e6%8d%9f%e5%a4%b1&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://candied-skunk-1ca.notion.site/176bfe21108480e19198ec69bf135e38?pvs=4&#34;&gt;(原理&amp;amp;实战)交叉熵损失&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>规范化 Norm</title>
      <link>https://www6v.github.io/www6vAlgo/docs/DeepLearning/%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96/DeeplearningNorm/</link>
      <pubDate>Mon, 08 Jan 2024 19:40:39 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/DeepLearning/%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96/DeeplearningNorm/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;norm-作用1&#34;&gt;&#xA;  Norm 作用[1]&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#norm-%e4%bd%9c%e7%94%a81&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;dnn 的标准组件，稳定和加速训练过程&lt;/p&gt;&#xA;&lt;h1 id=&#34;batch-norm1&#34;&gt;&#xA;  Batch Norm[1]&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#batch-norm1&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;reduce cross &lt;strong&gt;batch size&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;mini-batch dimension&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;一般用于图像，不涉及到padding的问题；&lt;/p&gt;&#xA;&lt;h1 id=&#34;layer-norm1&#34;&gt;&#xA;  Layer Norm[1]&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#layer-norm1&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;reduce cross &lt;strong&gt;hidden dim&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;reduce across the &lt;strong&gt;feature dimension&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;一般用于序列，一个 batch size 内存在 padding；&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;RMSNorm: 对 LN 的一种变体，llama&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;aside&gt; 💡&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://spaces.ac.cn/archives/9009&#34;&gt;https://spaces.ac.cn/archives/9009&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Pre LN: &lt;code&gt;llama&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;Post LN: &lt;code&gt;attention is all you need&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;llama在工程上使用Pre LN&lt;/p&gt;&#xA;&lt;/aside&gt;&#xA;&lt;hr&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;[&lt;a href=&#34;https://www.bilibili.com/video/BV13q49eaERj/&#34;&gt;pytorch] BN、LN、RMSNorm 及 pre LN vs. post LN 对比，标准化&lt;/a&gt;  v ***&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;​&#x9;&lt;a href=&#34;https://github.com/chunhuizhang/llm_aigc/blob/main/tutorials/nn_basics/tricks_norms/normalization.ipynb&#34;&gt;normalization.ipynb&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;​&#x9;[&lt;a href=&#34;https://www.notion.so/pytorch-BN-LN-RMSNorm-pre-LN-vs-post-LN-177bfe2110848088830cfea3d5a33d3e?pvs=21&#34;&gt;pytorch] BN、LN、RMSNorm 及 pre LN vs. post LN 对比，标准化 &lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>(原理)GQA</title>
      <link>https://www6v.github.io/www6vAlgo/docs/DeepLearning/Transformer/ModelGQA/</link>
      <pubDate>Sun, 19 Nov 2023 14:29:40 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/DeepLearning/Transformer/ModelGQA/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;论文&#34;&gt;&#xA;  论文&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e8%ae%ba%e6%96%87&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2305.13245&#34;&gt;GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;mha-vs-mqa-vs-gqa-1&#34;&gt;&#xA;  &lt;strong&gt;MHA vs. MQA vs.&lt;/strong&gt; GQA [1]&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#mha-vs-mqa-vs-gqa-1&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h3 id=&#34;mha&#34;&gt;&#xA;  &lt;strong&gt;MHA&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#mha&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;首先是原始的 &lt;strong&gt;MHA(Multi-Head Attention)&lt;/strong&gt;，QKV 三部分有相同数量的头，且一一对应。每次做 Attention，head1 的 QKV 就做好自己运算就可以，输出时各个头加起来就行。&lt;/p&gt;&#xA;&lt;h3 id=&#34;mqa&#34;&gt;&#xA;  &lt;strong&gt;MQA&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#mqa&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;而 &lt;strong&gt;MQA&lt;/strong&gt; 则是，让 &lt;strong&gt;Q 仍然保持原来的头数&lt;/strong&gt;，但 &lt;strong&gt;K 和 V 只有一个头&lt;/strong&gt;，相当于所有的 Q 头共享一组 K 和 V 头，所以叫做 Multi-Query 了。实现改变了会不会影响效果呢？确实会影响但相对它能带来的收益，性能的些微降低是可以接受的。&lt;/p&gt;&#xA;&lt;p&gt;能带来多大的收益呢，实验发现一般能提高 30%-40% 的吞吐。&lt;/p&gt;&#xA;&lt;p&gt;收益主要就是由降低了 KV cache 带来的。实际上 MQA 运算量和 MHA 是差不多的，可理解为&lt;strong&gt;读取一组 KV 头&lt;/strong&gt;之后，&lt;strong&gt;给所有 Q 头用&lt;/strong&gt;，但因为之前提到的内存和计算的不对称，所以是有利的。&lt;/p&gt;&#xA;&lt;h3 id=&#34;gqa&#34;&gt;&#xA;  GQA&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#gqa&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;而 &lt;strong&gt;GQA&lt;/strong&gt; 呢，是 MHA 和 MQA 的折衷方案，既不想损失性能太多，又想获得 MQA 带来的推理加速好处。具体思想是，不是所有 Q 头共享一组 KV，而是&lt;strong&gt;分组一定头数 Q 共享一组 KV&lt;/strong&gt;，比如上面图片就是两组 Q 共享一组 KV。&lt;/p&gt;</description>
    </item>
    <item>
      <title>(原理)梯度优化</title>
      <link>https://www6v.github.io/www6vAlgo/docs/DeepLearning/%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96/DeeplearningGradOpt/</link>
      <pubDate>Thu, 04 Apr 2024 17:28:27 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/DeepLearning/%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96/DeeplearningGradOpt/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;梯度优化&#34;&gt;&#xA;  梯度优化&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e6%a2%af%e5%ba%a6%e4%bc%98%e5%8c%96&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h1 id=&#34;gradient-accumulation&#34;&gt;&#xA;  &lt;strong&gt;Gradient accumulation&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#gradient-accumulation&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;img src=&#34;./images/maonmv7e.bmp&#34; alt=&#34;maonmv7e.bmp&#34; /&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;gradient-checkpointing-10&#34;&gt;&#xA;  &lt;strong&gt;G&lt;/strong&gt;radient checkpointing [10]&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#gradient-checkpointing-10&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;显存占用优化算法&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;memory usage 与 computation time 之间的 tradeoff ；&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;gradient checkpointing&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;In deep neural networks, backpropagation requires storing &lt;strong&gt;intermediate activations&lt;/strong&gt; for computing gradients during the backward pass.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;但是当层数变多时，存储所有的中间层的激活值（intermediate activations）非常地占用显存；&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;gradient checkpointing&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;选择性地重新计算（recompute）一部分的 intermediate activations 在反向传播过程中&lt;/strong&gt;来缓解显存的压力；&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;gradient-clipping--梯度裁剪&#34;&gt;&#xA;  &lt;strong&gt;Gradient Clipping  (梯度裁剪)&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#gradient-clipping--%e6%a2%af%e5%ba%a6%e8%a3%81%e5%89%aa&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h3 id=&#34;目的21&#34;&gt;&#xA;  目的[21]&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e7%9b%ae%e7%9a%8421&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;梯度爆炸问题的常见应对方式为“梯度裁剪”&lt;/strong&gt;，也就是通过“clip”方式来防止迭代中梯度值过大。&lt;/p&gt;&#xA;&lt;h3 id=&#34;两种常见形式20&#34;&gt;&#xA;  两种常见形式[20]&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e4%b8%a4%e7%a7%8d%e5%b8%b8%e8%a7%81%e5%bd%a2%e5%bc%8f20&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;梯度范数裁剪（Gradient Norm Clipping）: 这种方法涉及计算所有参数梯度的范数（例如L2范数），如果这个范数超过了设定的阈值，就将梯度缩放到这个阈值以内。在PyTorch中，这可以通过 &lt;strong&gt;torch.nn.utils.clip_grad_norm_&lt;/strong&gt; 函数实现。&lt;/li&gt;&#xA;&lt;li&gt;梯度值裁剪（Gradient Value Clipping）: 这种方法对每个参数的梯度值进行独立裁剪，确保它们不会超过一个设定的最大值或最小值。在PyTorch中，这可以通过 &lt;strong&gt;torch.nn.utils.clip_grad_value_&lt;/strong&gt; 函数实现。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;参考&#34;&gt;&#xA;  参考&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e5%8f%82%e8%80%83&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h3 id=&#34;overview&#34;&gt;&#xA;  overview&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#overview&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/v4.18.0/en/performance&#34;&gt;Performance and Scalability: How To Fit a Bigger Model and Train It Faster&lt;/a&gt;  ***&lt;/p&gt;</description>
    </item>
    <item>
      <title>(原理)过拟合</title>
      <link>https://www6v.github.io/www6vAlgo/docs/DeepLearning/basic/DeeplearningOverfitting/</link>
      <pubDate>Mon, 08 Jan 2024 19:40:39 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/DeepLearning/basic/DeeplearningOverfitting/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;原理过拟合&#34;&gt;&#xA;  (原理)过拟合&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e5%8e%9f%e7%90%86%e8%bf%87%e6%8b%9f%e5%90%88&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://candied-skunk-1ca.notion.site/1e1bfe2110848025a7b2ffba454daa86?source=copy_link&#34;&gt;(原理)过拟合&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>(实战)Transformer</title>
      <link>https://www6v.github.io/www6vAlgo/docs/DeepLearning/Transformer/TransformerCode/</link>
      <pubDate>Thu, 16 Feb 2023 13:57:57 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/DeepLearning/Transformer/TransformerCode/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;参考&#34;&gt;&#xA;  参考&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e5%8f%82%e8%80%83&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;1xx. &lt;a href=&#34;https://github.com/www6v/AIGC/blob/master/transformer/transformer.ipynb&#34;&gt;transformer.ipynb&lt;/a&gt; git&#xA;&lt;a href=&#34;https://www.bilibili.com/video/BV1nc411y7m4/&#34;&gt;Transformer代码实现&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;1xx. &lt;a href=&#34;https://paperswithcode.com/method/transformer&#34;&gt;Transformer&lt;/a&gt;&#xA;&lt;a href=&#34;https://github.com/tunz/transformer-pytorch/blob/e7266679f0b32fd99135ea617213f986ceede056/model/transformer.py#L201&#34;&gt;transformer.py&lt;/a&gt; git&lt;/p&gt;&#xA;&lt;p&gt;1xx. &lt;a href=&#34;http://arthurchiao.art/blog/transformers-from-scratch-zh/&#34;&gt;[译] Transformer 是如何工作的：600 行 Python 代码实现 self-attention 和两类 Transformer（2019）&lt;/a&gt; V, github&#xA;Transformers from scratch&lt;/p&gt;&#xA;&lt;p&gt;1xx. &lt;a href=&#34;https://blog.csdn.net/v_JULY_v/article/details/130090649&#34;&gt;从零实现Transformer的简易版与强大版：从300多行到3000多行&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;1xx. &lt;a href=&#34;https://zhuanlan.zhihu.com/p/398039366&#34;&gt;Transformer源码详解（Pytorch版本）&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>(原理&amp;实战)veRL Config</title>
      <link>https://www6v.github.io/www6vAlgo/docs/RL/framework/veRLConfig/</link>
      <pubDate>Mon, 22 Jul 2024 16:14:51 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/RL/framework/veRLConfig/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;verl-config&#34;&gt;&#xA;  veRL Config&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#verl-config&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://candied-skunk-1ca.notion.site/veRL-Config-238bfe21108480b48225d75aec0990b2?source=copy_link&#34;&gt;(原理&amp;amp;实战)veRL Config&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Tokenizer</title>
      <link>https://www6v.github.io/www6vAlgo/docs/DeepLearning/Transformer/TrainTokenizer/</link>
      <pubDate>Sun, 26 Feb 2023 17:28:01 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/DeepLearning/Transformer/TrainTokenizer/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h3 id=&#34;tokenizer-分词&#34;&gt;&#xA;  tokenizer 分词&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#tokenizer-%e5%88%86%e8%af%8d&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;单词分词法&lt;/li&gt;&#xA;&lt;li&gt;单字分词法&lt;/li&gt;&#xA;&lt;li&gt;子词分词法&#xA;BPE [GPT系列], WordPiece&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;参考&#34;&gt;&#xA;  参考&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e5%8f%82%e8%80%83&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;1xx. &lt;a href=&#34;https://zhuanlan.zhihu.com/p/630696264&#34;&gt;大模型词表扩充必备工具SentencePiece&lt;/a&gt;&#xA;1xx. &lt;a href=&#34;https://zhuanlan.zhihu.com/p/458452872&#34;&gt;NLP（二）：浅谈分词&lt;/a&gt;&#xA;1xx. &lt;a href=&#34;https://www.bilibili.com/video/BV1vN411p7t2/&#34;&gt;https://www.bilibili.com/video/BV1vN411p7t2/&lt;/a&gt;&#xA;1xx. &lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=MzAxMjc3MjkyMg==&amp;amp;mid=2648400849&amp;amp;idx=1&amp;amp;sn=58006756cccde4d06d273df59e2c8dd8&#34;&gt;开源大模型如何更好地适应中文场景：LLAMA扩充词表、BLOOM裁剪词表基本原理与开源实现&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>(实战)PyTorch</title>
      <link>https://www6v.github.io/www6vAlgo/docs/DeepLearning/basic/Pytorch/</link>
      <pubDate>Tue, 28 Mar 2023 15:47:08 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/DeepLearning/basic/Pytorch/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;pytorch-实战&#34;&gt;&#xA;  PyTorch 实战&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#pytorch-%e5%ae%9e%e6%88%98&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://candied-skunk-1ca.notion.site/PyTorch-bae29b5883fd45f7a20c97918382da12?pvs=4&#34;&gt;(实战)PyTorch&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Survey) Test-Time Scaling</title>
      <link>https://www6v.github.io/www6vAlgo/docs/LLM/Reasoning/Survey/ReasoningTTS/</link>
      <pubDate>Sun, 21 Jul 2024 12:39:48 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/LLM/Reasoning/Survey/ReasoningTTS/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;test-time-scaling&#34;&gt;&#xA;  Test-Time Scaling&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#test-time-scaling&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://candied-skunk-1ca.notion.site/A-Survey-on-Test-Time-Scaling-in-Large-Language-Models-What-How-Where-and-How-Well-227bfe21108480ff95e4c0c105c3c74b?source=copy_link&#34;&gt;(Survey) Test-Time Scaling&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Survey)Reasoning LLM Post-Training</title>
      <link>https://www6v.github.io/www6vAlgo/docs/LLM/Reasoning/Survey/ReasoningPostTraining/</link>
      <pubDate>Thu, 04 Apr 2024 22:33:18 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/LLM/Reasoning/Survey/ReasoningPostTraining/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;reasoning-llm-post-training&#34;&gt;&#xA;  Reasoning LLM Post-Training&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#reasoning-llm-post-training&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;iframe src=&#34;https://candied-skunk-1ca.notion.site/ebd/1bbbfe21108480859284e9e8f686fc4a&#34; width=&#34;100%&#34; height=&#34;1000&#34; frameborder=&#34;0&#34; allowfullscreen /&gt;</description>
    </item>
    <item>
      <title>(原理)GRPO</title>
      <link>https://www6v.github.io/www6vAlgo/docs/LLM/Reasoning/R1-zero/ReasoningGRPO/</link>
      <pubDate>Thu, 04 Apr 2024 22:03:52 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/LLM/Reasoning/R1-zero/ReasoningGRPO/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;grpo&#34;&gt;&#xA;  GRPO&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#grpo&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;iframe src=&#34;https://candied-skunk-1ca.notion.site/ebd/194bfe21108480129939e44fd7ddacfd&#34; width=&#34;100%&#34; height=&#34;1000&#34; frameborder=&#34;0&#34; allowfullscreen /&gt;</description>
    </item>
    <item>
      <title>(实战)Deepseek 蒸馏</title>
      <link>https://www6v.github.io/www6vAlgo/docs/LLM/Reasoning/R1/DeepseekDistill/</link>
      <pubDate>Sun, 25 Feb 2024 18:46:57 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/LLM/Reasoning/R1/DeepseekDistill/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://candied-skunk-1ca.notion.site/R1-1a5bfe211084809eb615f84dc74f4bb6?pvs=4&#34;&gt;(实战)Deepseek 蒸馏&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>(实战)Deepseek R1 SFT</title>
      <link>https://www6v.github.io/www6vAlgo/docs/LLM/Reasoning/R1/DeepseekSFT/</link>
      <pubDate>Fri, 23 Feb 2024 17:29:20 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/LLM/Reasoning/R1/DeepseekSFT/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;deepseek-r1-sft&#34;&gt;&#xA;  DeepSeek R1 SFT&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#deepseek-r1-sft&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://candied-skunk-1ca.notion.site/DeepSeek-R1-SFT-1a3bfe21108480c39346d30d7f189550?pvs=4&#34;&gt;(实战)DeepSeek R1 SFT&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>解读 DeepSeek[邱锡鹏]</title>
      <link>https://www6v.github.io/www6vAlgo/docs/LLM/Reasoning/R1/DeepSeekExplain2/</link>
      <pubDate>Sun, 18 Feb 2024 09:16:31 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/LLM/Reasoning/R1/DeepSeekExplain2/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;p&gt;{% asset_img  &amp;lsquo;ubqella3.bmp&amp;rsquo; %}&lt;/p&gt;&#xA;&lt;p&gt;{% asset_img  &amp;lsquo;gelov7re.bmp&amp;rsquo; %}&lt;/p&gt;&#xA;&lt;p&gt;{% asset_img  &amp;lsquo;Deepseek-R1实现过程.png&amp;rsquo; %}&lt;/p&gt;&#xA;&lt;p&gt;这基本上就是R1的技术路线。我简单列一些&lt;strong&gt;关于DeepSeek R1的思考和启发&lt;/strong&gt;：&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;1、R1/R1-zero的技术路线和社区对o1复现的差异&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;此前社区对o1的复现基本都会涉及到蒸馏和搜索。&lt;/li&gt;&#xA;&lt;li&gt;R1-Zero没有SFT，没有过程监督，没有搜索，也能训练出类似o1的效果。学术界之前也有很多实验，但在较小的模型上都没有成功。说明只有基模型足够强，Scaling RL才能取得比较好的效果。&lt;/li&gt;&#xA;&lt;li&gt;虽然R1强调MCTS没有效果，但是简单的majority vote能大幅提升R1的效果，说明搜索仍然是重要的Scale的范式。&lt;/li&gt;&#xA;&lt;li&gt;R1的成功还依赖DeepSeek强大的系统效率和RL调教能力。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;2、策略初始化&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;R1-zero是一个比较好的尝试，但是R1还是经过了先SFT（大概几干条）后再进行RL。&lt;/li&gt;&#xA;&lt;li&gt;未来后训练的重心会逐步倾向于RL，但是少量训练用于SFT可能还是必须的。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;3、奖励模型&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;R1的奖励设计跟普通的后训练没特别大的区别（Qwen2，Tulu3），有ground truth用ground truth做EM，否则用RM。&lt;/li&gt;&#xA;&lt;li&gt;RM的（训练数据量，模型大小，OOD问题，选代周期）的相关问题在整个训练的流程中还是比较关键。可能使用当前开源的比较强大的RM可以达到比较好的效果，也有可能基于内部的数据重新进行了偏好标注。&lt;/li&gt;&#xA;&lt;li&gt;奖励设计（例如RPM的技巧）可能会在基于少量样本的强化学习微调上仍然起到显著作用。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;4、PRM和MCIS&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;DS给了两个PRM和MCTS的“不成功尝试”。但PRM部分说的比较笼统，并且DS的PRM只评估Correctness（与OAI的Lets verify step by step一致）。&lt;/li&gt;&#xA;&lt;li&gt;R1给的是一个简单而且可规模化的可行解，这样做不一定是最优的。基于R1的Test-time search也继续优化它的效果。&lt;/li&gt;&#xA;&lt;li&gt;PRM总归是一种比较稠密的监督信号，按照传统R1的理论，对OR进行shaping可以使训练更稳定或收敛得更快。&lt;/li&gt;&#xA;&lt;li&gt;PRM不应该是一个被完全放弃的东西，可以让模型收敛得更快速或更稳定（Scaling曲线的斜率更大）。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;5、写作能力提升&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;o1相比4o在写作等任务上的提升非常小，但R1的创作经常会令人眼前一亮，可能主要是强基模型在Scale RL后涌现的能力，也有人猜测是因为R1的安全对齐做的比较少，没有太约束模型的创作能力。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;6、过度优化问题&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;R1经常会使用一些高端词汇，典型的如量子纠缠和熵增熵减（会用在各个领域）。猜测是某种形式的reward hacking导致的。&lt;/li&gt;&#xA;&lt;li&gt;R1在一些通用领域没有ground truth的任务上的推理效果还并不理想，强化学习的训练并不能保证泛化。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;7、Test-Time Scaling&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;o1出来后大家讨论比较多的是Test-Time Scaling，但重要的还是Training-Time Scaling，包括数据和Training&#xA;Step。蒸馏见效快，但上限不高，重要的还是高质量致据的缺失，蒸馏数据无法提供训练Scaling。RL是其中的关键，因为它可以保障有足够的数据和足够的训练步骤。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;8、Agentic展望&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;R1是目前&lt;strong&gt;唯一同时具有强推理能力和联网搜索的产品&lt;/strong&gt;，效果很好，可以调研一些复杂的信息并进行回答。&lt;strong&gt;强推理模型最终的落脚点大概率是Agent&lt;/strong&gt;，怎么用强推理模型帮助Agent更好更鲁棒是一个比较重要的问题。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;参考&#34;&gt;&#xA;  参考&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e5%8f%82%e8%80%83&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/LsMOIgQinPZBnsga0imcvA&#34;&gt;DeepSeek最强专业拆解来了，清交复教授超硬核解读&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>解读 DeepSeek[刘知远]</title>
      <link>https://www6v.github.io/www6vAlgo/docs/LLM/Reasoning/R1/DeepSeekExplain1/</link>
      <pubDate>Sun, 18 Feb 2024 09:16:22 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/LLM/Reasoning/R1/DeepSeekExplain1/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;p&gt;{% asset_img  &amp;lsquo;1ffwdizy.bmp&amp;rsquo; %}&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/AdTUawqCe3vQhwJM50lvfQ?poc_token=HNe_qmejZWeCnYf7RHdgbu8e8ckbXP2i1uyxxI4O&#34;&gt;硬核解读 DeepSeek：大模型强化学习技术原理与大模型技术发展研判&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>(原理)Reasoning LLM</title>
      <link>https://www6v.github.io/www6vAlgo/docs/LLM/Reasoning/R1/ReasoningLLM/</link>
      <pubDate>Sun, 18 Feb 2024 09:01:44 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/LLM/Reasoning/R1/ReasoningLLM/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;reasoning-llm&#34;&gt;&#xA;  Reasoning LLM&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#reasoning-llm&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://candied-skunk-1ca.notion.site/Visual-Guide-to-Reasoning-LLMs-Exploring-Test-Time-Compute-Techniques-and-DeepSeek-R1-194bfe2110848099a5c3e0585f332d2a?pvs=4&#34;&gt;(原理)Reasoning LLM&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>(原理) DeepSeek R1</title>
      <link>https://www6v.github.io/www6vAlgo/docs/LLM/Reasoning/R1/DeepSeekR1/</link>
      <pubDate>Tue, 06 Feb 2024 18:42:00 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/LLM/Reasoning/R1/DeepSeekR1/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;原理-deepseek-r1&#34;&gt;&#xA;  (原理) DeepSeek R1&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e5%8e%9f%e7%90%86-deepseek-r1&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://candied-skunk-1ca.notion.site/DeepSeek-R1-188bfe21108480778260cd48a6a2417b?pvs=4&#34;&gt;(原理)DeepSeek R1&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>DeepSeek V3</title>
      <link>https://www6v.github.io/www6vAlgo/docs/LLM/Reasoning/V3/DeepSeek/</link>
      <pubDate>Tue, 06 Feb 2024 18:35:28 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/LLM/Reasoning/V3/DeepSeek/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;deepseek-v3&#34;&gt;&#xA;  DeepSeek V3&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#deepseek-v3&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://candied-skunk-1ca.notion.site/DeepSeek-V3-170bfe211084809490cef0c42147d6d5?pvs=4&#34;&gt;DeepSeek V3&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>(原理)BERT</title>
      <link>https://www6v.github.io/www6vAlgo/docs/LLM/Dense/BERT/</link>
      <pubDate>Fri, 12 Jan 2024 22:16:10 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAlgo/docs/LLM/Dense/BERT/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;bert&#34;&gt;&#xA;  BERT&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#bert&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://candied-skunk-1ca.notion.site/BERT-16abfe211084808fb8a3d0769c37c3db?pvs=4&#34;&gt;(原理)BERT&lt;/a&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
