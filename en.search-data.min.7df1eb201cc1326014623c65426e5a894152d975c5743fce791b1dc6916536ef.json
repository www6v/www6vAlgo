[{"id":0,"href":"/www6vAlgo/docs/RL/framework/verl/","title":"HybridFlow[veRL]","section":"Framework","content":" è®ºæ–‡ # HybridFlow: A Flexible and Efficient RLHF Framework\nè§£è¯» # HybridFlow[veRL]\n"},{"id":1,"href":"/www6vAlgo/docs/RL/Agentic-RL/survey/survey/","title":"(Survey)Agentic RL","section":"Survey","content":" è®ºæ–‡ # The Landscape of Agentic Reinforcement Learning for LLMs: A Survey git è§£è¯» # (Survey)Agentic RL\nå‚è€ƒ # The Landscape of Agentic Reinforcement Learning for LLMs: A Survey\nThe Landscape of Agentic Reinforcement Learning for LLMs: A Survey\n"},{"id":2,"href":"/www6vAlgo/docs/RL/Agentic-RL/Tool/OTC/","title":"OTC","section":"Tool","content":" å‚è€ƒ # 2025å¹´å¤§æ¨¡å‹agent rlè®­ç»ƒå¤šè½®planningæŠ€æœ¯TORL,ToolRL, RAGEN,OTC,SkyRL-v0, GiGPO,Tool-N1 ,ARTIST, ZeroTIR, GRPO\n"},{"id":3,"href":"/www6vAlgo/docs/RL/Agentic-RL/Tool/ReTool/","title":"ReTool","section":"Tool","content":" è®ºæ–‡ # å‚è€ƒ # é€šè¿‡å·¥å…·å¢å¼º LLM Agent èƒ½åŠ›ï¼šveRL+ReTool çš„å®Œæ•´å®è·µæŒ‡å—\n"},{"id":4,"href":"/www6vAlgo/docs/RL/Agentic-RL/Tool/ToolRL/","title":"ToolRL","section":"Tool","content":" è®ºæ–‡ # ToolRL: Reward is All Tool Learning Needs\nä¸ºäº†ç¡®å®šæœ€ä½³å¥–åŠ±ç­–ç•¥ï¼Œæ¢ç´¢äº†å››ä¸ªå…³é”®ç»´åº¦çš„å„ç§å¥–åŠ±é…ç½®ï¼š(1) å¥–åŠ±ç±»å‹ï¼ˆå¥–åŠ±å“ªäº›æ–¹é¢ï¼‰ï¼Œ(2) å¥–åŠ±å°ºåº¦ï¼ˆå¥–åŠ±å¤šå°‘ï¼‰ï¼Œ(3) å¥–åŠ±ç²’åº¦ï¼ˆå¥–åŠ±ä¿¡å·çš„è¯¦ç»†ç¨‹åº¦ï¼‰ï¼Œä»¥åŠ (4) å¥–åŠ±åŠ¨æ€ï¼ˆå¥–åŠ±å¦‚ä½•éšæ—¶é—´æ¼”å˜ï¼‰ã€‚é€šè¿‡å¤§é‡çš„å®éªŒç¡®å®šäº†æœ€ç¬¦åˆä¸»ä½“å·¥å…·ä½¿ç”¨æƒ…å†µçš„å¥–åŠ±è®¾è®¡ï¼Œå¹¶æ­ç¤ºäº†å¥–åŠ±å¯¹äºè°ƒç”¨å·¥å…·çš„ LLM è€Œè¨€â€œæœ‰ç”¨â€çš„åŸå› ã€‚è®ºæ–‡å¾—å‡ºçš„æ ¸å¿ƒè§è§£æ€»ç»“å¦‚ä¸‹ï¼š\næ¨ç†è½¨è¿¹è¶Šé•¿å¹¶ä¸ä¸€å®šè¶Šå¥½ï¼Œè€Œä¸”è¿‡é•¿çš„å¥–åŠ±å¯èƒ½ä¼šé™ä½æ€§èƒ½ã€‚ åŠ¨æ€å¥–åŠ±å°ºåº¦æœ‰åŠ©äºæ¨¡å‹ä»ç®€å•è¡Œä¸ºå¹³ç¨³è¿‡æ¸¡åˆ°å¤æ‚è¡Œä¸ºã€‚ ç»†ç²’åº¦çš„å¥–åŠ±åˆ†è§£å¯å®ç°æ›´ç¨³å®šã€æ›´æœ‰æ•ˆçš„å­¦ä¹ ã€‚ è®ºæ–‡å¾—å‡ºçš„æ ¸å¿ƒè§è§£æ€»ç»“å¦‚ä¸‹ï¼š\næ¨ç†è½¨è¿¹è¶Šé•¿å¹¶ä¸ä¸€å®šè¶Šå¥½ï¼Œè€Œä¸”è¿‡é•¿çš„å¥–åŠ±å¯èƒ½ä¼šé™ä½æ€§èƒ½ã€‚ åŠ¨æ€å¥–åŠ±å°ºåº¦æœ‰åŠ©äºæ¨¡å‹ä»ç®€å•è¡Œä¸ºå¹³ç¨³è¿‡æ¸¡åˆ°å¤æ‚è¡Œä¸ºã€‚ ç»†ç²’åº¦çš„å¥–åŠ±åˆ†è§£å¯å®ç°æ›´ç¨³å®šã€æ›´æœ‰æ•ˆçš„å­¦ä¹ ã€‚ Format RewardÂ Correctness Reward\nå‚è€ƒ # 2025å¹´å¤§æ¨¡å‹agent rlè®­ç»ƒå¤šè½®planningæŠ€æœ¯TORL,ToolRL, RAGEN,OTC,SkyRL-v0, GiGPO,Tool-N1 ,ARTIST, ZeroTIR, GRPO\n"},{"id":5,"href":"/www6vAlgo/docs/RL/Agentic-RL/Search/Search-R1/","title":"Search-R1","section":"Search","content":" è®ºæ–‡ # Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning https://github.com/PeterGriffinJin/Search-R1 Methods # è¯¦ç»†æ–¹æ³•å’Œæ­¥éª¤:\nå°†æœç´¢å¼•æ“å»ºæ¨¡ä¸ºç¯å¢ƒçš„ä¸€éƒ¨åˆ†ï¼šÂ SEARCH-R1å°†æœç´¢å¼•èµ·ä½œä¸ºç¯å¢ƒçš„ä¸€éƒ¨åˆ†ï¼Œ è®©æ¨¡å‹ä¸ç¯å¢ƒäº¤äº’ï¼Œä»è€Œå¾—åˆ° rewardã€‚ æ”¯æŒå¤šè½®æ£€ç´¢å’Œæ¨ç†ï¼šÂ SEARCH-R1é€šè¿‡ç‰¹å®šçš„æ ‡ç­¾ï¼ˆ\u0026lt;search\u0026gt;,Â \u0026lt;/search\u0026gt;,Â \u0026lt;information\u0026gt;,Â \u0026lt;/information\u0026gt;,Â \u0026lt;think\u0026gt;,Â \u0026lt;/think\u0026gt;,Â \u0026lt;answer\u0026gt;,Â \u0026lt;/answer\u0026gt;ï¼‰æ¥æ”¯æŒå¤šè½®æ£€ç´¢å’Œæ¨ç†ã€‚ ä¼˜åŒ–ç®—æ³•å…¼å®¹æ€§ï¼šÂ SEARCH-R1 ä¸å„ç§ RL ç®—æ³•å…¼å®¹ï¼ŒåŒ…æ‹¬ PPO å’Œ GRPOã€‚ ç®€å•ç»“æœå¥–åŠ±å‡½æ•°ï¼šÂ é¿å…å¤æ‚çš„åŸºäºè¿‡ç¨‹çš„å¥–åŠ±, é‡‡ç”¨ç®€å•çš„åŸºäºç»“æœçš„å¥–åŠ±å‡½æ•°Â ï¼ˆå­—ç¬¦ä¸²åŒ¹é…ä½œä¸ºreward!!!ï¼‰ã€‚ æ€»ç»“ # ç»“è®º1: SEARCH-R1 æ˜¾è‘—æå‡äº†LLMåœ¨éœ€è¦å®æ—¶å¤–éƒ¨çŸ¥è¯†çš„å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„èƒ½åŠ›ã€‚Â é€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼ŒLLMå¯ä»¥è‡ªä¸»ç”ŸæˆæŸ¥è¯¢å¹¶æœ‰æ•ˆåˆ©ç”¨æ£€ç´¢åˆ°çš„ä¿¡æ¯ï¼Œä¼˜äºä¼ ç»Ÿçš„RAGæ–¹æ³•ã€‚\nç»“è®º2: SEARCH-R1åœ¨ä¸åŒLLMæ¶æ„å’Œè®­ç»ƒæ–¹æ³•ä¸Šå…·æœ‰å¹¿æ³›çš„é€‚ç”¨æ€§ã€‚Â å®éªŒç»“æœè¡¨æ˜ï¼Œæ— è®ºä½¿ç”¨åŸºç¡€æ¨¡å‹è¿˜æ˜¯æŒ‡ä»¤è°ƒæ•´æ¨¡å‹ï¼ŒSEARCH-R1éƒ½èƒ½å¸¦æ¥æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œä¸”å¯¹ä¸åŒçš„RLç®—æ³•ï¼ˆå¦‚PPOå’ŒGRPOï¼‰å…·æœ‰å…¼å®¹æ€§ã€‚\nç»“è®º3: SEARCH-R1æœ‰å¾ˆå¼ºçš„å®ç”¨ä»·å€¼ã€‚Â SEARCH-R1èƒ½å¤Ÿæ˜¾è‘—æé«˜LLMåœ¨éœ€è¦å®æ—¶å¤–éƒ¨çŸ¥è¯†çš„å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„èƒ½åŠ›ã€‚ å¯ä»¥ç”¨äºæ™ºèƒ½é—®ç­”ï¼Œæ™ºèƒ½åŠ©æ‰‹ç­‰é¢†åŸŸã€‚\nå‚è€ƒ # Search-R1ï¼šè®©å¤§æ¨¡å‹å­¦ä¼šâ€œæ£€ç´¢+æ¨ç†â€çš„æ–°èŒƒå¼ 1xx. ã€è®ºæ–‡è§£è¯»ã€‘Search-R1ï¼šå¼ºåŒ–å­¦ä¹ å¦‚ä½•æ•™ä¼š LLM è‡ªä¸»æœç´¢ï¼Ÿ\n1xx. æœ‰ä¸ªå­¦æœ¯çš„ä¼šè®®\n1xx. Search-R1ï¼šè®© LLM å­¦ä¼š â€œè¾¹æœè¾¹æƒ³â€ï¼Œå¼ºåŒ–å­¦ä¹ èµ‹èƒ½æ£€ç´¢å¢å¼ºæ¨ç†\n"},{"id":6,"href":"/www6vAlgo/docs/LLM/MOE/gptModelMOE/gptModelMOE/","title":"(åŸç†)Visual  MOE","section":"MOE","content":" Visual MOE # (åŸç†)Visual MOE\n"},{"id":7,"href":"/www6vAlgo/docs/RL/core/GRPODeepseek/","title":"(å®æˆ˜)GRPO","section":"Core","content":"\nGRPO # (å®æˆ˜)GRPO\n"},{"id":8,"href":"/www6vAlgo/docs/DeepLearning/%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96/DeeplearningLearningRate/","title":"(åŸç†)å­¦ä¹ ç‡","section":"ç½‘ç»œä¼˜åŒ–","content":"\nå­¦ä¹ ç‡ # (åŸç†)å­¦ä¹ ç‡\n"},{"id":9,"href":"/www6vAlgo/docs/DeepLearning/%E6%AD%A3%E5%88%99%E5%8C%96/WeightDecay/","title":"(åŸç†\u0026å®æˆ˜)æƒé‡è¡°å‡","section":"æ­£åˆ™åŒ–","content":"\næƒé‡è¡°å‡ WeightDecay # (åŸç†\u0026amp;å®æˆ˜)æƒé‡è¡°å‡\n"},{"id":10,"href":"/www6vAlgo/docs/LLM/core/gptScalingLaw/","title":"Scaling Law","section":"core","content":" Scaling Law[10] # Scaling Law # å‚æ•°é‡ vs æ•°æ®é‡ # å‚æ•°é‡ vs æ•°æ®é‡ # å‚è€ƒ # Scaling Law # è§£æå¤§æ¨¡å‹ä¸­çš„Scaling Law 1xx. è®ºæ–‡é˜…è¯»ï¼Œå¤§æ¨¡å‹çš„ç¼©æ”¾å®šå¾‹ï¼ŒScaling Laws for Neural Language Models 2xx. Training Compute-Optimal Large Language Models ç®€è¯» 2xx. ã€é¢„è®­ç»ƒæ¨¡å‹ã€‘æ¨ç¿»OpenAIç»“è®º, DeepMindé‡æ–°å®šä¹‰é¢„è®­ç»ƒçš„è®­ç»ƒå‚æ•°å’Œè®­ç»ƒè§„æ¨¡çš„å…³ç³»ï¼ ã€ŠScaling Laws for Neural Language Modelsã€‹ ã€ŠTraining Compute-Optimal Large Language Modelsã€‹\n"},{"id":11,"href":"/www6vAlgo/docs/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/MLData/","title":"æœºå™¨å­¦ä¹ -æ•°æ®","section":"æœºå™¨å­¦ä¹ ","content":"\næœºå™¨å­¦ä¹ -æ•°æ® # æœºå™¨å­¦ä¹ -æ•°æ®\n"},{"id":12,"href":"/www6vAlgo/docs/LLM/Foundation-Models/decode-only/gptFamily/gptFamily/","title":"GPT ç³»åˆ—","section":"decode-only","content":" è¿›åŒ–æ—¶é—´çº¿ # {% asset_img \u0026lsquo;family.jpg\u0026rsquo; %}\nGPT1 [1] # å®ƒæ˜¯æœ€æ—©ä¸€æ‰¹æå‡ºåœ¨ NLP ä»»åŠ¡ä¸Šä½¿ç”¨ pre-train + fine-tuning èŒƒå¼çš„å·¥ä½œã€‚ GPT çš„å®éªŒè¯æ˜äº†æ¨¡å‹çš„ç²¾åº¦å’Œæ³›åŒ–èƒ½åŠ›ä¼šéšç€è§£ç å™¨å±‚æ•°å¢åŠ è€Œä¸æ–­æå‡ï¼Œè€Œä¸”ç›®å‰è¿˜æœ‰æå‡ç©ºé—´ é¢„è®­ç»ƒæ¨¡å‹å…·æœ‰ zero-shot çš„èƒ½åŠ›ï¼Œå¹¶ä¸”èƒ½éšç€é¢„è®­ç»ƒçš„è¿›è¡Œä¸æ–­å¢å¼º GPT2 [1] # æ ¸å¿ƒæ€æƒ³ # å½“æ¨¡å‹çš„å®¹é‡éå¸¸å¤§ä¸”æ•°æ®é‡è¶³å¤Ÿä¸°å¯Œæ—¶ï¼Œä»…ä»…é è¯­è¨€æ¨¡å‹çš„å­¦ä¹ ä¾¿å¯ä»¥å®Œæˆå…¶ä»–æœ‰ç›‘ç£å­¦ä¹ çš„ä»»åŠ¡ï¼Œä¸éœ€è¦åœ¨ä¸‹æ¸¸ä»»åŠ¡å¾®è°ƒã€‚\nGPT-2 vs. GPT-1 # ä¸»æ¨ zero-shotï¼Œè€Œ GPT-1 ä¸º pre-train + fine-tuningï¼› è®­ç»ƒæ•°æ®è§„æ¨¡æ›´å¤§ï¼ŒGPT-2 ä¸º 800w æ–‡æ¡£ 40Gï¼ŒGPT-1 ä¸º 5GBï¼› æ¨¡å‹å¤§å°ï¼ŒGPT-2 æœ€å¤§ 15 äº¿å‚æ•°ï¼ŒGPT-1ä¸º 1 äº¿å‚æ•°ï¼› æ¨¡å‹ç»“æ„è°ƒæ•´ï¼Œå±‚å½’ä¸€åŒ–å’Œå‚æ•°åˆå§‹åŒ–æ–¹å¼ï¼› è®­ç»ƒå‚æ•°ï¼Œbatch_size ä» 64 å¢åŠ åˆ° 512ï¼Œä¸Šæ–‡çª—å£å¤§å°ä» 512 å¢åŠ åˆ° 1024ï¼Œç­‰ç­‰ï¼› GPT3 [1] # ä¸‹æ¸¸ä»»åŠ¡è¯„ä¼°æ–¹æ³• # GPT-3 åœ¨ä¸‹æ¸¸ä»»åŠ¡çš„è¯„ä¼°ä¸é¢„æµ‹æ—¶ï¼Œæä¾›äº†ä¸‰ç§ä¸åŒçš„æ–¹æ³•ï¼š Zero-shotï¼šä»…ä½¿ç”¨å½“å‰ä»»åŠ¡çš„è‡ªç„¶è¯­è¨€æè¿°ï¼Œä¸è¿›è¡Œä»»ä½•æ¢¯åº¦æ›´æ–°ï¼› One-shotï¼šå½“å‰ä»»åŠ¡çš„è‡ªç„¶è¯­è¨€æè¿°ï¼ŒåŠ ä¸Šä¸€ä¸ªç®€å•çš„è¾“å…¥è¾“å‡ºæ ·ä¾‹ï¼Œä¸è¿›è¡Œä»»ä½•æ¢¯åº¦æ›´æ–°ï¼› Few-shotï¼šå½“å‰ä»»åŠ¡çš„è‡ªç„¶è¯­è¨€æè¿°ï¼ŒåŠ ä¸Šå‡ ä¸ªç®€å•çš„è¾“å…¥è¾“å‡ºæ ·ä¾‹ï¼Œä¸è¿›è¡Œä»»ä½•æ¢¯åº¦æ›´æ–°ï¼›\nShot[2] One-shot Few-Shot Zero-Shot Few-shot vs fine-tuning # å…¶ä¸­ Few-shot ä¹Ÿè¢«ç§°ä¸º in-context learningï¼Œè™½ç„¶å®ƒä¸ fine-tuning ä¸€æ ·éƒ½éœ€è¦ä¸€äº›æœ‰ç›‘ç£æ ‡æ³¨æ•°æ®ï¼Œä½†æ˜¯ä¸¤è€…çš„åŒºåˆ«æ˜¯ï¼š ã€æœ¬è´¨åŒºåˆ«ã€‘ fine-tuning åŸºäºæ ‡æ³¨æ•°æ®å¯¹æ¨¡å‹å‚æ•°è¿›è¡Œæ›´æ–° è€Œin-context learningä½¿ç”¨æ ‡æ³¨æ•°æ®æ—¶ä¸åšä»»ä½•çš„æ¢¯åº¦å›ä¼ , æ¨¡å‹å‚æ•°ä¸æ›´æ–°\nGPT-3 vs. GPT-2 # æ•ˆæœä¸Šï¼Œè¶…å‡º GPT-2 éå¸¸å¤šï¼Œèƒ½ç”Ÿæˆäººç±»éš¾ä»¥åŒºåˆ†çš„æ–°é—»æ–‡ç« ï¼› ä¸»æ¨ few-shotï¼Œç›¸æ¯”äº GPT-2 çš„ zero-shotï¼Œå…·æœ‰å¾ˆå¼ºçš„åˆ›æ–°æ€§ï¼› æ¨¡å‹ç»“æ„ç•¥å¾®å˜åŒ–ï¼Œé‡‡ç”¨ sparse attention æ¨¡å—ï¼› æµ·é‡è®­ç»ƒè¯­æ–™ 45TBï¼ˆæ¸…æ´—å 570GBï¼‰ï¼Œç›¸æ¯”äº GPT-2 çš„ 40GBï¼› æµ·é‡æ¨¡å‹å‚æ•°ï¼Œæœ€å¤§æ¨¡å‹ä¸º 1750 äº¿ï¼ŒGPT-2 æœ€å¤§ä¸º 15 äº¿å‚æ•°ï¼› InstructGPT [1] # æ­¥éª¤ # æœ‰ç›‘ç£å¾®è°ƒï¼Œ å¥–åŠ±æ¨¡å‹è®­ç»ƒï¼Œ å¼ºåŒ–å­¦ä¹ è®­ç»ƒ æŠ€æœ¯æ–¹æ¡ˆ # æœ‰ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ æœ¬è´¨ä¸Šæ¥è¯´ï¼ŒSFT å¯ä»¥ç†è§£ä¸ºäººå·¥æ ‡æ³¨äº†ä¸€æ‰¹æ•°æ®ï¼Œç„¶åå»å¾®è°ƒ GPT-3ã€‚ä½†æ˜¯å€¼å¾—ä¸€æçš„æ˜¯ï¼Œè¿™é‡Œæ ‡æ³¨çš„æ•°æ®ä¸ GPT-3 ä¹‹å‰ç”¨æ¥åšä¸‹æ¸¸ä»»åŠ¡ä½¿ç”¨çš„ few-shot æ ¼å¼ï¼Œæœ‰éå¸¸æœ¬è´¨çš„åŒºåˆ«ã€‚ InstructGPT åœ¨ SFT ä¸­æ ‡æ³¨çš„æ•°æ®ï¼Œæ­£æ˜¯ä¸ºäº†æ¶ˆé™¤è¿™ç§æ¨¡å‹é¢„æµ‹ä¸ç”¨æˆ·è¡¨è¾¾ä¹ æƒ¯ä¹‹é—´çš„ gapã€‚åœ¨æ ‡æ³¨è¿‡ç¨‹ä¸­ï¼Œä»–ä»¬ä» GPT-3 çš„ç”¨æˆ·çœŸå®è¯·æ±‚ä¸­é‡‡æ ·å¤§é‡ä¸‹æ¸¸ä»»åŠ¡çš„æè¿°ï¼Œç„¶åè®©æ ‡æ³¨äººå‘˜å¯¹ä»»åŠ¡æè¿°è¿›è¡Œç»­å†™ï¼Œä»è€Œå¾—åˆ°è¯¥é—®é¢˜çš„é«˜è´¨é‡å›ç­”ã€‚\nåŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼‰ {% asset_img \u0026lsquo;instructGPT.jpg\u0026rsquo; %}\næ€»ç»“ # è§£å†³ GPT-3 çš„è¾“å‡ºä¸äººç±»æ„å›¾ä¹‹é—´çš„Aligné—®é¢˜ï¼› è®©å…·å¤‡ä¸°å¯Œä¸–ç•ŒçŸ¥è¯†çš„å¤§æ¨¡å‹ï¼Œå­¦ä¹ â€œäººç±»åå¥½â€ï¼› æ ‡æ³¨äººå‘˜æ˜æ˜¾æ„Ÿè§‰ InstructGPT çš„è¾“å‡ºæ¯” GPT-3 çš„è¾“å‡ºæ›´å¥½ï¼Œæ›´å¯é ï¼› InstructGPT åœ¨çœŸå®æ€§ï¼Œä¸°å¯Œåº¦ä¸Šè¡¨ç°æ›´å¥½ï¼› InstructGPT å¯¹æœ‰å®³ç»“æœçš„ç”Ÿæˆæ§åˆ¶çš„æ›´å¥½ï¼Œä½†æ˜¯å¯¹äº**â€œåè§â€æ²¡æœ‰æ˜æ˜¾æ”¹å–„**ï¼› ChatGPT è®­ç»ƒ [3] # åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ å¾®è°ƒæŠ€æœ¯ RLHF ä½¿ç”¨æœ‰ç›‘ç£å¾®è°ƒ Supervised Fine-tuningï¼ˆSFTï¼‰é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ Supervised fine-tuning (SFT) = Instruction Tuning è®­ç»ƒå¥–åŠ±æ¨¡å‹ Reward Modelï¼ˆRMï¼‰ ä½¿ç”¨å¼ºåŒ–å­¦ä¹ ç®—æ³•å¾®è°ƒè¯­è¨€æ¨¡å‹ RLHF [æœ¬è´¨ åŸºäºå¼ºåŒ–å­¦ä¹ , å¼ºåŒ–å­¦ä¹ ç®—æ³•] å‚è€ƒ # GPT / GPT-2 / GPT-3 / InstructGPT è¿›åŒ–ä¹‹è·¯ ***\nFew-Shot, Zero-Shot \u0026amp; One-shot çš„é€šä¿—ç†è§£\nAI å¤§æ¨¡å‹å¾®è°ƒè®­ç»ƒè¥å¤§çº²\n1xx. ä¸‡å­—æ‹†è§£ï¼è¿½æº¯ChatGPTå„é¡¹èƒ½åŠ›çš„èµ·æº ç¬¦å°§\n1xx. [Transformer 101ç³»åˆ—] ChatGPTæ˜¯æ€ä¹ˆç‚¼æˆçš„? æœª\n"},{"id":13,"href":"/www6vAlgo/docs/DeepLearning/Transformer/Transformer/","title":"(åŸç†)Transformer","section":"Transformer","content":"\n(åŸç†)Transformer # (åŸç†)Transformer\n"},{"id":14,"href":"/www6vAlgo/docs/LLM/Foundation-Models/gptLargeModelSurvey/gptLargeModelSurvey/","title":"(ç»¼è¿°)å¤§æ¨¡å‹","section":"Foundation Models","content":" LLMsçš„èƒŒæ™¯[1] # Scaling law of LLMs # KM scaling law Chinchilla Scaling law LLMsçš„æ¶Œç°èƒ½åŠ› # in-context learning instruction following step-by-step reasoning å¤§è¯­è¨€æ¨¡å‹çš„å…³é”®æŠ€æœ¯ *** # Scaling Training Ability Eliciting Alignment Tuning Tool Manipulation Pre-training[1] # æ•°æ®æ”¶é›† # æ¶æ„ # æ¨¡å‹è®­ç»ƒ *** # ä¼˜åŒ–è®¾ç½®\nBatch Training Learning Rate Optimizer Stabilizing the Training å¯æ‰©å±•çš„è®­ç»ƒæŠ€å·§\n3Då¹¶è¡Œ æ•°æ®å¹¶è¡Œ + æµæ°´çº¿å¹¶è¡Œ + å¼ é‡å¹¶è¡Œ ZeRO æ··åˆç²¾åº¦è®­ç»ƒ æ€»ä½“è®­ç»ƒå»ºè®® Adaptation Tuning of LLMs[1] # æŒ‡ä»¤è°ƒä¼˜ *** # æœ¬è´¨ä¸Šï¼ŒæŒ‡ä»¤å¾®è°ƒæ˜¯åœ¨è‡ªç„¶è¯­è¨€æ ¼å¼çš„å®ä¾‹ï¼ˆinstanceï¼‰é›†åˆä¸Šå¾®è°ƒé¢„è®­ç»ƒåçš„ LLM çš„æ–¹æ³• [62]ã€‚\næŒ‡ä»¤å¾®è°ƒåï¼ŒLLM å¯ä»¥å±•ç°å‡ºæ³›åŒ–åˆ°æœªè§è¿‡ä»»åŠ¡çš„å“è¶Šèƒ½åŠ› [28, 62, 64]ï¼Œå³ä½¿åœ¨å¤šè¯­è¨€åœºæ™¯ä¸‹ä¹Ÿèƒ½æœ‰ä¸é”™è¡¨ç° [98]ã€‚\næ ¼å¼åŒ–å®ä¾‹çš„æ„å»º # æ ¼å¼åŒ–å·²æœ‰æ•°æ®é›† æ ¼å¼åŒ–äººç±»éœ€æ±‚ æ„å»ºå®ä¾‹çš„å…³é”®å› ç´  å¢åŠ æŒ‡ä»¤ è®¾è®¡æ ¼å¼ æ€»çš„æ¥è¯´ï¼ŒæŒ‡ä»¤å¤šæ ·æ€§ä¼¼ä¹æ¯”å®ä¾‹æ•°é‡æ›´é‡è¦\næŒ‡ä»¤å¾®è°ƒç­–ç•¥ # å¹³è¡¡æ•°æ®åˆ†å¸ƒ ä¸€ç§å¹¿æ³›ä½¿ç”¨çš„æ–¹æ³•æ˜¯å®ä¾‹æ¯”ä¾‹æ··åˆç­–ç•¥ [87]ï¼Œå³å°†æ‰€æœ‰æ•°æ®é›†åˆå¹¶ï¼Œç„¶åä»æ··åˆæ•°æ®é›†ä¸­æŒ‰æ¯”ä¾‹é‡‡æ ·æ¯ç§å®ä¾‹ã€‚ æ­¤å¤–ï¼Œæ ¹æ®æœ€è¿‘çš„ç ”ç©¶å‘ç° [64, 99]ï¼Œæé«˜é«˜è´¨é‡æ•°æ®é›†ï¼ˆä¾‹å¦‚ FLAN [62] å’Œ P3 [209]ï¼‰çš„é‡‡æ ·æ¯”ä¾‹é€šå¸¸å¯ä»¥å¸¦æ¥æ€§èƒ½æå‡ã€‚\nç»“åˆæŒ‡ä»¤å¾®è°ƒå’Œé¢„è®­ç»ƒ ä¸ºäº†ä½¿å¾®è°ƒè¿‡ç¨‹æ›´åŠ æœ‰æ•ˆå’Œç¨³å®šï¼ŒOPT-IML [99] åœ¨æŒ‡ä»¤å¾®è°ƒæœŸé—´åŠ å…¥äº†é¢„è®­ç»ƒæ•°æ®ï¼Œè¿™å¯ä»¥çœ‹ä½œæ˜¯å¯¹æ¨¡å‹çš„æ­£åˆ™åŒ–ï¼ˆregularizationï¼‰ã€‚\nå…·ä½“è€Œè¨€ï¼ŒGLM-130B [97] å’Œ Galactica [34] å°†æŒ‡ä»¤æ ¼å¼æ•°æ®é›†ä½œä¸ºé¢„è®­ç»ƒè¯­æ–™åº“çš„ä¸€å°éƒ¨åˆ†æ¥é¢„è®­ç»ƒ LLMï¼Œè¿™æœ‰å¯èƒ½åŒæ—¶è·å¾—é¢„è®­ç»ƒå’ŒæŒ‡ä»¤å¾®è°ƒçš„ä¼˜åŠ¿ã€‚\næŒ‡ä»¤å¾®è°ƒçš„æ•ˆæœ # æ€§èƒ½æ”¹è¿› æœ€è¿‘çš„ç ”ç©¶åœ¨å¤šä¸ªè§„æ¨¡ä¸Šï¼ˆä» 7700 ç™¾ä¸‡åˆ° 5400 äº¿ä¸ç­‰ï¼‰å¯¹ LM è¿›è¡Œäº†å®éªŒï¼Œè¡¨æ˜ä¸åŒè§„æ¨¡çš„æ¨¡å‹éƒ½å¯ä»¥ä»æŒ‡ä»¤å¾®è°ƒä¸­å—ç›Š [64, 216]ï¼Œéšç€å‚æ•°è§„æ¨¡çš„å¢åŠ ï¼Œæ€§èƒ½ä¹Ÿå¾—åˆ°äº†æå‡ [98]ã€‚ ã€æ™®é€‚æ€§ã€‘ æ­¤å¤–ï¼Œç»è¿‡æŒ‡ä»¤å¾®è°ƒçš„è¾ƒå°æ¨¡å‹ç”šè‡³å¯ä»¥æ¯”æœªç»å¾®è°ƒçš„è¾ƒå¤§æ¨¡å‹è¡¨ç°æ›´å¥½ [28, 64]ã€‚\nä»»åŠ¡æ³›åŒ–æ€§ todo å¯¹é½è°ƒä¼˜ # é«˜æ•ˆè°ƒä¼˜ # å‚è€ƒ # å¤§è¯­è¨€æ¨¡å‹ç»¼è¿° ä¸­æ–‡ v10\nå¤§è¯­è¨€æ¨¡å‹ç»¼è¿° ä¸­æ–‡\nLLMSurvey Repo git\n[è®ºæ–‡]å¤§è¯­è¨€æ¨¡å‹ç»¼è¿°\nè¯¦è°ˆå¤§æ¨¡å‹è®­ç»ƒä¸­çš„æ•°æ®æ”¶é›†ã€å¤„ç†ä¸æ¨¡å‹å½±å“ï¼šA Survey of Large Language Modelså·¥ä½œä¸­çš„æ•°æ®æ€»ç»“\nå¤§æ¨¡å‹ç»¼è¿°-A Survey of Large Language Models 1xx. å€¼å¾—ä¸€çœ‹çš„å¤§æ¨¡å‹æœ€æ–°ç»¼è¿°ï¼šå…¼çœ‹å¤šè¯­ç§å¤§æ¨¡å‹å¾®è°ƒæ•°æ®é›†Aya 1xx. 43é¡µé¢„è®­ç»ƒæ¨¡å‹ç»¼è¿°ï¼ˆæ¸…åã€å¤æ—¦ã€äººå¤§ï¼‰\n"},{"id":15,"href":"/www6vAlgo/docs/DeepLearning/basic/DeepLearning/","title":"Deep Learning","section":"basic","content":"\nDeep Learning # Deep Learning\n"},{"id":16,"href":"/www6vAlgo/docs/LLM/MOE/gptModelMOECode/gptModelMOECode/","title":"(ä»£ç )MOE","section":"MOE","content":" import torch import torch.nn as nn import torch.nn.functional as F import torch_npu from torch_npu.contrib import transfer_to_npu class Expert(nn.Module): def __init__(self, input_dim, hidden_dim, output_dim): super().__init__() self.net = nn.Sequential( nn.Linear(input_dim, hidden_dim), nn.GELU(), nn.Linear(hidden_dim, output_dim)) def forward(self, x): return self.net(x) class MoE(nn.Module): def __init__(self, input_dim, num_experts, top_k, expert_capacity, hidden_dim, output_dim): super().__init__() self.num_experts = num_experts self.top_k = top_k self.expert_capacity = expert_capacity # è·¯ç”±ç½‘ç»œ self.gate = nn.Linear(input_dim, num_experts) # ä¸“å®¶é›†åˆ self.experts = nn.ModuleList( [Expert(input_dim, hidden_dim, output_dim) for _ in range(num_experts)]) def forward(self, x): batch_size, input_dim = x.shape device = x.device # è·¯ç”±è®¡ç®— logits = self.gate(x) probs = torch.softmax(logits, dim=-1) topk_probs, topk_indices = torch.topk(probs, self.top_k, dim=-1) # è¾…åŠ©æŸå¤±è®¡ç®— if self.training: # é‡è¦æ€§æŸå¤±ï¼ˆä¸“å®¶åˆ©ç”¨ç‡å‡è¡¡ï¼‰ importance = probs.sum(0) importance_loss = torch.var(importance) / (self.num_experts ** 2) # è´Ÿè½½å‡è¡¡æŸå¤±ï¼ˆæ ·æœ¬åˆ†é…å‡è¡¡ï¼‰ mask = torch.zeros_like(probs, dtype=torch.bool) mask.scatter_(1, topk_indices, True) routing_probs = probs * mask expert_usage = mask.float().mean(0) routing_weights = routing_probs.mean(0) load_balance_loss = self.num_experts * (expert_usage * routing_weights).sum() aux_loss = importance_loss + load_balance_loss else: aux_loss = 0.0 # ä¸“å®¶åˆ†é…é€»è¾‘ flat_indices = topk_indices.view(-1) flat_probs = topk_probs.view(-1) sample_indices = torch.arange(batch_size, device=device)[:, None]\\ .expand(-1, self.top_k).flatten() # åˆå§‹åŒ–è¾“å‡º outputs = torch.zeros(batch_size, self.experts[0].net[-1].out_features, device=device) # å¤„ç†æ¯ä¸ªä¸“å®¶ for expert_idx in range(self.num_experts): # è·å–åˆ†é…ç»™å½“å‰ä¸“å®¶çš„æ ·æœ¬ expert_mask = flat_indices == expert_idx expert_samples = sample_indices[expert_mask] expert_weights = flat_probs[expert_mask] # å®¹é‡æ§åˆ¶ if len(expert_samples) \u0026gt; self.expert_capacity: expert_samples = expert_samples[:self.expert_capacity] expert_weights = expert_weights[:self.expert_capacity] if len(expert_samples) == 0: continue # å¤„ç†ä¸“å®¶è®¡ç®— expert_input = x[expert_samples] expert_output = self.experts[expert_idx](expert_input) weighted_output = expert_output * expert_weights.unsqueeze(-1) # ç´¯åŠ è¾“å‡º outputs.index_add_(0, expert_samples, weighted_output) return outputs, aux_loss # æµ‹è¯•ç¤ºä¾‹ if __name__ == \u0026#34;__main__\u0026#34;: input_dim = 128 output_dim = 256 num_experts = 8 top_k = 2 expert_capacity = 32 hidden_dim = 512 batch_size = 64 # add device = torch.device(\u0026#34;npu:4\u0026#34; if torch.npu.is_available() else \u0026#34;cpu\u0026#34;) moe = MoE(input_dim, num_experts, top_k, expert_capacity, hidden_dim, output_dim).to(device) x = torch.randn(batch_size, input_dim).to(device) experimental_config = torch_npu.profiler._ExperimentalConfig( export_type=torch_npu.profiler.ExportType.Text, profiler_level=torch_npu.profiler.ProfilerLevel.Level0, msprof_tx=False, aic_metrics=torch_npu.profiler.AiCMetrics.AiCoreNone, l2_cache=False, op_attr=False, data_simplification=False, record_op_args=False, gc_detect_threshold=None ) with torch_npu.profiler.profile( activities=[ torch_npu.profiler.ProfilerActivity.CPU, torch_npu.profiler.ProfilerActivity.NPU ], schedule=torch_npu.profiler.schedule(wait=0, warmup=0, active=1, repeat=1, skip_first=1), on_trace_ready=torch_npu.profiler.tensorboard_trace_handler(\u0026#34;./moe_stand_npu_result\u0026#34;), record_shapes=False, profile_memory=False, with_stack=False, with_modules=False, with_flops=False, experimental_config=experimental_config) as prof: # è®­ç»ƒæ¨¡å¼ for _ in range(10): moe.train() output, loss = moe(x) print(f\u0026#34;Using device: {x.device}\u0026#34;) print(f\u0026#34;Training output shape: {output.shape}\u0026#34;) # torch.Size([64, 256]) print(f\u0026#34;Training auxiliary loss: {loss.item():.4f}\u0026#34;) # ç¤ºä¾‹å€¼ï¼Œå¦‚0.1234 prof.step() print(\u0026#34;=\u0026#34; * 80) # æ¨ç†æ¨¡å¼ moe.eval() output, _ = moe(x) print(f\u0026#34;Eval output shape: {output.shape}\u0026#34;) # torch.Size([64, 256]) å‚è€ƒ # MoE git\n"},{"id":17,"href":"/www6vAlgo/docs/RL/core/PPO/","title":"(åŸç†)PPO","section":"Core","content":"\nPPO # (åŸç†)PPO\n"},{"id":18,"href":"/www6vAlgo/docs/DeepLearning/%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96/DeeplearningBatchsize/","title":"(åŸç†)Batchsize","section":"ç½‘ç»œä¼˜åŒ–","content":"\næœ€ä½³å®è·µ # batchsize # batchsize ä¸‹é™ [1] åˆ«å¤ªå°çš„é™åˆ¶åœ¨äºï¼Œbatch sizeå¤ªå°ï¼Œä¼šæ¥ä¸åŠæ”¶æ•›ã€‚\næ‰€ä»¥åœ¨å¸¸è§çš„settingï¼ˆï½100 epochsï¼‰ï¼Œbatch sizeä¸€èˆ¬ä¸ä¼šä½äº16ã€‚\nbatchsize ä¸Šé™ [1] batch sizeåˆ«å¤ªå¤§çš„é™åˆ¶åœ¨äºä¸¤ä¸ªç‚¹ï¼Œ\n1ï¼‰batch sizeå¤ªå¤§ï¼Œmemoryå®¹æ˜“ä¸å¤Ÿç”¨ã€‚è¿™ä¸ªå¾ˆæ˜¾ç„¶ï¼Œå°±ä¸å¤šè¯´äº†ã€‚\n2ï¼‰batch sizeå¤ªå¤§ï¼Œæ·±åº¦å­¦ä¹ çš„ä¼˜åŒ–ï¼ˆtraining lossé™ä¸ä¸‹å»ï¼‰å’Œæ³›åŒ–ï¼ˆgeneralization gapå¾ˆå¤§ï¼‰éƒ½ä¼šå‡ºé—®é¢˜ã€‚\nlearning rate \u0026amp; batch size # æ€»ä¹‹ï¼Œå¯ä»¥è¯æ˜ï¼Œlearning rate/batch sizeçš„æ¯”å€¼å¯¹æ·±åº¦å­¦ä¹ æ˜¯æœ‰æŒ‡æ•°çº§çš„å½±å“[3]ï¼Œæ‰€ä»¥éå¸¸é‡è¦ï¼Œæ²¡äº‹åˆ«çè°ƒã€‚[1]\nè¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆå¤§çš„batch_sizeå¾€å¾€å»ºè®®å¯ä»¥ç›¸åº”å–å¤§ç‚¹learning_rate, å› ä¸ºæ¢¯åº¦éœ‡è¡å°ï¼Œå¤§learning_rateå¯ä»¥åŠ é€Ÿæ”¶æ•›è¿‡ç¨‹ï¼Œä¹Ÿå¯ä»¥é˜²æ­¢é™·å…¥åˆ°å±€éƒ¨æœ€å°å€¼ï¼Œè€Œå°batch_sizeç”¨å°learning_rateè¿­ä»£ï¼Œé˜²æ­¢é”™è¿‡æœ€ä¼˜ç‚¹ï¼Œä¸€ç›´ä¸Šä¸‹éœ‡è¡æ²¡æ³•æ”¶æ•›ï¼ˆè¿™ä¹Ÿæ˜¯ä¸€ä¸ªå°trickï¼‰ã€‚[2]\nå‚è€ƒ # æ€ä¹ˆé€‰å–è®­ç»ƒç¥ç»ç½‘ç»œæ—¶çš„Batch size? Summer Clover è®­ç»ƒç¥ç»ç½‘ç»œæ—¶batchsizeæ‰©å¤§ä¸€å€çš„åŒæ—¶éœ€è¦å¢åŠ epochæ•°é‡å—? æ–°ä¸€ 7.1 æ‰¹å¤§å°è°ƒæ•´å®éªŒ ç™¾åº¦é‚±\n7.1 æ‰¹å¤§å°è°ƒæ•´å®éªŒ\nè®¾ç½®BatchSize\næ·±åº¦å­¦ä¹ ä¸­çš„batchçš„å¤§å°å¯¹å­¦ä¹ æ•ˆæœæœ‰ä½•å½±å“ï¼Ÿ\n"},{"id":19,"href":"/www6vAlgo/docs/DeepLearning/basic/DeeplearningForwardBackward/","title":"(åŸç†\u0026å®æˆ˜)å‰å‘/åå‘ä¼ æ’­","section":"basic","content":"\nå‰å‘/åå‘ä¼ æ’­ # (åŸç†\u0026amp;å®æˆ˜)å‰å‘/åå‘ä¼ æ’­\n"},{"id":20,"href":"/www6vAlgo/docs/DeepLearning/%E6%AD%A3%E5%88%99%E5%8C%96/Dropout/","title":"(åŸç†\u0026å®æˆ˜)Dropout","section":"æ­£åˆ™åŒ–","content":"\nDropout # (åŸç†\u0026amp;å®æˆ˜)Dropout\n"},{"id":21,"href":"/www6vAlgo/docs/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/MLModel/","title":"æœºå™¨å­¦ä¹ -æ¨¡å‹","section":"æœºå™¨å­¦ä¹ ","content":"\næœºå™¨å­¦ä¹ -æ¨¡å‹ # æœºå™¨å­¦ä¹ -æ¨¡å‹\n"},{"id":22,"href":"/www6vAlgo/docs/DeepLearning/Transformer/SelfAttention/","title":"(åŸç†)Self-Attention","section":"Transformer","content":"\nSelf-Attention # (åŸç†)Self-Attention\n"},{"id":23,"href":"/www6vAlgo/docs/DeepLearning/Transformer/Embedding/survey/","title":"(Survey)Embedding","section":"Embedding","content":" è®ºæ–‡ # è®ºæ–‡åœ°å€\nOn The Role of Pretrained Language Models in General-Purpose Text Embeddings: A Survey é€šç”¨æ–‡æœ¬åµŒå…¥ï¼ˆGPTEï¼‰æ¨¡å‹çš„å…¸å‹æ¶æ„å’Œè®­ç»ƒæ–¹å¼ # é€šç”¨æ–‡æœ¬embeddingçš„ä»£è¡¨æ¨¡å‹åŠå‚æ•° # å‚è€ƒ # Embeddingçš„9ç‚¹æ€»ç»“-ä»æ¶æ„ã€æ•°æ®åˆ°ä»£è¡¨æ¨¡å‹\n"},{"id":24,"href":"/www6vAlgo/docs/LLM/Foundation-Models/gptLargeModel/gptLargeModel/","title":"å¤§æ¨¡å‹","section":"Foundation Models","content":" å‚è€ƒ # 1xx. [è¯‘][è®ºæ–‡] å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç»¼è¿°ä¸å®ç”¨æŒ‡å—ï¼ˆAmazonï¼Œ2023ï¼‰ å®æˆ˜\n1xx. é€šå‘AGIä¹‹è·¯ï¼šå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æŠ€æœ¯ç²¾è¦ ***\n1xx. å¿…çœ‹çš„åäºŒä¸ªå¤§æ¨¡å‹å‰æ²¿ç»¼è¿°ï¼šå…¼è®ºHALOå¤§æ¨¡å‹å¹»è§‰æ£€æµ‹ä¸ç¼“è§£æ–¹æ¡ˆåŠGoogleå°æ¨¡å‹é¢„æµ‹å¤§æ¨¡å‹è®­ç»ƒä¸ç¨³å®šçš„æ¢ç´¢ 12ä¸ªç»¼è¿°\n"},{"id":25,"href":"/www6vAlgo/docs/LLM/core/gptEmergent/","title":"(åŸç†)æ¶Œç°ç°è±¡","section":"core","content":" Emergent Abilities # ğŸ”— æ–‡ç« ï¼šEmergent Abilities of Large Language Models (2022.10) (arxiv.org) ğŸ”‘å…³é”®è¯å’Œæ‘˜è¦ Keywords: LLMs, Emergent Ability, Scaling abstract ä¸å¯é¢„æµ‹ ä¸èƒ½ä»å°æ¨¡å‹çš„çš„æ€§èƒ½å¤–æ¨ æ˜¯å¦èƒ½é€šè¿‡ç»§ç»­æ‰©å¤§æ¨¡å‹è§„æ¨¡æ¥è·å¾—æ›´å¤šæ¶Œç°èƒ½åŠ› âš™ï¸ç ”ç©¶è®¾è®¡å’Œç»“è®º å®šä¹‰ é€šå¸¸çš„æ¶Œç°ç°è±¡ å¤§æ¨¡å‹çš„æ¶Œç°ç°è±¡ å°æ¨¡å‹æ¥è¿‘éšæœº å¤§æ¨¡å‹çªç„¶å‡ºç° ç›¸å˜ å®éªŒæ¡†æ¶ performance vs 1. FLOPs, model parameters Training datasets å ç”²ï¼šemergent ä¸å¾ˆå¤šå› ç´ éƒ½æœ‰å…³ï¼Œæœ¬æ–‡å¹¶ä¸æ˜¯è¯´åˆ°å“ªä¸ª scale å°±ä¼šå‡ºç° emergentï¼Œè€Œæ˜¯è¯´ emergent ç°è±¡æ™®éå­˜åœ¨ã€‚ å®éªŒ1 Few-shot Prompting æµ‹è¯•æ•°æ®è¯´æ˜: A: ä¸‰ä½æ•°åŠ æ³•ï¼Œä¸¤ä½æ•°ä¹˜æ³• B: [dÉªfÉ™rÉ™nt], å¤åŸ \u0026ldquo;different,\u0026rdquo; C: ä» e l h l o å¤åŸ hello D: æ³¢æ–¯è¯­é—®ç­” E: é’ˆå¯¹GPT-3 å¯¹æŠ—æ ‡çš„é—®ç­” \u0026hellip; ç»“æœ è¿™äº› taskï¼Œä»¥ few-shot å½¢å¼å±•ç¤ºè¿‡ä»¥åï¼Œéƒ½æœ‰ emergent ä¸åŒæ¨¡å‹ emergent scale ä¸ä¸€æ · æœ‰çš„ taskï¼Œåªæœ‰ 540B çš„ PaLM emergeäº† å®éªŒ2 å¢å¼ºè¯­è¨€æ¨¡å‹èƒ½åŠ›çš„ emerge ç°è±¡ å·²çŸ¥çš„ä¸€äº›å¤§æ¨¡å‹æŠ€å·§åœ¨ä½•ç§è§„æ¨¡ä¸‹å‘æŒ¥ä½œç”¨ï¼Ÿ å¤§æ¨¡å‹æŠ€å·§ æ€ç»´é“¾ Chain-of-thought: Let\u0026rsquo;s think step by step. æŒ‡ä»¤å¾®è°ƒ è¯·å†™ä¸€æ®µXXXçš„æè¿° è‰ç¨¿æœ¬æ–¹æ³•ï¼š è®¡ç®— 15+16, è®©æ¨¡å‹åœ¨è‰ç¨¿æœ¬ä¸Šå†™â€œ5+6=11ï¼Œè¿›ä½1â€ è¿™äº›å¢å¼ºè¯­è¨€æ¨¡å‹èƒ½åŠ›çš„æ–¹æ³•éƒ½æœ‰ä¸€å®šç¨‹åº¦çš„æ¶Œç° è”æƒ³ï¼šä¹‹å‰çš„ prompt tuningï¼Œparameter efficient tuningï¼Œéƒ½æ˜¯æŸç§éšç€æ¨¡å‹è§„æ¨¡æ‰©å¤§çš„æ¶Œç°ï¼Ÿ è®¨è®º Emergent ç°è±¡çš„è§£é‡Š å¤šæ­¥èƒ½åŠ›è¯´ æ¯ä¸ªå­èƒ½åŠ›è¾¾åˆ° 90% -\u0026gt; ä¸€æ— æ˜¯å¤„ æ¯ä¸ªå­èƒ½åŠ›è¾¾åˆ° 95% -\u0026gt; èƒ½å®Œæˆä¸€äº›ä»»åŠ¡äº† æŒ‡æ ‡ç¼ºé™·è¯´ å¥‡æ€ªçš„ç°è±¡ï¼šäº¤å‰ç†µæŸå¤±ä¸æ˜¯ emergent çš„ï¼Œè€Œæ˜¯åœ¨é€æ­¥ä¸‹é™ Emergent çš„é˜ˆå€¼å¯èƒ½ä¼šè¶Šæ¥è¶Šå° æ›´å¹²å‡€çš„æ•°æ®ï¼Œæ›´å¥½çš„è®­ç»ƒæŠ€å·§ï¼Œæ›´ä¼˜ç§€çš„æ¨¡å‹ç»“æ„éƒ½å¯ä»¥æ˜¯ Emergenté˜ˆå€¼å˜å° æœªæ¥æ–¹å‘ï¼š ç»§ç»­æ‰©å¤§ model scaleï¼Œè¿œæœªè¾¾åˆ°ä¸Šé™ ä¸€äº›æ–°ç»“æ„çš„ scaling æ•°æ®çš„ scaling ç†è§£ prompt æœºåˆ¶ æ›´å‰æ²¿çš„ taskï¼Œç”¨æ¥æŒ‡å¯¼ emergent ç†è§£ emergence ğŸ“šè®ºæ–‡è´¡çŒ® ä¼˜ç‚¹ ç¬¬ä¸€æ¬¡æ­£å¼æå‡º emergent å®éªŒ åšäº†å……åˆ†çš„å®éªŒè¡¨æ˜è¯¥ç°è±¡åœ¨å„ç§æ•°æ®é›†ä¸Šå¹¿æ³›å­˜åœ¨ ç”šè‡³éªŒè¯äº†ä¸€äº›â€œæ–¹æ³•â€çš„æ¶Œç° æå‡ºäº†ä¸€äº›è§£é‡Šè¯¥ç°è±¡çš„è§‚ç‚¹ï¼Œå¹¶æå‡ºè´¨ç–‘ æ”¹è¿›ç‚¹ è¿˜æ˜¯ä¸çŸ¥é“ä¸ºå•¥ emerge å®éªŒé‡‡ç”¨å„ç§ä¸åŒæ¨¡å‹ï¼Œæ— æ³•å¾—å‡ºå“ªä¸ªè®¡ç®—é‡çº§å¯¹å“ªç§èƒ½åŠ›æœ‰ emerge å‚è€ƒ # æ¸…ååšå£«å¸¦ä½ æ€è€ƒå¤§è¯­è¨€æ¨¡å‹LLMçš„æ¶Œç°ç°è±¡ï¼ˆEmergentï¼‰ æœ‰è„‘å›¾ Emergent Abilities of Large Language Models ï¼ˆhttps://arxiv.org/abs/2206.07682ï¼‰\nå†è°ˆChatGPTç­‰å¤§æ¨¡å‹çš„æ¶Œç°èƒ½åŠ›ï¼šå…³äºæ¶Œç°èƒ½åŠ›çš„å®šä¹‰ã€æµ‹è¯•æ–¹æ³•åŠåˆ†æå·¥ä½œæ€»ç»“ "},{"id":26,"href":"/www6vAlgo/docs/LLM/Foundation-Models/decode-only/gptLlama/gptLlama/","title":"LLaMA","section":"decode-only","content":" LLaMA # LLaMA\n"},{"id":27,"href":"/www6vAlgo/docs/RL/Agentic-RL/Search/websailer/","title":"WebSailor","section":"Search","content":" è®ºæ–‡ # ã€ŠWebSailor: Navigating Super-human Reasoning for Web Agentã€‹é˜¿é‡Œå·´å·´é›†å›¢é€šä¹‰å®éªŒå®¤\nä¸»è¦ä»‹ç»äº†ä¸€ç§åä¸ºWebSailorçš„æ–°å‹ç½‘é¡µæ™ºèƒ½ä½“ï¼ˆWeb Agentï¼‰ï¼Œå…¶åœ¨å¤æ‚ä¿¡æ¯å¯»æ±‚ä»»åŠ¡ä¸­å±•ç°äº†è¶…è¶Šäººç±»çš„æ¨ç†èƒ½åŠ›ã€‚ ä»¥ä¸‹æ˜¯å¯¹æ–‡æ¡£çš„æ·±åº¦é˜…è¯»æ€»ç»“ï¼Œæ¶µç›–å…¶æ ¸å¿ƒé—®é¢˜ã€æ–¹æ³•ã€å®éªŒåŠè´¡çŒ®ã€‚\nä¸€ã€ç ”ç©¶èƒŒæ™¯ä¸é—®é¢˜å®šä¹‰ # 1.1 ä¿¡æ¯å¯»æ±‚çš„æŒ‘æˆ˜ # äº’è”ç½‘æ—¶ä»£çš„ä¿¡æ¯çˆ†ç‚¸è¶…è¶Šäº†äººç±»è®¤çŸ¥æé™ï¼ˆæœ‰é™è®°å¿†ã€è„†å¼±æ³¨æ„åŠ›ã€æ— æ³•å¹¶è¡Œæ¢ç´¢ï¼‰ã€‚ ä¸“æœ‰æ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆå¦‚OpenAIçš„Deep Researchï¼‰å·²å±•ç°å‡ºè¶…è¶Šäººç±»çš„æ€§èƒ½ï¼Œä½†å¼€æºæ™ºèƒ½ä½“ä»å­˜åœ¨å·¨å¤§æ€§èƒ½å·®è·ã€‚ 1.2 ä»»åŠ¡åˆ†çº§ # è®ºæ–‡å°†ä¿¡æ¯å¯»æ±‚ä»»åŠ¡åˆ†ä¸ºä¸‰ä¸ªçº§åˆ«ï¼š\nLevel 1ï¼šä½ä¸ç¡®å®šæ€§ä»»åŠ¡ï¼ˆå¦‚å•æ¬¡æœç´¢å³å¯è§£å†³ï¼‰ã€‚ Level 2ï¼šé«˜åˆå§‹ä¸ç¡®å®šæ€§ä½†è§£å†³è·¯å¾„æ¸…æ™°ï¼ˆå¦‚æ ‡å‡†å¤šè·³é—®ç­”ï¼‰ã€‚ Level 3ï¼ˆæœ¬æ–‡ç„¦ç‚¹ï¼‰ï¼šé«˜ä¸ç¡®å®šæ€§ä¸”è§£å†³è·¯å¾„å¤æ‚ã€æ— é¢„å®šä¹‰è·¯å¾„ï¼ˆå¦‚BrowseCompåŸºå‡†ä¸­çš„ä»»åŠ¡ï¼‰ã€‚ 1.3 æ€§èƒ½å·®è·æ ¹æº # ç°æœ‰è®­ç»ƒèŒƒå¼é›†ä¸­äºLevel 1â€“2ä»»åŠ¡ï¼Œç¼ºä¹å¯¹Level 3å¤æ‚æ¨ç†æ¨¡å¼çš„æš´éœ²ï¼Œå¯¼è‡´æ¨¡å‹æ— æ³•å‘å±•å‡ºå¤šæ­¥æ¨ç†èƒ½åŠ›ã€‚\näºŒã€æ ¸å¿ƒæ–¹æ³•ï¼šWebSailoræ¡†æ¶ # 2.1 è®­ç»ƒæ•°æ®åˆæˆï¼ˆSailorFog-QAï¼‰ # a) æ„å»ºå¤æ‚çŸ¥è¯†å›¾ # é€šè¿‡éšæœºæ¸¸èµ°ä»çœŸå®ç½‘ç«™ä¸­æå–äº’è”çš„çŸ¥è¯†ç»“æ„ï¼Œç”Ÿæˆå…·æœ‰æ¶Œç°å¼éçº¿æ€§ç»“æ„çš„å›¾ã€‚ b) ç”Ÿæˆé«˜ä¸ç¡®å®šæ€§é—®é¢˜ # é‡‡æ ·å¤šæ ·åŒ–æ‹“æ‰‘çš„å­å›¾ï¼ˆåŒ…å«æ–°é¢–çš„å®ä½“ä¸å…³ç³»ç»„åˆï¼‰ã€‚ ä¿¡æ¯æ¨¡ç³ŠåŒ–å¤„ç†ï¼ˆå¦‚å°†ç²¾ç¡®æ—¥æœŸè½¬ä¸ºâ€œ2010å¹´ä»£åˆâ€ï¼Œåç§°éƒ¨åˆ†æ©ç ç­‰ï¼‰ï¼Œå¼ºåˆ¶æ™ºèƒ½ä½“è¿›è¡Œæ¨ç†è€Œéç®€å•æŸ¥æ‰¾ã€‚ c) ä¼˜åŠ¿ # æ•°æ®åŸºäºçœŸå®äº’è”ç½‘ï¼Œè´´åˆå®é™…æŒ‘æˆ˜ã€‚ å­å›¾æ‹“æ‰‘å¤šæ ·æ€§è‡ªç„¶äº§ç”Ÿéœ€å¤æ‚æ¨ç†æ¨¡å¼ï¼ˆå¤šæ­¥æ¼”ç»ã€ç»„åˆä¸æ¯”è¾ƒåˆ†æï¼‰çš„é—®é¢˜ã€‚ é«˜åº¦å¯æ‰©å±•ï¼ˆå­å›¾æ•°é‡éšå›¾è§„æ¨¡éçº¿æ€§å¢é•¿ï¼‰ã€‚ 2.2 æ¨ç†è½¨è¿¹é‡å»º # a) é—®é¢˜ # å¼€æºå¤§å‹æ¨ç†æ¨¡å‹ï¼ˆLRMï¼Œå¦‚QwQã€DeepSeek-R1ï¼‰èƒ½ç”Ÿæˆæ­£ç¡®è½¨è¿¹ï¼Œä½†å…¶åŸç”Ÿæ¨ç†è¾“å‡ºå†—é•¿ã€é£æ ¼åŒ–ï¼Œç›´æ¥ç”¨äºå¾®è°ƒä¼šé™åˆ¶æ™ºèƒ½ä½“çš„æ¢ç´¢ç­–ç•¥æ³›åŒ–èƒ½åŠ›ï¼Œä¸”é•¿è½¨è¿¹æ˜“è¶…å‡ºä¸Šä¸‹æ–‡çª—å£é™åˆ¶ã€‚\nb) è§£å†³æ–¹æ¡ˆ # ç”¨LRMç”Ÿæˆå®Œæ•´åŠ¨ä½œ-è§‚å¯Ÿåºåˆ—ï¼ˆä¸¢å¼ƒåŸç”Ÿå†—é•¿æ€è€ƒï¼‰ã€‚ ç”¨å¦ä¸€æŒ‡ä»¤éµå¾ªæ¨¡å‹ï¼ˆå¦‚Qwen-2.5-72Bï¼‰ä¸ºæ¯ä¸€æ­¥åŠ¨ä½œé‡å»ºç®€æ´ã€ç›®æ ‡å¯¼å‘çš„æ€è€ƒï¼ˆâ€œçŸ­é“¾æ€ç»´â€é£æ ¼ï¼‰ï¼Œå½¢æˆé«˜è´¨é‡ç›‘ç£ä¿¡å·ã€‚ 2.3 è®­ç»ƒæµç¨‹ä¼˜åŒ– # a) å†·å¯åŠ¨ï¼ˆRFTï¼‰ # å¿…è¦æ€§ï¼šRLå¥–åŠ±ç¨€ç–ï¼ˆåˆå§‹è¿‘é›¶åé¦ˆï¼‰ï¼Œä¸”è’¸é¦ä¾èµ–ä½ï¼ˆä»…éœ€2k+é«˜è´¨é‡æ ·æœ¬ï¼‰ã€‚ è¿‡æ»¤ï¼šä¿ç•™æ­£ç¡®è½¨è¿¹ã€é•¿åº¦ï¼œ32k tokenã€å·¥å…·è°ƒç”¨ï¼5æ¬¡ï¼ˆç¡®ä¿å¤æ‚æ€§ï¼‰ã€‚ è®­ç»ƒç›®æ ‡ï¼šå¢å¼ºå†³ç­–èƒ½åŠ›ï¼ˆæ©ç ç¯å¢ƒè§‚å¯Ÿçš„æŸå¤±è®¡ç®—ï¼‰ã€‚ b) å¼ºåŒ–å­¦ä¹ ï¼ˆDUPOç®—æ³•ï¼‰ # æŒ‘æˆ˜ï¼šå¤šè½®æ¨ç†ä¸å·¥å…·ä½¿ç”¨å¯¼è‡´è®­ç»ƒç¼“æ…¢ã€‚ åˆ›æ–°ï¼šå¤åˆ¶é‡‡æ ·ç­–ç•¥ä¼˜åŒ–ï¼ˆè®­ç»ƒå‰è¿‡æ»¤å…¨æ­£ç¡®æ ·æœ¬ï¼Œè®­ç»ƒä¸­å¤åˆ¶åŒä¸€æ‰¹æ¬¡å†…æ ‡å‡†å·®éé›¶çš„æ ·æœ¬ï¼‰ï¼Œæé€Ÿ2â€“3å€ã€‚ å¥–åŠ±è®¾è®¡ï¼šç»“åˆæ ¼å¼éªŒè¯ï¼ˆ0.1æƒé‡ï¼‰å’Œç­”æ¡ˆéªŒè¯ï¼ˆ0.9æƒé‡ï¼‰ï¼Œé¿å…å¥–åŠ±é»‘å®¢ã€‚ ä¸‰ã€å®éªŒç»“æœ # 3.1 åŸºå‡†æµ‹è¯• # BrowseComp-en/zhï¼šæœ€å…·æŒ‘æˆ˜æ€§çš„ç½‘é¡µæµè§ˆåŸºå‡†ï¼Œéœ€å¤æ‚ç­–ç•¥ã€‚ GAIAï¼šéœ€å¤šæ¨¡æ€ä¸å·¥å…·ä½¿ç”¨ï¼ˆä»…ç”¨æ–‡æœ¬å­é›†ï¼‰ã€‚ Xbench-DeepSearchï¼šåŠ¨æ€æ·±åº¦æœç´¢åŸºå‡†ã€‚ 3.2 æ€§èƒ½å¯¹æ¯” # WebSailorï¼ˆ3B/7B/32B/72Bï¼‰åœ¨æ‰€æœ‰å¼€æºæ¨¡å‹ä¸æ™ºèƒ½ä½“æ–¹æ³•ä¸­é¢†å…ˆï¼Œä¸”è¶…è¶Šéƒ¨åˆ†ç»“åˆæµè§ˆèƒ½åŠ›çš„ä¸“æœ‰LRMï¼ˆå¦‚Grok-3ã€Doubaoï¼‰ã€‚ WebSailor-72Båœ¨BrowseComp-zhä¸Šä¸DoubaoæŒå¹³ï¼Œè™½ä»è½åäºDeepResearchï¼ˆSOTAï¼‰ï¼Œä½†æ˜¾è‘—ç¼©å°äº†å¼€æºä¸ä¸“æœ‰ç³»ç»Ÿçš„å·®è·ã€‚ å‘ä¸‹å…¼å®¹æ€§ï¼šåœ¨ç®€å•ä»»åŠ¡ï¼ˆå¦‚SimpleQAï¼‰ä¸Šä¹Ÿè¡¨ç°ä¼˜å¼‚ã€‚ 3.3 å…³é”®åˆ†æ # æ•°æ®å¤æ‚æ€§ï¼šSailorFog-QAçš„å·¥å…·è°ƒç”¨åˆ†å¸ƒä¸BrowseComp-ené«˜åº¦ç›¸ä¼¼ï¼ˆé•¿å°¾ã€å¤šï¼5æ¬¡è°ƒç”¨ï¼‰ï¼Œè€ŒWebDanceræ•°æ®é›†ä¸­ï¼50%ä»…éœ€2æ¬¡è°ƒç”¨ã€‚ RLæœ‰æ•ˆæ€§ï¼šRLè®­ç»ƒæ˜¾è‘—æå‡Pass@1æ€§èƒ½ï¼ˆå°¤å…¶BrowseCompï¼‰ï¼Œå¢å¼ºæ ·æœ¬æ•ˆç‡ä¸ç¨³å®šæ€§ã€‚ å†·å¯åŠ¨å¿…è¦æ€§ï¼šæ— å†·å¯åŠ¨çš„RLæ¨¡å‹å·¥å…·è°ƒç”¨æ•°æ›´ä½ï¼Œæ— æ³•æŒæ¡é•¿è§†è·æ¨ç†ï¼Œæ€§èƒ½å·®è·å¤§ã€‚ å››ã€å±€é™ä¸æœªæ¥å·¥ä½œ # ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶ï¼ˆ32k tokenï¼‰å¯èƒ½åˆ¶çº¦æ›´å¤æ‚é—®é¢˜çš„è§£å†³ã€‚ è¿‡åº¦æ€è€ƒå€¾å‘ï¼šå¯¹ç®€å•é—®é¢˜ä¹Ÿè¿›è¡Œå¤šæ­¥å·¥å…·è°ƒç”¨ï¼ˆä½†å¸¸ä¸ºäº¤å‰éªŒè¯ï¼Œéæ— æ„ä¹‰æ¢ç´¢ï¼‰ã€‚ è®­ç»ƒæ•ˆç‡ï¼šåŒæ­¥RLæ¡†æ¶ä½æ•ˆï¼ˆä»…50æ­¥ï¼‰ï¼Œæœªæ¥å°†è½¬å‘å¼‚æ­¥è®­ç»ƒã€‚ äº”ã€ç»“è®º # WebSailoré€šè¿‡åˆæˆé«˜ä¸ç¡®å®šæ€§æ•°æ®ã€é‡å»ºç®€æ´æ¨ç†è½¨è¿¹ã€ä»¥åŠRFTå†·å¯åŠ¨ä¸DUPOç®—æ³•ï¼Œå®ç°äº†å¼€æºæ™ºèƒ½ä½“åœ¨å¤æ‚ä¿¡æ¯å¯»æ±‚ä»»åŠ¡ä¸Šçš„çªç ´æ€§è¿›å±•ï¼Œè¯æ˜äº†å¼€æºæ¨¡å‹å¯è¾¾åˆ°æ¥è¿‘ä¸“æœ‰ç³»ç»Ÿçš„æ€§èƒ½ã€‚æœªæ¥å°†ç»§ç»­æ¢ç´¢æ›´å¤æ‚ä»»åŠ¡ä¸é«˜æ•ˆRLè®­ç»ƒï¼Œä»¥è¿½æ±‚æ›´å¹¿æ³›çš„â€œè¶…äººç±»â€æ€§èƒ½ã€‚\né™„å½•ä¸æ¡ˆä¾‹ # æ–‡æ¡£è¿˜æä¾›äº†ï¼š\nå·¥å…·ç»†èŠ‚ï¼ˆsearchã€visitï¼‰ï¼› QAæ„å»ºæµç¨‹ï¼› è®­ç»ƒè¶…å‚æ•°ï¼› å®Œæ•´è½¨è¿¹æ¡ˆä¾‹ï¼ˆå¦‚BrowseComp-enä¸­å…³äºJoey Hessçš„æŸ¥è¯¢ï¼‰ï¼Œå±•ç¤ºå¤šæ­¥æ¨ç†ä¸å·¥å…·è°ƒç”¨çš„å®é™…åº”ç”¨ã€‚ æ€»ç»“ # è¯¥ç ”ç©¶åœ¨æ•°æ®åˆæˆã€æ¨ç†é‡å»ºå’Œè®­ç»ƒä¼˜åŒ–æ–¹é¢å‡æœ‰æ˜¾è‘—åˆ›æ–°ï¼Œä¸ºå¼€æºç¤¾åŒºæä¾›äº†å¯å¤ç°çš„é«˜æ€§èƒ½ç½‘é¡µæ™ºèƒ½ä½“æ–¹æ¡ˆï¼Œæ¨åŠ¨äº†å¯¹â€œè¶…äººç±»æ¨ç†â€èƒ½åŠ›çš„æ¢ç´¢ã€‚\nå‚è€ƒ # æœ¬æ–‡ç”±å…ƒå®ç”Ÿæˆ\nAgentæ™ºèƒ½ä½“ | æ·±å…¥è§£è¯»é˜¿é‡Œå¼€æºWeb Agentæ–°ç‹è€…ï¼šWebSailor\n"},{"id":28,"href":"/www6vAlgo/docs/RL/core/RewardModel/","title":"(åŸç†|å®ç°)PPO-RewardModel","section":"Core","content":"\nPPO-RewardModel # (åŸç†|å®ç°)PPO-RewardModel\n"},{"id":29,"href":"/www6vAlgo/docs/DeepLearning/basic/DeeplearningLoss/","title":"(åŸç†\u0026å®æˆ˜)äº¤å‰ç†µæŸå¤±","section":"basic","content":"\näº¤å‰ç†µæŸå¤± # (åŸç†\u0026amp;å®æˆ˜)äº¤å‰ç†µæŸå¤±\n"},{"id":30,"href":"/www6vAlgo/docs/DeepLearning/%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96/DeeplearningNorm/","title":"è§„èŒƒåŒ– Norm","section":"ç½‘ç»œä¼˜åŒ–","content":"\nNorm ä½œç”¨[1] # dnn çš„æ ‡å‡†ç»„ä»¶ï¼Œç¨³å®šå’ŒåŠ é€Ÿè®­ç»ƒè¿‡ç¨‹\nBatch Norm[1] # reduce cross batch size mini-batch dimension ä¸€èˆ¬ç”¨äºå›¾åƒï¼Œä¸æ¶‰åŠåˆ°paddingçš„é—®é¢˜ï¼›\nLayer Norm[1] # reduce cross hidden dim reduce across the feature dimension. ä¸€èˆ¬ç”¨äºåºåˆ—ï¼Œä¸€ä¸ª batch size å†…å­˜åœ¨ paddingï¼›\nRMSNorm: å¯¹ LN çš„ä¸€ç§å˜ä½“ï¼Œllama ğŸ’¡ https://spaces.ac.cn/archives/9009 Pre LN: llama Post LN: attention is all you need llamaåœ¨å·¥ç¨‹ä¸Šä½¿ç”¨Pre LN\n[pytorch] BNã€LNã€RMSNorm åŠ pre LN vs. post LN å¯¹æ¯”ï¼Œæ ‡å‡†åŒ– v *** â€‹\tnormalization.ipynb\nâ€‹\t[pytorch] BNã€LNã€RMSNorm åŠ pre LN vs. post LN å¯¹æ¯”ï¼Œæ ‡å‡†åŒ– 1xx. Batch Normalization, Layer Normalization and Root Mean Square Layer Normalization: A Comprehensive Guide with Python Implementations\ntodo\n7.5 é€å±‚è§„èŒƒåŒ– ç™¾åº¦é‚± æœ‰ä»£ç \nhttps://aistudio.baidu.com/education/lessonvideo/3048901\n"},{"id":31,"href":"/www6vAlgo/docs/DeepLearning/Transformer/ModelGQA/","title":"(åŸç†)GQA","section":"Transformer","content":"\nè®ºæ–‡ # GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints\nMHA vs. MQA vs. GQA [1] # MHA # é¦–å…ˆæ˜¯åŸå§‹çš„ MHA(Multi-Head Attention)ï¼ŒQKV ä¸‰éƒ¨åˆ†æœ‰ç›¸åŒæ•°é‡çš„å¤´ï¼Œä¸”ä¸€ä¸€å¯¹åº”ã€‚æ¯æ¬¡åš Attentionï¼Œhead1 çš„ QKV å°±åšå¥½è‡ªå·±è¿ç®—å°±å¯ä»¥ï¼Œè¾“å‡ºæ—¶å„ä¸ªå¤´åŠ èµ·æ¥å°±è¡Œã€‚\nMQA # è€Œ MQA åˆ™æ˜¯ï¼Œè®© Q ä»ç„¶ä¿æŒåŸæ¥çš„å¤´æ•°ï¼Œä½† K å’Œ V åªæœ‰ä¸€ä¸ªå¤´ï¼Œç›¸å½“äºæ‰€æœ‰çš„ Q å¤´å…±äº«ä¸€ç»„ K å’Œ V å¤´ï¼Œæ‰€ä»¥å«åš Multi-Query äº†ã€‚å®ç°æ”¹å˜äº†ä¼šä¸ä¼šå½±å“æ•ˆæœå‘¢ï¼Ÿç¡®å®ä¼šå½±å“ä½†ç›¸å¯¹å®ƒèƒ½å¸¦æ¥çš„æ”¶ç›Šï¼Œæ€§èƒ½çš„äº›å¾®é™ä½æ˜¯å¯ä»¥æ¥å—çš„ã€‚\nèƒ½å¸¦æ¥å¤šå¤§çš„æ”¶ç›Šå‘¢ï¼Œå®éªŒå‘ç°ä¸€èˆ¬èƒ½æé«˜ 30%-40% çš„ååã€‚\næ”¶ç›Šä¸»è¦å°±æ˜¯ç”±é™ä½äº† KV cache å¸¦æ¥çš„ã€‚å®é™…ä¸Š MQA è¿ç®—é‡å’Œ MHA æ˜¯å·®ä¸å¤šçš„ï¼Œå¯ç†è§£ä¸ºè¯»å–ä¸€ç»„ KV å¤´ä¹‹åï¼Œç»™æ‰€æœ‰ Q å¤´ç”¨ï¼Œä½†å› ä¸ºä¹‹å‰æåˆ°çš„å†…å­˜å’Œè®¡ç®—çš„ä¸å¯¹ç§°ï¼Œæ‰€ä»¥æ˜¯æœ‰åˆ©çš„ã€‚\nGQA # è€Œ GQA å‘¢ï¼Œæ˜¯ MHA å’Œ MQA çš„æŠ˜è¡·æ–¹æ¡ˆï¼Œæ—¢ä¸æƒ³æŸå¤±æ€§èƒ½å¤ªå¤šï¼Œåˆæƒ³è·å¾— MQA å¸¦æ¥çš„æ¨ç†åŠ é€Ÿå¥½å¤„ã€‚å…·ä½“æ€æƒ³æ˜¯ï¼Œä¸æ˜¯æ‰€æœ‰ Q å¤´å…±äº«ä¸€ç»„ KVï¼Œè€Œæ˜¯åˆ†ç»„ä¸€å®šå¤´æ•° Q å…±äº«ä¸€ç»„ KVï¼Œæ¯”å¦‚ä¸Šé¢å›¾ç‰‡å°±æ˜¯ä¸¤ç»„ Q å…±äº«ä¸€ç»„ KVã€‚\nMQA å’Œ GQA å½¢å¼åœ¨æ¨ç†åŠ é€Ÿæ–¹é¢ï¼Œä¸»è¦æ˜¯é€šè¿‡ä¸¤æ–¹é¢æ¥å®Œæˆï¼š\né™ä½äº†ä»å†…å­˜ä¸­è¯»å–çš„æ•°æ®é‡ï¼Œæ‰€ä»¥ä¹Ÿå°±å‡å°‘äº†è®¡ç®—å•å…ƒç­‰å¾…æ—¶é—´ï¼Œæé«˜äº†è®¡ç®—åˆ©ç”¨ç‡ï¼› KV cache å˜å°äº† head_num å€ï¼Œä¹Ÿå°±æ˜¯æ˜¾å­˜ä¸­éœ€è¦ä¿å­˜çš„ tensor å˜å°äº†ï¼Œç©ºå‡ºæ¥ç©ºé—´å°±å¯ä»¥åŠ å¤§ batch sizeï¼Œä»è€Œåˆèƒ½æé«˜åˆ©ç”¨ç‡ã€‚ å¦‚æœè¦ç”¨ MQA å’Œ GQAï¼Œå¯ä»¥æ˜¯ä»å¤´è®­ç»ƒçš„æ—¶å€™å°±åŠ ä¸Šï¼Œä¹Ÿå¯ä»¥åƒ GQA è®ºæ–‡é‡Œé¢ä¸€æ ·ï¼Œç”¨å·²æœ‰çš„å¼€æºæ¨¡å‹ï¼ŒæŒ‘ä¸€äº›å¤´å–ä¸ª mean ç”¨æ¥åˆå§‹åŒ– MQA æˆ– GQA ç»§ç»­è®­ç»ƒä¸€æ®µæ—¶é—´ã€‚\nGQA \u0026amp; MQA [2] # å›¾ 4.1 Multi-head attention æ‹¥æœ‰ H ä¸ªæŸ¥è¯¢ã€é”®å’Œå€¼å¤´ã€‚Multi-query attention åœ¨æ‰€æœ‰ æŸ¥è¯¢å¤´ä¹‹é—´å…±äº«å•ä¸ªé”®å’Œå€¼å¤´ã€‚Grouped-query attention åˆ™åœ¨æ¯ä¸ªæŸ¥è¯¢å¤´ç»„ä¹‹é—´å…±äº«å• ä¸ªé”®å’Œå€¼å¤´ï¼Œä»è€Œåœ¨å¤šå¤´å’Œå¤šæŸ¥è¯¢æ³¨æ„åŠ›ä¹‹é—´è¿›è¡Œæ’å€¼ã€‚\nFig. 4.1 Multi-head attention has H query, key, and value heads. Multi-query attention shares single key and value heads across all query heads. Grouped-query attention instead shares single key and value heads for each group of query heads, interpolating between multi-head and multi-query attention.\nå‚è€ƒ # ä¸ºä»€ä¹ˆç°åœ¨å¤§å®¶éƒ½åœ¨ç”¨ MQA å’Œ GQAï¼Ÿ ***\nLLMå­¦ä¹ ç³»åˆ—1ï¼šå¤§æ¨¡å‹æ¶æ„è¦ç‚¹æ€»ç»“ ä¸»æµå¤§è¯­è¨€æ¨¡å‹çš„æŠ€æœ¯åŸç†ç»†èŠ‚ *** è…¾è®¯ [æ¶æ„] + è®­ç»ƒ + å¾®è°ƒ\n1xx. ç†è§£Attention:ä»èµ·æºåˆ°MHA,MQAå’ŒGQA *** 1xx. æ·±åº¦è§£æGroup Query Attention(GQA)ä¸ºä»€ä¹ˆèƒ½ç»™LLM decoderå¸¦æ¥æå¤§æ¨ç†åŠ é€Ÿ 1xx. æ·±åº¦å­¦ä¹ ä¸­çš„æ³¨æ„åŠ›æœºåˆ¶ï¼šMHAã€MQAå’ŒGQA\n1xx. ã€ç ”1åŸºæœ¬åŠŸ ï¼ˆçœŸçš„å¾ˆç®€å•ï¼‰Group Query-Attentionã€‘å¤§æ¨¡å‹è®­ç»ƒå¿…å¤‡æ–¹æ³•â€”â€”bonus(ä½ç½®ç¼–ç è®²è§£) v *** Nomolization[post, pre, sandwich] + Position Encoding[RoPE] + GQAä»£ç  1xx. ä¸€æ–‡é€šé€å„ç§æ³¨æ„åŠ›ï¼šä»å¤šå¤´æ³¨æ„åŠ›MHAåˆ°åˆ†ç»„æŸ¥è¯¢æ³¨æ„åŠ›GQAã€å¤šæŸ¥è¯¢æ³¨æ„åŠ›MQA åˆ é™¤\næ‰‹å†™å¤§æ¨¡å‹ç»„ä»¶ä¹‹Group Query Attentionï¼Œä» MHAï¼ŒMQA åˆ° GQA\n"},{"id":32,"href":"/www6vAlgo/docs/LLM/Foundation-Models/decode-only/gptLlamaFamily/gptLlamaFamily/","title":"LLaMA å®¶æ—","section":"decode-only","content":" LLaMA å®¶æ—[1] # é¡¹ç›® æè¿° æ•°æ®é›† LLaMa åŸºåº§æ¨¡å‹ å…¬å¼€å¯ç”¨çš„æ•°æ®é›†(1T token) Stanford Alpaca ç»“åˆè‹±æ–‡è¯­æ–™é€šè¿‡Self Instructæ–¹å¼å¾®è°ƒLLaMA 7B Self Instruct from davinci-003 API(52K) Vicuna-13B é€šè¿‡ShareGPT.comçš„7ä¸‡æ¡å¯¹è¯æ•°æ®å¾®è°ƒLLaMA(AlpacaåŸºç¡€ä¹‹ä¸Š, å¤šè½®å¯¹è¯å’Œé•¿åºåˆ—, full fine-tune) ç”¨æˆ·å…±äº«å¯¹è¯(70K sample) BELLE ç»“åˆä¸­æ–‡è¯­æ–™é€šè¿‡Self Instructæ–¹å¼å¾®è°ƒBLOOMZ-7Bæˆ–LLaMA Chinese-LLaMA/Chinese-Alpaca é€šè¿‡ä¸­æ–‡æ•°æ®é¢„è®­ç»ƒ/æŒ‡ä»¤å¾®è°ƒLLaMA å§œå­ç‰™ç³»åˆ—æ¨¡å‹Ziya-LLaMA-13B-v1 åŸºäºLLaMA-13Bçš„ä¸­è‹±æ–‡æ¨¡å‹ ChatLLaMA(è‹±æ–‡ç‰ˆ) LLaMAçš„RLHFç‰ˆ ColossalChat é€šè¿‡self-instructæŠ€æœ¯æŒ‡ä»¤å¾®è°ƒLLaMAä¸”åŠ ä¸ŠRLHF {% asset_img \u0026rsquo;llama2-famaly.jpg\u0026rsquo; %}\nå‚è€ƒ # å®¶æ— # LLaMAçš„è§£è¯»ä¸å…¶å¾®è°ƒï¼šAlpaca-LoRA/Vicuna/BELLE/ä¸­æ–‡LLaMA/å§œå­ç‰™/LLaMA 2 *** 1xx. æˆ‘æƒ³å­¦å¤§æ¨¡å‹ï¼Œåº”è¯¥ä»å“ªä¸ªæ¨¡å‹å¼€å§‹ï¼ŸLLaMAç”Ÿæ€å®¶è°±æ•´ç†å’Œåˆ†æ 1xx. NLPï¼ˆä¹ï¼‰ï¼šLLaMA, Alpaca, ColossalChat ç³»åˆ—æ¨¡å‹ç ”ç©¶\n1xx. \u0026laquo;åƒå¸†å¢å¼ºç‰ˆ Llama 2-æå‡å¤§æ¨¡å‹å¯¹è¯æŒ‡ä»¤éµå¾ªèƒ½åŠ›\u0026raquo; v\n1xx. è¿‘æœŸå¤§æ¨¡å‹åŠ¨æ€ï¼šLLaMA-2-7B-32Kçš„è®­ç»ƒæ•°æ®ç»„ç»‡æƒ…å†µåŠé¢å‘å„¿ç«¥å¿ƒç†å¥åº·é¢†åŸŸçš„å¾®è°ƒæ¨¡å‹æ¨ä»‹ llama-2-7b-32k - LLaMA-2çš„ä¸Šä¸‹æ–‡é•¿åº¦ä¸º4Ktokenã€‚è¦å°†å…¶æ‰©å±•åˆ°32Kä¸Šä¸‹æ–‡ï¼Œè¯¥å·¥ä½œåˆ†æˆäº†ä¸‰ä¸ªéƒ¨åˆ†ï¼šå»ºæ¨¡ã€æ•°æ®å’Œç³»ç»Ÿä¼˜åŒ–ã€‚\nå®æˆ˜ # 1xx. ä»0åˆ°1å¤ç°æ–¯å¦ç¦ç¾Šé©¼ï¼ˆStanford Alpaca 7Bï¼‰ GPUs: 8 å¡ A800 80GB GPUs\næ±‰åŒ– # 1xx. æ˜åŠ›è®¡åˆ’ 23 æœŸ-Linly-Chinese-LLaMA2 ä¸­æ–‡å¼€æºå¤§æ¨¡å‹æ–¹æ¡ˆåˆ†äº« v\n"},{"id":33,"href":"/www6vAlgo/docs/LLM/core/gptHallucination/","title":"(åŸç†)å¹»è§‰é—®é¢˜","section":"core","content":" å¹»è§‰[3] # Hallucination in large language models usually refers to the model generating unfaithful, fabricated, inconsistent, or nonsensical content. As a term, hallucination has been somewhat generalized to cases when the model makes mistakes. Here, I would like to narrow down the problem of hallucination to cases where the model output is fabricated and not grounded by either the provided context or world knowledge. å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„å¹»è§‰é€šå¸¸æ˜¯æŒ‡æ¨¡å‹ç”Ÿæˆä¸å¿ å®ã€æé€ ã€ä¸ä¸€è‡´æˆ–æ— æ„ä¹‰çš„å†…å®¹ã€‚ä½œä¸ºä¸€ä¸ªæœ¯è¯­ï¼Œå¹»è§‰åœ¨æŸç§ç¨‹åº¦ä¸Šè¢«æ¨å¹¿åˆ°æ¨¡å‹çŠ¯é”™çš„æƒ…å†µã€‚åœ¨è¿™é‡Œï¼Œæˆ‘æƒ³å°†å¹»è§‰é—®é¢˜ç¼©å°åˆ°æ¨¡å‹è¾“å‡ºæ˜¯æé€ çš„ï¼Œ è€Œä¸æ˜¯åŸºäºæ‰€æä¾›çš„ä¸Šä¸‹æ–‡æˆ–ä¸–ç•ŒçŸ¥è¯†çš„æƒ…å†µã€‚\nThere are two types of hallucination: å¹»è§‰æœ‰ä¸¤ç§ç±»å‹ï¼š\nIn-context hallucination: The model output should be consistent with the source content in context. ä¸Šä¸‹æ–‡å¹»è§‰ï¼šæ¨¡å‹è¾“å‡ºåº”ä¸ä¸Šä¸‹æ–‡ä¸­çš„æºå†…å®¹ä¸€è‡´ã€‚ Extrinsic hallucination: The model output should be grounded by the pre-training dataset. However, given the size of the pre-training dataset, it is too expensive to retrieve and identify conflicts per generation. If we consider the pre-training data corpus as a proxy for world knowledge, we essentially try to ensure the model output is factual and verifiable by external world knowledge. Equally importantly, when the model does not know about a fact, it should say so. å¤–åœ¨å¹»è§‰ï¼šæ¨¡å‹è¾“å‡ºåº”ä»¥è®­ç»ƒå‰æ•°æ®é›†ä¸ºåŸºç¡€ã€‚ä½†æ˜¯ï¼Œè€ƒè™‘åˆ°é¢„è®­ç»ƒæ•°æ®é›†çš„å¤§å°ï¼Œæ£€ç´¢å’Œè¯†åˆ«æ¯ä»£å†²çªçš„æˆæœ¬å¤ªé«˜ã€‚å¦‚æœæˆ‘ä»¬å°†é¢„è®­ç»ƒæ•°æ®è¯­æ–™åº“è§†ä¸ºä¸–ç•ŒçŸ¥è¯†çš„ä»£ç†ï¼Œæˆ‘ä»¬åŸºæœ¬ä¸Šä¼šå°è¯•ç¡®ä¿æ¨¡å‹è¾“å‡ºæ˜¯çœŸå®çš„ï¼Œå¹¶ä¸”å¯ä»¥é€šè¿‡å¤–éƒ¨ä¸–ç•ŒçŸ¥è¯†è¿›è¡ŒéªŒè¯ã€‚åŒæ ·é‡è¦çš„æ˜¯ï¼Œå½“æ¨¡å‹ä¸çŸ¥é“æŸä¸ªäº‹å®æ—¶ï¼Œå®ƒåº”è¯¥è¿™ä¹ˆè¯´ã€‚ Anti-Hallucination Methods[3] # RAG â†’ Edits and Attribution # Self-RAG (â€œSelf-reflective retrieval-augmented generationâ€; Asai et al. 2024) trains a LM end-to-end to learn to reflect on its own generation by outputting both task output and intermittent special reflection tokens. They created a supervision dataset for a critic model and a generator model by prompting GPT-4 and then distilled that into an in-house model to reduce inference cost. Self-RAGï¼ˆâ€œè‡ªåå°„æ£€ç´¢å¢å¼ºä¸€ä»£â€;Asai ç­‰äººï¼Œ2024 å¹´ï¼‰é€šè¿‡è¾“å‡ºä»»åŠ¡è¾“å‡ºå’Œé—´æ­‡æ€§ç‰¹æ®Šåå°„ä»¤ç‰Œ ï¼Œç«¯åˆ°ç«¯è®­ç»ƒ LM ä»¥å­¦ä¹ åå°„è‡ªå·±çš„ç”Ÿæˆã€‚ä»–ä»¬é€šè¿‡æç¤º GPT-4 ä¸º critic æ¨¡å‹å’Œç”Ÿæˆå™¨æ¨¡å‹åˆ›å»ºäº†ä¸€ä¸ªç›‘ç£æ•°æ®é›†ï¼Œç„¶åå°†å…¶æç‚¼æˆå†…éƒ¨æ¨¡å‹ä»¥é™ä½æ¨ç†æˆæœ¬ã€‚\nChain of Actions # Without grounding by external retrieved knowledge, we can design a process for using the model itself to do verification and revision to reduce hallucination. åœ¨æ²¡æœ‰å¤–éƒ¨æ£€ç´¢çŸ¥è¯†çš„åŸºç¡€çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥è®¾è®¡ä¸€ä¸ªæµç¨‹ï¼Œä½¿ç”¨æ¨¡å‹æœ¬èº«è¿›è¡ŒéªŒè¯å’Œä¿®æ”¹ï¼Œä»¥å‡å°‘å¹»è§‰ã€‚\nDhuliawala et al. (2023) proposed a method named Chain-of-Verification (CoVe) based on a chain of actions to plan and execute verification. [10] Dhuliawala ç­‰äººï¼ˆ2023 å¹´ï¼‰ æå‡ºäº†ä¸€ç§åä¸ºéªŒè¯é“¾ ï¼ˆCoVeï¼‰ çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åŸºäºä¸€ç³»åˆ—è¡ŒåŠ¨æ¥è®¡åˆ’å’Œæ‰§è¡ŒéªŒè¯ã€‚\nRECITE (â€œRecitation-augmented generationâ€; Sun et al. 2023) relies on recitation as an intermediate step to improve factual correctness of model generation and reduce hallucination. The motivation is to utilize Transformer memory as an information retrieval mechanism. Within RECITEâ€™s recite-and-answer scheme, the LLM is asked to first recite relevant information and then generate the output. Precisely, we can use few-shot in-context prompting to teach the model to generate recitation and then generate answers conditioned on recitation. Further it can be combined with self-consistency ensemble consuming multiple samples and extended to support multi-hop QA. RECITE ï¼ˆâ€œæœ—è¯µå¢å¼ºç”Ÿæˆâ€;Sun ç­‰äººï¼Œ2023 å¹´ï¼‰ä¾é èƒŒè¯µä½œä¸ºä¸­é—´æ­¥éª¤æ¥æé«˜æ¨¡å‹ç”Ÿæˆçš„äº‹å®æ­£ç¡®æ€§å¹¶å‡å°‘å¹»è§‰ã€‚åŠ¨æœºæ˜¯åˆ©ç”¨ Transformer å†…å­˜ä½œä¸ºä¿¡æ¯æ£€ç´¢æœºåˆ¶ã€‚åœ¨ RECITE çš„èƒŒè¯µå’Œå›ç­”æ–¹æ¡ˆä¸­ï¼Œè¦æ±‚ LLM é¦–å…ˆèƒŒè¯µç›¸å…³ä¿¡æ¯ï¼Œç„¶åç”Ÿæˆè¾“å‡ºã€‚å‡†ç¡®åœ°è¯´ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å°é•œå¤´ä¸Šä¸‹æ–‡æç¤ºæ¥æ•™æ¨¡å‹ç”ŸæˆèƒŒè¯µï¼Œç„¶åç”Ÿæˆä»¥èƒŒè¯µä¸ºæ¡ä»¶çš„ç­”æ¡ˆã€‚æ­¤å¤–ï¼Œå®ƒå¯ä»¥ä¸ä½¿ç”¨å¤šä¸ªæ ·æœ¬çš„è‡ªä¸€è‡´æ€§é›†æˆç›¸ç»“åˆï¼Œå¹¶æ‰©å±•ä»¥æ”¯æŒå¤šè·³ QAã€‚\ntodo\nSurvey # è®ºæ–‡ # è®ºæ–‡åœ°å€ A Survey of Hallucination in Large Foundation Models Paper 1xx. å¤§æ¨¡å‹å‰æ²¿çƒ­ç‚¹æœ€æ–°ç»¼è¿°ï¼šå¤§æ¨¡å‹å¾®è°ƒé—å¿˜ã€Agentæ™ºèƒ½ä½“ã€å¹»è§‰åŠRAGæ£€ç´¢å¢å¼ºæ¨¡å‹æ¨ä»‹ å¤§æ¨¡å‹å¾®è°ƒé—å¿˜ å¹»è§‰\nè®ºæ–‡ # è®ºæ–‡åœ°å€ Siren\u0026rsquo;s Song in the AI Ocean: A Survey on Hallucination in Large Language Models Paper 1xx. äººå·¥æ™ºèƒ½æµ·æ´‹ä¸­çš„å¡å£¬ä¹‹æ­Œï¼šå¤§å‹è¯­è¨€æ¨¡å‹LLMä¸­çš„å¹»è§‰ç ”ç©¶ç»¼è¿°ï¼ˆä¸€ï¼‰ 1xx. å¤§å‹è¯­è¨€æ¨¡å‹çš„å¹»è§‰ç ”ç©¶ï½œå‡è½»åŠé¿å…å¤§æ¨¡å‹LLMå¹»è§‰ï¼ˆäºŒï¼‰ 1xx. å€¼å¾—ä¸€è¯»çš„å¤§æ¨¡å‹ç”Ÿæˆå¹»è§‰ç ”ç©¶ç»¼è¿°ï¼šå¤§æ¨¡å‹å¹»è§‰çš„èµ·å› ã€è¯„ä¼°ä»¥åŠå‡è½»ç­–ç•¥æ€»ç»“ å¹»è§‰ vs äº‹å®æ€§[1] # å¹»è§‰ä¸»è¦æ˜¯æŒ‡LLMç”Ÿæˆæ¯«æ— æ ¹æ®æˆ–æ¯«æ— æ ¹æ®çš„å†…å®¹ï¼Œå¹»è§‰å¯ä»¥ç†è§£ä¸ºæ¨¡å‹å€¾å‘äº\u0026quot;ç”Ÿæˆä¸æŸäº›æ¥æºç›¸å…³çš„æ— æ„ä¹‰æˆ–ä¸çœŸå®çš„å†…å®¹\u0026quot;ã€‚è¿™ä¸äº‹å®æ€§é—®é¢˜ä¸åŒï¼Œåè€…å¼ºè°ƒæ¨¡å‹å­¦ä¹ ã€è·å–å’Œåˆ©ç”¨äº‹å®æ€§çŸ¥è¯†çš„èƒ½åŠ›ã€‚\nä¸¾ä¾‹è¯´æ˜ä¸¤è€…çš„åŒºåˆ«ï¼š\nå¦‚æœä¸€ä¸ªLLMåœ¨è¢«è¦æ±‚åˆ›ä½œ\u0026quot;ä¸€ä¸ªå…³äºå…”å­å’Œç‹¼äº¤æœ‹å‹çš„ç«¥è¯æ•…äº‹\u0026quot;æ—¶ï¼Œåˆ›ä½œå‡ºäº†ä¸€ä¸ªå…³äº\u0026quot;å…”å­å’Œç‹—äº¤æœ‹å‹\u0026quot;çš„æ•…äº‹ï¼Œé‚£ä¹ˆå®ƒå°±è¡¨ç°å‡ºäº†å¹»è§‰ã€‚ä¸è¿‡ï¼Œè¿™å¹¶ä¸ä¸€å®šæ˜¯äº‹å®æ€§é”™è¯¯ã€‚ å¦‚æœç”Ÿæˆçš„å†…å®¹åŒ…å«å‡†ç¡®çš„ä¿¡æ¯ï¼Œä½†ä¸æç¤ºçš„å…·ä½“å†…å®¹æœ‰å‡ºå…¥ï¼Œé‚£å°±æ˜¯å¹»è§‰ï¼Œè€Œä¸æ˜¯äº‹å®æ€§é—®é¢˜ã€‚ ä¾‹å¦‚ï¼Œå¦‚æœLLMçš„è¾“å‡ºåŒ…å«äº†æ¯”æç¤ºæŒ‡å®šæ›´å¤šçš„ç»†èŠ‚æˆ–ä¸åŒçš„å…ƒç´ ï¼Œä½†äº‹å®ä»ç„¶æ­£ç¡®ï¼Œè¿™å°±æ˜¯å¹»è§‰ã€‚\nç›¸åï¼Œå¦‚æœLLMé¿å…ç»™å‡ºç›´æ¥ç­”æ¡ˆï¼Œè€Œæ˜¯è¯´\u0026quot;æˆ‘ä¸çŸ¥é“\u0026quot;ï¼Œæˆ–è€…ç»™å‡ºäº†ä¸€ä¸ªå‡†ç¡®çš„ç­”æ¡ˆï¼Œä½†é—æ¼äº†ä¸€äº›æ­£ç¡®çš„ç»†èŠ‚ï¼Œé‚£ä¹ˆè¿™å°±æ˜¯äº‹å®æ€§é—®é¢˜ï¼Œè€Œä¸æ˜¯å¹»è§‰ã€‚\næ­¤å¤–ï¼Œå€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå¹»è§‰æœ‰æ—¶ä¼šäº§ç”Ÿä¸€äº›å†…å®¹ï¼Œè™½ç„¶ä¸åŸå§‹è¾“å…¥å†…å®¹æœ‰åå·®ï¼Œä½†åœ¨äº‹å®æ–¹é¢ä»ç„¶æ˜¯å‡†ç¡®çš„ã€‚\nè§£å†³æ–¹æ¡ˆ[2] # Prompt å·¥ç¨‹ *\nFew-shot å¤–éƒ¨çŸ¥è¯† *\nRAG åå¤„ç† *\nå®äº‹æ£€æŸ¥ * äººå·¥æ£€æŸ¥ * æå‡æ•°æ®è´¨é‡\nPretrainingçš„æ•°æ®è´¨é‡ SFTçš„æ•°æ®è´¨é‡ æ¨¡å‹èƒ½åŠ›æå‡ *\nå¾®è°ƒ å‚è€ƒ # å†çœ‹å¤§æ¨¡å‹äº‹å®æ€§çš„ç•Œå®šã€é”™è¯¯çš„èµ·å› ã€è¯„ä¼°åŠå‰æ²¿ç¼“è§£æ–¹æ¡ˆï¼šSurvey on Factuality in LLMS\né™ä½å¤§æ¨¡å‹å¹»è§‰çš„5ç§æ–¹æ¡ˆ v\nå‡å°‘å¤§æ¨¡å‹å¹»è§‰ï¼Œä½ å¿…é¡»è¦æŒæ¡çš„ 6 ä¸ªæ–¹æ³•ï¼ v\nExtrinsic Hallucinations in LLMs ***\nã€è¯‘ã€‘LLMä¸­çš„å¤–éƒ¨å¹»è§‰\nWork # å†çœ‹å¤§æ¨¡å‹å¹»è§‰é—®é¢˜å¦‚ä½•ç¼“è§£ ï¼šChain-of-Verification-ä¸€ç§åŸºäºé“¾å¼éªŒè¯æ€æƒ³çš„è‡ªæˆ‘ä¿®æ­£å·¥ä½œè§£è¯» 1xx. ä¹Ÿçœ‹ç¼“è§£å¤§æ¨¡å‹å¹»è§‰çš„å¤šé˜¶æ®µRAGæ¡†æ¶ï¼šåŠ å…¥æ··åˆæ£€ç´¢ã€è¿‡ç¨‹ç†ç”±ç”Ÿæˆä¸éªŒè¯çš„æ–¹æ¡ˆ survey # 1xx. å¤§æ¨¡å‹çš„å¹»è§‰é—®é¢˜è°ƒç ”: LLM Hallucination Survey\n1xx. ç½‘ç»œå®‰å…¨é¢†åŸŸå¾®è°ƒæ¨¡å‹SecGPTï¼šå…¼çœ‹å¤§æ¨¡å‹å¹»è§‰çš„åº¦é‡æ–¹å¼ã€è¯„ä¼°benchmarkåŠRAGå¢å¼ºä¸åŒæ–¹å¼ å¤§æ¨¡å‹å¹»è§‰ç»¼è¿°\n1xx. LLMä¹‹å¹»è§‰ï¼ˆä¸€ï¼‰ï¼šå¤§è¯­è¨€æ¨¡å‹å¹»è§‰è§£å†³æ–¹æ¡ˆç»¼è¿°\n"},{"id":34,"href":"/www6vAlgo/docs/LLM/Foundation-Models/decode-only/gptLlama3-1/gptLlama3-1/","title":"Llama3.1","section":"decode-only","content":" Llama3.1 # Llama3.1\n"},{"id":35,"href":"/www6vAlgo/docs/RL/core/DPO/","title":"(åŸç†|å®ç°)DPO","section":"Core","content":"\nDPO # (åŸç†|å®ç°)DPO\n"},{"id":36,"href":"/www6vAlgo/docs/DeepLearning/%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96/DeeplearningGradOpt/","title":"(åŸç†)æ¢¯åº¦ä¼˜åŒ–","section":"ç½‘ç»œä¼˜åŒ–","content":"\næ¢¯åº¦ä¼˜åŒ– # Gradient accumulation # Gradient checkpointing [10] # æ˜¾å­˜å ç”¨ä¼˜åŒ–ç®—æ³•\nmemory usage ä¸ computation time ä¹‹é—´çš„ tradeoff ï¼› gradient checkpointing\nIn deep neural networks, backpropagation requires storing intermediate activations for computing gradients during the backward pass.\nä½†æ˜¯å½“å±‚æ•°å˜å¤šæ—¶ï¼Œå­˜å‚¨æ‰€æœ‰çš„ä¸­é—´å±‚çš„æ¿€æ´»å€¼ï¼ˆintermediate activationsï¼‰éå¸¸åœ°å ç”¨æ˜¾å­˜ï¼›\ngradient checkpointing\né€‰æ‹©æ€§åœ°é‡æ–°è®¡ç®—ï¼ˆrecomputeï¼‰ä¸€éƒ¨åˆ†çš„ intermediate activations åœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­æ¥ç¼“è§£æ˜¾å­˜çš„å‹åŠ›ï¼›\nGradient Clipping (æ¢¯åº¦è£å‰ª) # ç›®çš„[21] # æ¢¯åº¦çˆ†ç‚¸é—®é¢˜çš„å¸¸è§åº”å¯¹æ–¹å¼ä¸ºâ€œæ¢¯åº¦è£å‰ªâ€ï¼Œä¹Ÿå°±æ˜¯é€šè¿‡â€œclipâ€æ–¹å¼æ¥é˜²æ­¢è¿­ä»£ä¸­æ¢¯åº¦å€¼è¿‡å¤§ã€‚\nä¸¤ç§å¸¸è§å½¢å¼[20] # æ¢¯åº¦èŒƒæ•°è£å‰ªï¼ˆGradient Norm Clippingï¼‰: è¿™ç§æ–¹æ³•æ¶‰åŠè®¡ç®—æ‰€æœ‰å‚æ•°æ¢¯åº¦çš„èŒƒæ•°ï¼ˆä¾‹å¦‚L2èŒƒæ•°ï¼‰ï¼Œå¦‚æœè¿™ä¸ªèŒƒæ•°è¶…è¿‡äº†è®¾å®šçš„é˜ˆå€¼ï¼Œå°±å°†æ¢¯åº¦ç¼©æ”¾åˆ°è¿™ä¸ªé˜ˆå€¼ä»¥å†…ã€‚åœ¨PyTorchä¸­ï¼Œè¿™å¯ä»¥é€šè¿‡ torch.nn.utils.clip_grad_norm_ å‡½æ•°å®ç°ã€‚ æ¢¯åº¦å€¼è£å‰ªï¼ˆGradient Value Clippingï¼‰: è¿™ç§æ–¹æ³•å¯¹æ¯ä¸ªå‚æ•°çš„æ¢¯åº¦å€¼è¿›è¡Œç‹¬ç«‹è£å‰ªï¼Œç¡®ä¿å®ƒä»¬ä¸ä¼šè¶…è¿‡ä¸€ä¸ªè®¾å®šçš„æœ€å¤§å€¼æˆ–æœ€å°å€¼ã€‚åœ¨PyTorchä¸­ï¼Œè¿™å¯ä»¥é€šè¿‡ torch.nn.utils.clip_grad_value_ å‡½æ•°å®ç°ã€‚ å‚è€ƒ # overview # Performance and Scalability: How To Fit a Bigger Model and Train It Faster ***\ngradient accumulation # 1xx. [LLMs å®è·µ] 11 gradient accumulation æ˜¾å­˜ä¼˜åŒ– trick v\nâ€‹\tgradient_accumulation.ipynb\nâ€‹\t[ LLMs å®è·µ] 11 gradient accumulation æ˜¾å­˜ä¼˜åŒ– trick 1xx. Pytorchå…¥é—¨ï¼ˆ7ï¼‰â€”â€” æ¢¯åº¦ç´¯åŠ ï¼ˆGradient Accumulationï¼‰\n1xx. èŠèŠæ¢¯åº¦ç´¯åŠ (Gradient Accumulation)\n1xx. What is Gradient Accumulation in Deep Learning?\n1xx. Performing gradient accumulation with Accelerate\nâ€‹\tä½¿ç”¨Accelerateè¿›è¡Œæ¢¯åº¦ç´¯ç§¯\ngradient checkpointing # [LLMs å®è·µ] 13 gradient checkpointing æ˜¾å­˜ä¼˜åŒ– trick v â€‹\tgradient_checkpointing.ipynb\nâ€‹\t[LLMs å®è·µ] 13 gradient checkpointing æ˜¾å­˜ä¼˜åŒ– trick â€‹\tFitting larger networks into memory. *** çœ‹åŠ¨å›¾\nâ€‹\tBackprop and systolic arrays.\nGradient Clipping # æ¢¯åº¦è£å‰ªï¼ˆGradient Clippingï¼‰ â€‹\thttps://github.com/pytorch/pytorch/blob/main/torch/nn/utils/clip_grad.py\næ·±åº¦ç‚¼ä¸¹ä¹‹æ¢¯åº¦è£å‰ª 1xx. ã€æ·±åº¦å­¦ä¹ ã€‘ç¬¬6.2èŠ‚ æ¢¯åº¦è£å‰ª\n1xx. ã€Pytorchã€‘æ¢¯åº¦è£å‰ªâ€”â€”torch.nn.utils.clip_grad_norm_çš„åŸç†åŠè®¡ç®—è¿‡ç¨‹\n1xx. PyTorchä½¿ç”¨Tricksï¼šæ¢¯åº¦è£å‰ª-é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸æˆ–æ¢¯åº¦æ¶ˆå¤± ï¼ï¼\n"},{"id":37,"href":"/www6vAlgo/docs/DeepLearning/basic/DeeplearningOverfitting/","title":"(åŸç†)è¿‡æ‹Ÿåˆ","section":"basic","content":"\n(åŸç†)è¿‡æ‹Ÿåˆ # (åŸç†)è¿‡æ‹Ÿåˆ\n"},{"id":38,"href":"/www6vAlgo/docs/DeepLearning/Transformer/TransformerCode/","title":"(å®æˆ˜)Transformer","section":"Transformer","content":"\nå‚è€ƒ # 1xx. transformer.ipynb git Transformerä»£ç å®ç°\n1xx. Transformer transformer.py git\n1xx. [è¯‘] Transformer æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼š600 è¡Œ Python ä»£ç å®ç° self-attention å’Œä¸¤ç±» Transformerï¼ˆ2019ï¼‰ V, github Transformers from scratch\n1xx. ä»é›¶å®ç°Transformerçš„ç®€æ˜“ç‰ˆä¸å¼ºå¤§ç‰ˆï¼šä»300å¤šè¡Œåˆ°3000å¤šè¡Œ\n1xx. Transformeræºç è¯¦è§£ï¼ˆPytorchç‰ˆæœ¬ï¼‰\n"},{"id":39,"href":"/www6vAlgo/docs/LLM/core/gptImpossibleTriangle/","title":"(åŸç†)ä¸å¯èƒ½ä¸‰è§’","section":"core","content":" ä¸å¯èƒ½ä¸‰è§’[1] # ä¸å¯èƒ½ä¸‰è§’ # é¢„è®­ç»ƒæ¨¡å‹ä¹‹æ‰€ä»¥æ˜¯åˆ’æ—¶ä»£çš„è¿›å±•ï¼Œæ˜¯å®ƒå…·å¤‡äº†ä¸­ç­‰å°ºå¯¸ï¼ˆä¸€å¼ å¡å³å¯ç²¾è°ƒï¼‰å’Œå…¨ä»»åŠ¡SOTAçš„ç²¾è°ƒæ•ˆæœ è€Œæœ€è¿‘ä¸¤å¹´é¢„è®­ç»ƒæ¨¡å‹éƒ½åœ¨å¾€å¤§å°ºå¯¸å‘å±•ï¼Œä¹Ÿå°±æ˜¯å…·å¤‡äº†å°‘æ ·æœ¬æ•ˆæœï¼Œä½†ä»–ä»¬çš„å°‘æ ·æœ¬æ•ˆæœä¾æ—§æ¯”ä¸è¿‡ä¸­ç­‰æ¨¡å‹çš„ç²¾è°ƒ å¼¥è¡¥æ–¹æ³• # ä¼˜åŒ–size å¯¹äºå‡å°‘æ¨¡å‹å°ºå¯¸ï¼Œä¸€æ¡å…¸å‹çš„æ•…äº‹çº¿å°±æ˜¯è’¸é¦ã€‚ä½†å…¶ä¸­ä»å­˜åœ¨ä¸¤ä¸ªé—®é¢˜ï¼šä¸€æ˜¯å­¦ç”Ÿæ¨¡å‹å¾ˆéš¾è¾¾åˆ°åŸå§‹æ¨¡å‹çš„æ•ˆæœï¼ŒäºŒæ˜¯åŸå§‹çš„å¤§å°ºå¯¸æ¨¡å‹çš„æ¨ç†æ•ˆç‡å¤ªä½ ä¼˜åŒ–few-shot å¯¹äºæå‡å°‘æ ·æœ¬è¡¨ç°ï¼Œæ•°æ®å¢å¼ºæ˜¯ä¸€ä¸ªå¥½åŠæ³•ï¼Œæ¯”å¦‚ç”¨æ— ç›‘ç£æ•°æ®åšè‡ªç›‘ç£è®­ç»ƒã€æˆ–è€…åŸºäºå…¶ä»–æ¨¡å‹ç”Ÿæˆä¸€äº›ä¼ªæ ·æœ¬ï¼Œä½†è¿™ç±»æ–¹æ³•ä¾æ—§å—é™äºç°æœ‰æ ‡æ³¨æ ·æœ¬çš„å¤šæ ·æ€§ï¼Œæ³›åŒ–æ€§èƒ½æå‡æœ‰é™ fine-tuning å¯¹äºæå‡ç²¾è°ƒè¡¨ç°å’Œæ•ˆç‡ï¼ˆå…¶å®ä¹Ÿåå°‘æ ·æœ¬ï¼‰ï¼Œæœ€è¿‘ä¸€ä¸ªæ¯”è¾ƒç«çš„æ•…äº‹æ˜¯promptï¼Œä½†è¿™ç§æ–¹å¼å¯¹promptçš„è®¾è®¡éå¸¸æ•æ„Ÿï¼ŒåŒæ—¶æ•ˆæœä¹Ÿå¾ˆéš¾è¶…è¿‡ç›®å‰çš„æœ‰ç›‘ç£SOTA å…¶ä»– ä¸å¯èƒ½ä¸‰è§’ # åˆ†å¸ƒå¼ç³»ç»Ÿ # CAPç†è®º C ä¸€è‡´æ€§ A å¯ç”¨æ€§ P åˆ†åŒº åˆ†å¸ƒå¼å­˜å‚¨ # RUMçŒœæƒ³ Read-overhead Update-overhead Memory-overhead èŒƒå¼ # pretrain, finetune èŒƒå¼[3] # ç¬¬ä¸‰é˜¶æ®µèŒƒå¼\npretrain, prompt, predict èŒƒå¼[3] # ç¬¬å››é˜¶æ®µèŒƒå¼\næ€»ç»“ # æ ¹æ®ä¸å¯èƒ½ä¸‰è§’å½¢ï¼Œ pretrain, finetune èŒƒå¼[3] å‘pretrain, prompt, predict èŒƒå¼[3]çš„è¿ç§»æ˜¯å—å¤§æ¨¡å‹å¤§å°çš„å½±å“\nå‚è€ƒ # ä¸å¯èƒ½ä¸‰è§’ # é¢„è®­ç»ƒæ¨¡å‹çš„ä¸‹ä¸€æ­¥ï¼Ÿçªç ´Impossible Triangle Impossible Triangle: Whatâ€™s Next for Pre-trained Language Models? å¾®è½¯æœ±æ™¨å…‰ï¼šé¢„è®­ç»ƒæ¨¡å‹ä¸‹ä¸€æ­¥æ€ä¹ˆèµ°ï¼Ÿçªç ´PLMçš„ã€Œä¸å¯èƒ½ä¸‰è§’ã€ Go to Page self "},{"id":40,"href":"/www6vAlgo/docs/RL/framework/veRLConfig/","title":"(åŸç†\u0026å®æˆ˜)veRL Config","section":"Framework","content":"\nveRL Config # (åŸç†\u0026amp;å®æˆ˜)veRL Config\n"},{"id":41,"href":"/www6vAlgo/docs/DeepLearning/Transformer/Embedding/Embedding/","title":"(åŸç†)Embedding","section":"Embedding","content":" example [1] # é™ç»´: t-SNE K-Means èšç±» æ–‡æœ¬æœç´¢ ç›¸ä¼¼åº¦æœç´¢ Embedding ä»·å€¼ [2] # é™ç»´ å°†è¿™äº›é«˜ç»´æ•°æ®æ˜ å°„åˆ°ä¸€ä¸ªä½ç»´ç©ºé—´ï¼Œå¤§å¤§å‡å°‘äº†æ¨¡å‹çš„å¤æ‚åº¦ã€‚ æ•æ‰è¯­ä¹‰ä¿¡æ¯ Embeddingä¸ä»…ä»…æ˜¯é™ç»´ï¼Œæ›´é‡è¦çš„æ˜¯ï¼Œå®ƒèƒ½å¤Ÿæ•æ‰åˆ°æ•°æ®çš„è¯­ä¹‰ä¿¡æ¯ã€‚ æ³›åŒ–èƒ½åŠ› ç”±äºEmbeddingèƒ½å¤Ÿæ•æ‰åˆ°æ•°æ®çš„ä¸€äº›å†…åœ¨è§„å¾‹ï¼Œå› æ­¤å¯¹äºè¿™äº›æœªè§è¿‡çš„æ•°æ®ï¼ŒEmbeddingä»ç„¶èƒ½å¤Ÿç»™å‡ºåˆç†çš„è¡¨ç¤º åº”ç”¨ [2] # è¯­ä¹‰è¡¨ç¤ºå’Œè¯­ä¹‰ç›¸ä¼¼åº¦ è¯è¯­å…³ç³»å’Œç±»æ¯”æ¨ç† ä¸Šä¸‹æ–‡ç†è§£ æ–‡æœ¬åˆ†ç±»å’Œæƒ…æ„Ÿåˆ†æ æœºå™¨ç¿»è¯‘å’Œç”Ÿæˆæ¨¡å‹ å¤©æ¢¯æ¦œ # mteb/leaderboard\nexample[3] # m3eæ¨¡å‹ bgeæ¨¡å‹ å‚è€ƒ # embedding git\nã€ŠAI å¤§æ¨¡å‹åº”ç”¨å¼€å‘å®æˆ˜è¥ã€‹ 03-å¤§æ¨¡å‹å¼€å‘åŸºç¡€ï¼šEmbedding\nä¸€æ–‡é€šé€Text Embeddingæ¨¡å‹ï¼šä»text2vecã€openai-ada-002åˆ°m3eã€bge\n1xx. å¦‚ä½•é€‰å–RAGä¸­çš„embeddingæ¨¡å‹ v ***\nhuggingface embeddingæ¨¡å‹æ’è¡Œæ¦œ\nSentence Bert Demo Repo git\n1xx. å¼•å…¥ä»»åŠ¡InstructionæŒ‡ä»¤çš„å¥å­å‘é‡åŒ–æ–¹æ¡ˆï¼šInstructorçš„å®ç°æ€è·¯åŠè®­ç»ƒæ•°æ®é›†æ„é€ æ–¹æ¡ˆ\nRepo git\n1xx. ä¹Ÿçœ‹åˆ©ç”¨å¤§æ¨¡å‹è¿›è¡ŒRAGæ–‡æœ¬åµŒå…¥è®­ç»ƒæ•°æ®ç”Ÿæˆï¼šå…¼çœ‹é¢å‘NLPä»»åŠ¡çš„å¼€æºæŒ‡ä»¤å¾®è°ƒæ•°æ®é›† ã€ŠImproving Text Embeddings with Large Language Modelsã€‹\n1xx. å¦‚ä½•æé«˜LLMsçš„æ–‡æœ¬è¡¨å¾(Text Embedding)èƒ½åŠ›?\nã€ŠImproving Text Embeddings with Large Language Modelsã€‹\n1xx. æ–‡æœ¬è½¬å‘é‡æ•™ç¨‹s2â€”â€”è®¤è¯†æ–‡æœ¬è½¬å‘é‡æ–¹æ³•ï¼ˆsbertæœ¬è´¨å’Œæ¨ç†åŠ é€Ÿï¼‰ V\n"},{"id":42,"href":"/www6vAlgo/docs/LLM/core/gptEval/","title":"æµ‹è¯„ *","section":"core","content":" åŸºç¡€æŒ‡æ ‡[1] # åˆ†ç±»ä»»åŠ¡\nAccuracy Precision Recall F1-score AUC-ROC æ›²çº¿ ç”Ÿæˆä»»åŠ¡\nBLEU ROUGE METEOR äººå·¥è¯„ä¼° å›å½’ä»»åŠ¡\nMSE MAE R2 PPL å›°æƒ‘åº¦\næµ‹è¯„é›† # MMLU C-EVAL Framework # OpenCompass å‚è€ƒ # AIå¤§æ¨¡å‹é¢è¯•é¢˜ï¼š5.æ¨¡å‹å¾®è°ƒæ€ä¹ˆè¯„ä¼°æ•ˆæœ 1xx. ä¸€äº›è®¨è®ºï¼šä¸‰å¼ å…³äºå¤§æ¨¡å‹å¾®è°ƒæ–¹æ¡ˆçš„è„‘å›¾åŠå‡ ç‚¹llama2ç­‰è¡Œä¸šè½åœ°çš„é—®é¢˜æ€è€ƒ 1xx. https://github.com/CLUEbenchmark/SuperCLUE-Llama2-Chinese\n1xx. å¦‚ä½•è®©è‡ªå·±çš„å¤§æ¨¡å‹æ¦œå•è¯„åˆ†æ›´é«˜ï¼šä¹Ÿè°ˆæ¦œå•è¯„æµ‹è¯„åˆ†çš„ä¸€äº›å¸¸è§æ–¹æ¡ˆå’Œå…¸å‹æ¡ˆä¾‹ CEval # 1xx. å¤§æ¨¡å‹è½åœ°çš„ä¸€äº›å‰æ²¿è§‚ç‚¹ï¼šå…¼çœ‹çŸ¥è¯†å›¾è°±å¢å¼ºå¤§æ¨¡å‹é—®ç­”çš„å‡ ä¸ªæ–¹æ¡ˆåŠCEVALæ¦œå•è¯„æµ‹å¯å‘ äºŒã€CEVALæ¦œå•è¯„æµ‹ä¸­èƒ½å¤Ÿå¾—åˆ°ä¸€äº›å¯ç¤º\n1. C-Eval æ•°æ®é›†è¯„æµ‹ç®€æ˜æ•™ç¨‹\n1xx. å¤§æ¨¡å‹Bç«¯è½åœ°â€œç‰›åˆ€æ€é¸¡â€çš„å¥‡æ€ªæ„Ÿè§‰ï¼šå…¼çœ‹CEVAlé€šç”¨è¯„æµ‹åˆ°é‡‘èã€åŒ»ç–—ä¸¤å¤§å‚åŸŸè¯„æµ‹çš„è½¬å˜ CEVAl\nFramework # https://opencompass.org.cn/home\n"},{"id":43,"href":"/www6vAlgo/docs/DeepLearning/Transformer/TrainTokenizer/","title":"Tokenizer","section":"Transformer","content":"\ntokenizer åˆ†è¯ # å•è¯åˆ†è¯æ³• å•å­—åˆ†è¯æ³• å­è¯åˆ†è¯æ³• BPE [GPTç³»åˆ—], WordPiece å‚è€ƒ # 1xx. å¤§æ¨¡å‹è¯è¡¨æ‰©å……å¿…å¤‡å·¥å…·SentencePiece 1xx. NLPï¼ˆäºŒï¼‰ï¼šæµ…è°ˆåˆ†è¯ 1xx. https://www.bilibili.com/video/BV1vN411p7t2/ 1xx. å¼€æºå¤§æ¨¡å‹å¦‚ä½•æ›´å¥½åœ°é€‚åº”ä¸­æ–‡åœºæ™¯ï¼šLLAMAæ‰©å……è¯è¡¨ã€BLOOMè£å‰ªè¯è¡¨åŸºæœ¬åŸç†ä¸å¼€æºå®ç°\n"},{"id":44,"href":"/www6vAlgo/docs/RL/Agentic-RL/Search/Kimi-Researcher/","title":"Kimi-Researcher","section":"Search","content":" è®ºæ–‡ # Kimi-Researcher - End-to-End RL Training for Emerging Agentic Capabilities\nå‚è€ƒ # å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“æ–°æ¨¡æ¿ï¼šæ·±å…¥è§£æKimiâ€‘Researcher\n1xx. Kimi-Researcherï¼šç«¯åˆ°ç«¯å¼ºåŒ–å­¦ä¹ é©±åŠ¨çš„è‡ªä¸»æ™ºèƒ½ä½“\n1xx. up: æœ‰ä¸ªè§†é¢‘ "},{"id":45,"href":"/www6vAlgo/docs/RL/core/unified/","title":"unified paradigm","section":"Core","content":" RL unified paradigm # RL unified paradigm # DPO # PPO # GRPO # å‚è€ƒ # DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models\n"},{"id":46,"href":"/www6vAlgo/docs/DeepLearning/basic/Pytorch/","title":"(å®æˆ˜)PyTorch","section":"basic","content":"\nPyTorch å®æˆ˜ # (å®æˆ˜)PyTorch\n"},{"id":47,"href":"/www6vAlgo/docs/LLM/Foundation-Models/gptLeaderBoard/gptLeaderBoard/","title":"å¤§æ¨¡å‹ æ’è¡Œæ¦œ","section":"Foundation Models","content":" å¤§æ¨¡å‹ # æ’è¡Œæ¦œ # HuggingFaceH å¤§æ¨¡å‹æ’è¡Œæ¦œ\nLLM Collection\nä¸­å›½æ’è¡Œæ¦œ # ä¸­å›½å¤§æ¨¡å‹ é€šç”¨ 39 é‡‘è 25 å¸æ³• 8 æ³•å¾‹ 6 åŒ»å­¦ 13 åŒ»ç–— 24 æ•™è‚² 13 ç§‘ç ” 17 å·¥ä¸š 23 æ”¿åŠ¡ 12 è¿ç»´ 7 "},{"id":48,"href":"/www6vAlgo/docs/LLM/Foundation-Models/encode-only/gptBERT/gptBERT/","title":"(åŸç†)BERT","section":"encode-only","content":"\nBERT # (åŸç†)BERT\n"}]