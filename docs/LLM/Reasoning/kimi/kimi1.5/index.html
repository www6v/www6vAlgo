<!DOCTYPE html>
<html lang="en" dir="ltr">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="
  论文
  #

KIMI K1.5:SCALING REINFORCEMENT LEARNING WITH LLMS
git

  Kimi K1.5 技术报告深度解读 (Kimi K1.5 Paper Reading Notes)
  #


  0. 背景 (Background)
  #


发布 (Release): 2025年1月20日 (与 DeepSeek-R1 同时期)。
效果 (Achievement): 达到了与 OpenAI-O1 模型相似的效果。
价值 (Significance): 报告中包含更多可供算法工程师和研究人员参考的算法处理细节，特别是关于如何处理数据以增强推理能力。



  1. 整体架构 (Overall Architecture)
  #


遵循与 ChatGPT 相似的标准流程：

预训练 (Pre-training)
SFT 训练 (Supervised Fine-Tuning)
强化学习 (RL)





  2. 预训练 (Pre-training)
  #


基础模型 (Base Model): 在多样化、高质量的多模态语料库上训练 (包括：英、中、代码、数学、知识、图像描述等)。
训练阶段 (Phases): 分三个阶段进行

视觉-语言预训练 (Vision-Language Pre-training): 先训练 LLM，然后逐步整合多模态能力 (Vision Tower 独立训练，然后加入图文交织数据并更新 LLM 参数)。
冷却阶段 (Cooling Down): 利用精选和合成数据巩固模型能力，尤其针对推理和知识任务 (使用拒绝采样保证质量)。
长上下文激活阶段 (Long-Context Activation):

目标: 将序列处理能力扩展到 131,072 Token。
方法:

过采样 Long-Context 数据 (40% 全注意力，60% 部分注意力)。
逐步训练：4k -&gt; 32k -&gt; 128k。









  3. SFT 训练 (SFT Training)
  #


  3.1. 常规的 SFT (Standard SFT)
  #


数据构建 (Data Construction): 通过人工标注构建种子集，用种子模型生成回复，再进行排序和优化 (对推理任务使用基于规则/奖励模型的拒绝采样扩充)。
数据分布 (Data Distribution): 总计约 100 万样本，涵盖通用问答、编码、数学/科学、长上下文任务及文本-视觉示例。


  3.2. Long-CoT SFT (重点 1)
  #


目的 (Purpose): 获得长链思维 (Long-CoT) 能力。
数据特点 (Data Characteristics): 答案部分较长，且蕴含人类思考过程 (规划、评估、反思、探索)。



  4. 强化学习 (RL)（重点 2）
  #


  4.1. RL 数据集构建 (Dataset Construction)
  #


衡量属性 (Key Properties):

多样性 (Diversity): 保证数据来源和领域丰富，通过标签系统打标。
难度平衡 (Difficulty Balance): 对问题进行难度分级 (基于高温度回复通过率)。采用课程学习 (Curriculum Learning)，先学简单，再学复杂。
精确评估 (Accurate Evaluation): 移除难以精确评估的问题 (如多选题、对错题、证明题)，以及容易被 Hack 的 Prompt。




  4.2. 问题定义 (Problem Definition)
  #


核心是将优化问题转化为最大化最终答案 (y) 和思考过程 (Z) 的奖励 (r) 的期望。


  4.3. 策略优化 (Policy Optimization)
  #


优化目标 (Optimization Goal): 将 RL 期望最大化转化为 Loss 函数进行优化 (通过梯度上升)。
关键点 (Key Details):

移除了 Value Model (与 DeepSeek-R1 相似)，认为错误路径也有助益。
设计了长度惩罚奖励 (Length Penalty) 来减少模型过度思考 (越长奖励越小)。




  4.4. 采样策略 (Sampling Strategy)
  #


采用 Off-policy 训练，使用：

课程采样 (Curriculum Sampling): 从简单任务过渡到复杂任务。
优先采样策略 (Priority Sampling): 重点训练模型表现不佳的问题 (按 1−si 比例采样，si 为成功率)。




  4.5. Long2short (重点 3)
  #


目的 (Purpose): 实现长链推理 (Long-CoT) 到短链推理 (Short-CoT) 的高效迁移，提升响应速度。
方法 (Methods):

模型融合 (Model Fusion): Long/Short 模型权重直接融合。
最短拒绝采样 (Shortest Refusal Sampling): 生成多条样本，选最短且正确的。
长短样本的 DPO (DPO): 短而正确的作为正样本，错误或 1.5 倍长于短样本的作为负样本。
Long2short 强化学习: 在一阶段 RL 后，使用长度惩罚减少生成长度。




  4.6. 其他细节 (Other Details)
  #


代码 (Code): 自动生成测试用例作为奖励 (使用 CYaRon，并对生成的测试用例进行严格筛选验证)。
数学 (Math): 采用思维链奖励模型 (Chain-of-Thought RM) 提高评估不同答案书写形式的准确性。
视觉数据 (Vision Data): Vision RL 数据来自真实世界、合成视觉推理和文本渲染数据 (如将文本、代码转为图像)。



  5. 实验结论 (Experimental Conclusions)
  #


Kimi-K1.5 在主要数据集上表现出色，是首个追平 OpenAI-O1 的多模态大模型。
自我进化 (Self-Evolution): 随着训练，模型自发输出更长的 CoT，且效果更好。
课程学习 (Curriculum Learning): 课程采样策略能有效提升模型能力，防止过早饱和。
负样本梯度 (Negative Sample Gradient): 实验证明，使用负样本 (奖励低于平均值的样本) 对模型能力提升有益。


  参考
  #

深度解读 Kimi-K1.5，真正了解 RL 数据是怎么筛选的 *** 
细节之王 Kimi K1.5，大模型算法工程师复现推理模型必读文章之一 
由 Gemimi 辅助生成">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="#343a40">
<meta name="color-scheme" content="light dark"><meta property="og:url" content="https://www6v.github.io/www6vAlgo/docs/LLM/Reasoning/kimi/kimi1.5/">
  <meta property="og:site_name" content="LLM 算法">
  <meta property="og:title" content="Kimi1.5">
  <meta property="og:description" content="论文 # KIMI K1.5:SCALING REINFORCEMENT LEARNING WITH LLMS
git
Kimi K1.5 技术报告深度解读 (Kimi K1.5 Paper Reading Notes) # 0. 背景 (Background) # 发布 (Release): 2025年1月20日 (与 DeepSeek-R1 同时期)。 效果 (Achievement): 达到了与 OpenAI-O1 模型相似的效果。 价值 (Significance): 报告中包含更多可供算法工程师和研究人员参考的算法处理细节，特别是关于如何处理数据以增强推理能力。 1. 整体架构 (Overall Architecture) # 遵循与 ChatGPT 相似的标准流程： 预训练 (Pre-training) SFT 训练 (Supervised Fine-Tuning) 强化学习 (RL) 2. 预训练 (Pre-training) # 基础模型 (Base Model): 在多样化、高质量的多模态语料库上训练 (包括：英、中、代码、数学、知识、图像描述等)。 训练阶段 (Phases): 分三个阶段进行 视觉-语言预训练 (Vision-Language Pre-training): 先训练 LLM，然后逐步整合多模态能力 (Vision Tower 独立训练，然后加入图文交织数据并更新 LLM 参数)。 冷却阶段 (Cooling Down): 利用精选和合成数据巩固模型能力，尤其针对推理和知识任务 (使用拒绝采样保证质量)。 长上下文激活阶段 (Long-Context Activation): 目标: 将序列处理能力扩展到 131,072 Token。 方法: 过采样 Long-Context 数据 (40% 全注意力，60% 部分注意力)。 逐步训练：4k -&gt; 32k -&gt; 128k。 3. SFT 训练 (SFT Training) # 3.1. 常规的 SFT (Standard SFT) # 数据构建 (Data Construction): 通过人工标注构建种子集，用种子模型生成回复，再进行排序和优化 (对推理任务使用基于规则/奖励模型的拒绝采样扩充)。 数据分布 (Data Distribution): 总计约 100 万样本，涵盖通用问答、编码、数学/科学、长上下文任务及文本-视觉示例。 3.2. Long-CoT SFT (重点 1) # 目的 (Purpose): 获得长链思维 (Long-CoT) 能力。 数据特点 (Data Characteristics): 答案部分较长，且蕴含人类思考过程 (规划、评估、反思、探索)。 4. 强化学习 (RL)（重点 2） # 4.1. RL 数据集构建 (Dataset Construction) # 衡量属性 (Key Properties): 多样性 (Diversity): 保证数据来源和领域丰富，通过标签系统打标。 难度平衡 (Difficulty Balance): 对问题进行难度分级 (基于高温度回复通过率)。采用课程学习 (Curriculum Learning)，先学简单，再学复杂。 精确评估 (Accurate Evaluation): 移除难以精确评估的问题 (如多选题、对错题、证明题)，以及容易被 Hack 的 Prompt。 4.2. 问题定义 (Problem Definition) # 核心是将优化问题转化为最大化最终答案 (y) 和思考过程 (Z) 的奖励 (r) 的期望。 4.3. 策略优化 (Policy Optimization) # 优化目标 (Optimization Goal): 将 RL 期望最大化转化为 Loss 函数进行优化 (通过梯度上升)。 关键点 (Key Details): 移除了 Value Model (与 DeepSeek-R1 相似)，认为错误路径也有助益。 设计了长度惩罚奖励 (Length Penalty) 来减少模型过度思考 (越长奖励越小)。 4.4. 采样策略 (Sampling Strategy) # 采用 Off-policy 训练，使用： 课程采样 (Curriculum Sampling): 从简单任务过渡到复杂任务。 优先采样策略 (Priority Sampling): 重点训练模型表现不佳的问题 (按 1−si 比例采样，si 为成功率)。 4.5. Long2short (重点 3) # 目的 (Purpose): 实现长链推理 (Long-CoT) 到短链推理 (Short-CoT) 的高效迁移，提升响应速度。 方法 (Methods): 模型融合 (Model Fusion): Long/Short 模型权重直接融合。 最短拒绝采样 (Shortest Refusal Sampling): 生成多条样本，选最短且正确的。 长短样本的 DPO (DPO): 短而正确的作为正样本，错误或 1.5 倍长于短样本的作为负样本。 Long2short 强化学习: 在一阶段 RL 后，使用长度惩罚减少生成长度。 4.6. 其他细节 (Other Details) # 代码 (Code): 自动生成测试用例作为奖励 (使用 CYaRon，并对生成的测试用例进行严格筛选验证)。 数学 (Math): 采用思维链奖励模型 (Chain-of-Thought RM) 提高评估不同答案书写形式的准确性。 视觉数据 (Vision Data): Vision RL 数据来自真实世界、合成视觉推理和文本渲染数据 (如将文本、代码转为图像)。 5. 实验结论 (Experimental Conclusions) # Kimi-K1.5 在主要数据集上表现出色，是首个追平 OpenAI-O1 的多模态大模型。 自我进化 (Self-Evolution): 随着训练，模型自发输出更长的 CoT，且效果更好。 课程学习 (Curriculum Learning): 课程采样策略能有效提升模型能力，防止过早饱和。 负样本梯度 (Negative Sample Gradient): 实验证明，使用负样本 (奖励低于平均值的样本) 对模型能力提升有益。 参考 # 深度解读 Kimi-K1.5，真正了解 RL 数据是怎么筛选的 *** 细节之王 Kimi K1.5，大模型算法工程师复现推理模型必读文章之一 由 Gemimi 辅助生成">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="website">
<title>Kimi1.5 | LLM 算法</title>
<link rel="icon" href="/www6vAlgo/favicon.png" >
<link rel="manifest" href="/www6vAlgo/manifest.json">
<link rel="canonical" href="https://www6v.github.io/www6vAlgo/docs/LLM/Reasoning/kimi/kimi1.5/">
<link rel="stylesheet" href="/www6vAlgo/book.min.6c8b9d2a1fc95075ed7da46ca81060b39add8fff6741ac51259f768929281e2c.css" integrity="sha256-bIudKh/JUHXtfaRsqBBgs5rdj/9nQaxRJZ92iSkoHiw=" crossorigin="anonymous">
  <script defer src="/www6vAlgo/fuse.min.js"></script>
  <script defer src="/www6vAlgo/en.search.min.2fc88223f2298fa00c47bc800096784438b8643d8c26661cb8d699143598530a.js" integrity="sha256-L8iCI/Ipj6AMR7yAAJZ4RDi4ZD2MJmYcuNaZFDWYUwo=" crossorigin="anonymous"></script>
<link rel="alternate" type="application/rss+xml" href="https://www6v.github.io/www6vAlgo/docs/LLM/Reasoning/kimi/kimi1.5/index.xml" title="LLM 算法" />
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  
</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/www6vAlgo/"><span>LLM 算法</span>
  </a>
</h2>


<div class="book-search hidden">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>
<script>document.querySelector(".book-search").classList.remove("hidden")</script>















  
  <ul>
    
      
        <li class="book-section-flat" >
          
  
  

  
    <input type="checkbox" id="section-ca51f083a72ceb6f7ce7aac637ec4cff" class="toggle"  />
    <label for="section-ca51f083a72ceb6f7ce7aac637ec4cff" class="flex justify-between">
      <a role="button" class="">DeepLearning</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-ca800fece441ac3e580321c74f3e9d49" class="toggle"  />
    <label for="section-ca800fece441ac3e580321c74f3e9d49" class="flex justify-between">
      <a role="button" class="">basic</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/basic/DeepLearning/" class="">Deep Learning</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/basic/DeeplearningForwardBackward/" class="">(原理&amp;实战)前向/反向传播</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/basic/DeeplearningLoss/" class="">(原理&amp;实战)交叉熵损失</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/basic/DeeplearningOverfitting/" class="">(原理)过拟合</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/basic/Pytorch/" class="">(实战)PyTorch</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-1a190617d0c8a17ae9ae2d3ed30bd150" class="toggle"  />
    <label for="section-1a190617d0c8a17ae9ae2d3ed30bd150" class="flex justify-between">
      <a role="button" class="">正则化</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/%E6%AD%A3%E5%88%99%E5%8C%96/WeightDecay/" class="">(原理&amp;实战)权重衰减</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/%E6%AD%A3%E5%88%99%E5%8C%96/Dropout/" class="">(原理&amp;实战)Dropout</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-1424866912bd75b061251f3b3e940596" class="toggle"  />
    <label for="section-1424866912bd75b061251f3b3e940596" class="flex justify-between">
      <a role="button" class="">网络优化</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96/DeeplearningLearningRate/" class="">(原理)学习率</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96/DeeplearningBatchsize/" class="">(原理)Batchsize</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96/DeeplearningNorm/" class="">规范化 Norm</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96/DeeplearningGradOpt/" class="">(原理)梯度优化</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-d175a581e6d1d294c2886df9f4e638fd" class="toggle"  />
    <label for="section-d175a581e6d1d294c2886df9f4e638fd" class="flex justify-between">
      <a role="button" class="">Transformer</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/Transformer/Transformer/" class="">(原理)Transformer</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/Transformer/SelfAttention/" class="">(原理)Self-Attention</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/Transformer/ModelGQA/" class="">(原理)GQA</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/Transformer/TransformerCode/" class="">(实战)Transformer</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/Transformer/TrainTokenizer/" class="">Tokenizer</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-986dec1b5e65fdcdcaa6d6a6bdce0c55" class="toggle"  />
    <label for="section-986dec1b5e65fdcdcaa6d6a6bdce0c55" class="flex justify-between">
      <a role="button" class="">Embedding</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/Transformer/Embedding/survey/" class="">(Survey)Embedding</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/Transformer/Embedding/Embedding/" class="">(原理)Embedding</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <input type="checkbox" id="section-47d8239bc563cf0526676851b768f952" class="toggle"  />
    <label for="section-47d8239bc563cf0526676851b768f952" class="flex justify-between">
      <a role="button" class="">机器学习</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/MLData/" class="">机器学习-数据</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/MLModel/" class="">机器学习-模型</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <input type="checkbox" id="section-8289f046e5a8f2479317b06c48dded09" class="toggle"  />
    <label for="section-8289f046e5a8f2479317b06c48dded09" class="flex justify-between">
      <a role="button" class="">强化学习</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-fd4324249788d4f101352645b9815095" class="toggle"  />
    <label for="section-fd4324249788d4f101352645b9815095" class="flex justify-between">
      <a role="button" class="">Core</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-a4b91a8ec30520aa20445e5046653468" class="toggle"  />
    <label for="section-a4b91a8ec30520aa20445e5046653468" class="flex justify-between">
      <a role="button" class="">PPO family</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/RL/core/PPO-family/PPO/" class="">(原理)PPO</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/RL/core/PPO-family/PPO1/" class="">(原理)PPO</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/RL/core/PPO-family/RewardModel/" class="">(原理|实现)PPO-RewardModel</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-792edea28c7fa6c149b193954c187e3e" class="toggle"  />
    <label for="section-792edea28c7fa6c149b193954c187e3e" class="flex justify-between">
      <a role="button" class="">GRPO Family</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/RL/core/GRPO-family/GRPODeepseek/" class="">(实战)GRPO</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/RL/core/GRPO-family/GRPO/" class="">(原理)GRPO</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/RL/core/compare/" class="">(原理) 综述</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/RL/core/DPO/" class="">(原理|实现)DPO</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/RL/core/unified/" class="">unified paradigm</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-6e820217fb4ea1d6cfba6041f84f71d5" class="toggle"  />
    <label for="section-6e820217fb4ea1d6cfba6041f84f71d5" class="flex justify-between">
      <a role="button" class="">Deep Research</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-f7109e1e6e5f757bc2eb5a41da8bed9a" class="toggle"  />
    <label for="section-f7109e1e6e5f757bc2eb5a41da8bed9a" class="flex justify-between">
      <a role="button" class="">Search</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/RL/Deep-Research/Search/Search-R1/" class="">Search-R1</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/RL/Deep-Research/Search/websailer/" class="">WebSailor</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/RL/Deep-Research/Search/Kimi-Researcher/" class="">Kimi-Researcher</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-da74d49476c904de0c477669d9aed65c" class="toggle"  />
    <label for="section-da74d49476c904de0c477669d9aed65c" class="flex justify-between">
      <a role="button" class="">Survey</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/RL/Deep-Research/Survey/Survey/" class="">Survey</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-cd468af946713c742ccdb635ec20a709" class="toggle"  />
    <label for="section-cd468af946713c742ccdb635ec20a709" class="flex justify-between">
      <a role="button" class="">Agentic RL</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-99414e52e25eeac060b84b3a14f1049c" class="toggle"  />
    <label for="section-99414e52e25eeac060b84b3a14f1049c" class="flex justify-between">
      <a role="button" class="">Survey</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/RL/Agentic-RL/survey/survey/" class="">(Survey)Agentic RL</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-e5627b4d6fcbd271891b0c243d5abda5" class="toggle"  />
    <label for="section-e5627b4d6fcbd271891b0c243d5abda5" class="flex justify-between">
      <a role="button" class="">Tool</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/RL/Agentic-RL/Tool/OTC/" class="">OTC</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/RL/Agentic-RL/Tool/ReTool/" class="">ReTool</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/RL/Agentic-RL/Tool/ToolRL/" class="">ToolRL</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-d720d571cb3e63953708e846bc3c9da9" class="toggle"  />
    <label for="section-d720d571cb3e63953708e846bc3c9da9" class="flex justify-between">
      <a role="button" class="">Framework</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/RL/framework/verl/" class="">HybridFlow[veRL]</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/RL/framework/veRLConfig/" class="">(原理&amp;实战)veRL Config</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <input type="checkbox" id="section-74da2f7bc7a3fb6c948028291efa6462" class="toggle" checked />
    <label for="section-74da2f7bc7a3fb6c948028291efa6462" class="flex justify-between">
      <a role="button" class="">LLM</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-50717b22c392318484ed92082d544dd2" class="toggle"  />
    <label for="section-50717b22c392318484ed92082d544dd2" class="flex justify-between">
      <a role="button" class="">Survey</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Survey/LargeModelSurvey/" class="">(综述)大模型</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Survey/LargeModel/" class="">大模型</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Survey/LeaderBoard/" class="">大模型 排行榜</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-fb69e8f04a6f9bb8fb43ebdb9607c2d9" class="toggle"  />
    <label for="section-fb69e8f04a6f9bb8fb43ebdb9607c2d9" class="flex justify-between">
      <a role="button" class="">Dense</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Dense/Family/" class="">GPT 系列</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Dense/Llama/" class="">LLaMA</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Dense/LlamaFamily/" class="">LLaMA 家族</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Dense/Llama3-1/" class="">Llama3.1</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Dense/BERT/" class="">(原理)BERT</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-00115c923a3b56db78447633045b86e5" class="toggle" checked />
    <label for="section-00115c923a3b56db78447633045b86e5" class="flex justify-between">
      <a role="button" class="">Reasoning</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-eb6efb7e57d9b3bd5d67d76eb45cf382" class="toggle"  />
    <label for="section-eb6efb7e57d9b3bd5d67d76eb45cf382" class="flex justify-between">
      <a role="button" class="">Survey</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Reasoning/Survey/ReasoningTTS/" class="">(Survey) Test-Time Scaling</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Reasoning/Survey/ReasoningPostTraining/" class="">(Survey)Reasoning LLM Post-Training</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-2d95ba6fdc69c818b831536584a44b3e" class="toggle"  />
    <label for="section-2d95ba6fdc69c818b831536584a44b3e" class="flex justify-between">
      <a role="button" class="">R1</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Reasoning/R1/DeepseekDistill/" class="">(实战)Deepseek 蒸馏</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Reasoning/R1/DeepseekSFT/" class="">(实战)Deepseek R1 SFT</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Reasoning/R1/DeepSeekExplain2/" class="">解读 DeepSeek[邱锡鹏]</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Reasoning/R1/DeepSeekExplain1/" class="">解读 DeepSeek[刘知远]</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Reasoning/R1/ReasoningLLM/" class="">(原理)Reasoning LLM</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Reasoning/R1/DeepSeekR1/" class="">(原理) DeepSeek R1</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-f93f1ae6af7e9a9bbf26ec16ed8e350e" class="toggle"  />
    <label for="section-f93f1ae6af7e9a9bbf26ec16ed8e350e" class="flex justify-between">
      <a role="button" class="">V3</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Reasoning/V3/DeepSeek/" class="">DeepSeek V3</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-1a4f5c4ee7bee807e0e4278f7f7d8719" class="toggle"  />
    <label for="section-1a4f5c4ee7bee807e0e4278f7f7d8719" class="flex justify-between">
      <a role="button" class="">Qwen</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Reasoning/Qwen/Qwen3/" class="">Qwen3</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Reasoning/Qwen/Qwen3-report/" class="">Qwen3 Report</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-d9743338127b6aab5ee87bc9bc97be5e" class="toggle" checked />
    <label for="section-d9743338127b6aab5ee87bc9bc97be5e" class="flex justify-between">
      <a role="button" class="">kimi</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Reasoning/kimi/kimi-k2/" class="">kimi k2</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Reasoning/kimi/kimi1.5/" class="active">Kimi1.5</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-6d0afc3f46dbf37aaf932c7a930559a9" class="toggle"  />
    <label for="section-6d0afc3f46dbf37aaf932c7a930559a9" class="flex justify-between">
      <a role="button" class="">Overthinking</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Reasoning/Overthinking/survey/" class="">(Survey)Overthinking</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-5366419f34f701d933f9513a09b5b014" class="toggle"  />
    <label for="section-5366419f34f701d933f9513a09b5b014" class="flex justify-between">
      <a role="button" class="">快慢思考</a>
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-69a7d42415bc536b90d48518db8c889c" class="toggle"  />
    <label for="section-69a7d42415bc536b90d48518db8c889c" class="flex justify-between">
      <a role="button" class="">MOE</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/MoE/ModelMOE/" class="">(原理)Visual  MOE</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/MoE/ModelMOECode/" class="">(代码)MOE</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-d3ad2ad02a69d9fe3f2c5be5fef9a925" class="toggle"  />
    <label for="section-d3ad2ad02a69d9fe3f2c5be5fef9a925" class="flex justify-between">
      <a role="button" class="">Core</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Core/ScalingLaw/" class="">Scaling Law</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Core/Emergent/" class="">(原理)涌现现象</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Core/Hallucination/" class="">(原理)幻觉问题</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Core/ImpossibleTriangle/" class="">(原理)不可能三角</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Core/Eval/" class="">测评 *</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>














</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/www6vAlgo/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <h3>Kimi1.5</h3>

  <label for="toc-control">
    
    <img src="/www6vAlgo/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#论文">论文</a></li>
    <li><a href="#kimi-k15-技术报告深度解读-kimi-k15-paper-reading-notes">Kimi K1.5 技术报告深度解读 (Kimi K1.5 Paper Reading Notes)</a>
      <ul>
        <li>
          <ul>
            <li><a href="#0-背景-background">0. 背景 (Background)</a></li>
            <li><a href="#1-整体架构-overall-architecture">1. 整体架构 (Overall Architecture)</a></li>
            <li><a href="#2-预训练-pre-training">2. 预训练 (Pre-training)</a></li>
            <li><a href="#3-sft-训练-sft-training">3. SFT 训练 (SFT Training)</a></li>
            <li><a href="#4-强化学习-rl重点-2">4. 强化学习 (RL)（重点 2）</a></li>
            <li><a href="#5-实验结论-experimental-conclusions">5. 实验结论 (Experimental Conclusions)</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#参考">参考</a></li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown book-article"><h1 id="论文">
  论文
  <a class="anchor" href="#%e8%ae%ba%e6%96%87">#</a>
</h1>
<p><a href="https://arxiv.org/pdf/2501.12599">KIMI K1.5:SCALING REINFORCEMENT LEARNING WITH LLMS</a></p>
<p><a href="https://github.com/MoonshotAI/Kimi-k1.5">git</a></p>
<h1 id="kimi-k15-技术报告深度解读-kimi-k15-paper-reading-notes">
  Kimi K1.5 技术报告深度解读 (Kimi K1.5 Paper Reading Notes)
  <a class="anchor" href="#kimi-k15-%e6%8a%80%e6%9c%af%e6%8a%a5%e5%91%8a%e6%b7%b1%e5%ba%a6%e8%a7%a3%e8%af%bb-kimi-k15-paper-reading-notes">#</a>
</h1>
<h3 id="0-背景-background">
  0. 背景 (Background)
  <a class="anchor" href="#0-%e8%83%8c%e6%99%af-background">#</a>
</h3>
<ul>
<li><strong>发布 (Release):</strong> 2025年1月20日 (与 DeepSeek-R1 同时期)。</li>
<li><strong>效果 (Achievement):</strong> 达到了与 OpenAI-O1 模型相似的效果。</li>
<li><strong>价值 (Significance):</strong> 报告中包含更多可供算法工程师和研究人员参考的<strong>算法处理细节</strong>，特别是关于如何处理数据以增强推理能力。</li>
</ul>
<hr>
<h3 id="1-整体架构-overall-architecture">
  1. 整体架构 (Overall Architecture)
  <a class="anchor" href="#1-%e6%95%b4%e4%bd%93%e6%9e%b6%e6%9e%84-overall-architecture">#</a>
</h3>
<ul>
<li>遵循与 ChatGPT 相似的标准流程：
<ol>
<li><strong>预训练 (Pre-training)</strong></li>
<li><strong>SFT 训练 (Supervised Fine-Tuning)</strong></li>
<li><strong>强化学习 (RL)</strong></li>
</ol>
</li>
</ul>
<hr>
<h3 id="2-预训练-pre-training">
  2. 预训练 (Pre-training)
  <a class="anchor" href="#2-%e9%a2%84%e8%ae%ad%e7%bb%83-pre-training">#</a>
</h3>
<ul>
<li><strong>基础模型 (Base Model):</strong> 在多样化、高质量的多模态语料库上训练 (包括：英、中、代码、数学、知识、图像描述等)。</li>
<li><strong>训练阶段 (Phases):</strong> 分三个阶段进行
<ol>
<li><strong>视觉-语言预训练 (Vision-Language Pre-training):</strong> 先训练 LLM，然后逐步整合多模态能力 (Vision Tower 独立训练，然后加入图文交织数据并更新 LLM 参数)。</li>
<li><strong>冷却阶段 (Cooling Down):</strong> 利用精选和合成数据巩固模型能力，尤其针对推理和知识任务 (使用<strong>拒绝采样</strong>保证质量)。</li>
<li><strong>长上下文激活阶段 (Long-Context Activation):</strong>
<ul>
<li><strong>目标:</strong> 将序列处理能力扩展到 <strong>131,072 Token</strong>。</li>
<li><strong>方法:</strong>
<ul>
<li>过采样 Long-Context 数据 (40% 全注意力，60% 部分注意力)。</li>
<li>逐步训练：4k -&gt; 32k -&gt; 128k。</li>
</ul>
</li>
</ul>
</li>
</ol>
</li>
</ul>
<hr>
<h3 id="3-sft-训练-sft-training">
  3. SFT 训练 (SFT Training)
  <a class="anchor" href="#3-sft-%e8%ae%ad%e7%bb%83-sft-training">#</a>
</h3>
<h4 id="31-常规的-sft-standard-sft">
  3.1. 常规的 SFT (Standard SFT)
  <a class="anchor" href="#31-%e5%b8%b8%e8%a7%84%e7%9a%84-sft-standard-sft">#</a>
</h4>
<ul>
<li><strong>数据构建 (Data Construction):</strong> 通过人工标注构建种子集，用种子模型生成回复，再进行排序和优化 (对推理任务使用基于规则/奖励模型的<strong>拒绝采样</strong>扩充)。</li>
<li><strong>数据分布 (Data Distribution):</strong> 总计约 100 万样本，涵盖通用问答、编码、数学/科学、长上下文任务及文本-视觉示例。</li>
</ul>
<h4 id="32-long-cot-sft-重点-1">
  3.2. Long-CoT SFT (重点 1)
  <a class="anchor" href="#32-long-cot-sft-%e9%87%8d%e7%82%b9-1">#</a>
</h4>
<ul>
<li><strong>目的 (Purpose):</strong> 获得长链思维 (Long-CoT) 能力。</li>
<li><strong>数据特点 (Data Characteristics):</strong> 答案部分较长，且蕴含<strong>人类思考过程</strong> (规划、评估、反思、探索)。</li>
</ul>
<hr>
<h3 id="4-强化学习-rl重点-2">
  4. 强化学习 (RL)（重点 2）
  <a class="anchor" href="#4-%e5%bc%ba%e5%8c%96%e5%ad%a6%e4%b9%a0-rl%e9%87%8d%e7%82%b9-2">#</a>
</h3>
<h4 id="41-rl-数据集构建-dataset-construction">
  4.1. RL 数据集构建 (Dataset Construction)
  <a class="anchor" href="#41-rl-%e6%95%b0%e6%8d%ae%e9%9b%86%e6%9e%84%e5%bb%ba-dataset-construction">#</a>
</h4>
<ul>
<li><strong>衡量属性 (Key Properties):</strong>
<ul>
<li><strong>多样性 (Diversity):</strong> 保证数据来源和领域丰富，通过<strong>标签系统</strong>打标。</li>
<li><strong>难度平衡 (Difficulty Balance):</strong> 对问题进行难度分级 (基于高温度回复通过率)。采用<strong>课程学习 (Curriculum Learning)</strong>，先学简单，再学复杂。</li>
<li><strong>精确评估 (Accurate Evaluation):</strong> 移除难以精确评估的问题 (如多选题、对错题、证明题)，以及容易被 <strong>Hack</strong> 的 Prompt。</li>
</ul>
</li>
</ul>
<h4 id="42-问题定义-problem-definition">
  4.2. 问题定义 (Problem Definition)
  <a class="anchor" href="#42-%e9%97%ae%e9%a2%98%e5%ae%9a%e4%b9%89-problem-definition">#</a>
</h4>
<ul>
<li>核心是将优化问题转化为最大化<strong>最终答案</strong> (y) 和<strong>思考过程</strong> (Z) 的奖励 (r) 的期望。</li>
</ul>
<h4 id="43-策略优化-policy-optimization">
  4.3. 策略优化 (Policy Optimization)
  <a class="anchor" href="#43-%e7%ad%96%e7%95%a5%e4%bc%98%e5%8c%96-policy-optimization">#</a>
</h4>
<ul>
<li><strong>优化目标 (Optimization Goal):</strong> 将 RL 期望最大化转化为 Loss 函数进行优化 (通过梯度上升)。</li>
<li><strong>关键点 (Key Details):</strong>
<ul>
<li><u>移除了 <strong>Value Model</strong> (与 DeepSeek-R1 相似)，认为错误路径也有助益。</u></li>
<li><u>设计了<strong>长度惩罚奖励</strong> (Length Penalty) 来减少模型过度思考 (越长奖励越小)。</u></li>
</ul>
</li>
</ul>
<h4 id="44-采样策略-sampling-strategy">
  4.4. 采样策略 (Sampling Strategy)
  <a class="anchor" href="#44-%e9%87%87%e6%a0%b7%e7%ad%96%e7%95%a5-sampling-strategy">#</a>
</h4>
<ul>
<li>采用 Off-policy 训练，使用：
<ul>
<li><strong>课程采样 (Curriculum Sampling):</strong> 从简单任务过渡到复杂任务。</li>
<li><strong>优先采样策略 (Priority Sampling):</strong> 重点训练模型表现不佳的问题 (按 1−si 比例采样，si 为成功率)。</li>
</ul>
</li>
</ul>
<h4 id="45-long2short-重点-3">
  4.5. Long2short (重点 3)
  <a class="anchor" href="#45-long2short-%e9%87%8d%e7%82%b9-3">#</a>
</h4>
<ul>
<li><strong>目的 (Purpose):</strong> 实现长链推理 (Long-CoT) 到短链推理 (Short-CoT) 的高效迁移，提升响应速度。</li>
<li><strong>方法 (Methods):</strong>
<ul>
<li><u><strong>模型融合 (Model Fusion):</strong> Long/Short 模型权重直接融合。</u></li>
<li><strong>最短拒绝采样 (Shortest Refusal Sampling):</strong> 生成多条样本，选最短且正确的。</li>
<li><strong>长短样本的 DPO (DPO):</strong> 短而正确的作为正样本，错误或 1.5 倍长于短样本的作为负样本。</li>
<li><u><strong>Long2short 强化学习:</strong> 在一阶段 RL 后，使用长度惩罚减少生成长度。</u></li>
</ul>
</li>
</ul>
<h4 id="46-其他细节-other-details">
  4.6. 其他细节 (Other Details)
  <a class="anchor" href="#46-%e5%85%b6%e4%bb%96%e7%bb%86%e8%8a%82-other-details">#</a>
</h4>
<ul>
<li><strong>代码 (Code):</strong> 自动生成测试用例作为奖励 (使用 CYaRon，并对生成的测试用例进行严格筛选验证)。</li>
<li><strong>数学 (Math):</strong> 采用<strong>思维链奖励模型 (Chain-of-Thought RM)</strong> 提高评估不同答案书写形式的准确性。</li>
<li><strong>视觉数据 (Vision Data):</strong> Vision RL 数据来自真实世界、合成视觉推理和文本渲染数据 (如将文本、代码转为图像)。</li>
</ul>
<hr>
<h3 id="5-实验结论-experimental-conclusions">
  5. 实验结论 (Experimental Conclusions)
  <a class="anchor" href="#5-%e5%ae%9e%e9%aa%8c%e7%bb%93%e8%ae%ba-experimental-conclusions">#</a>
</h3>
<ul>
<li>Kimi-K1.5 在主要数据集上表现出色，是首个追平 OpenAI-O1 的<strong>多模态大模型</strong>。</li>
<li><strong>自我进化 (Self-Evolution):</strong> 随着训练，模型自发输出更长的 CoT，且效果更好。</li>
<li><strong>课程学习 (Curriculum Learning):</strong> 课程采样策略能有效提升模型能力，防止过早饱和。</li>
<li><strong>负样本梯度 (Negative Sample Gradient):</strong> 实验证明，使用负样本 (奖励低于平均值的样本) 对模型能力提升有益。</li>
</ul>
<h1 id="参考">
  参考
  <a class="anchor" href="#%e5%8f%82%e8%80%83">#</a>
</h1>
<p><a href="https://yuanchaofa.com/post/kimi-k1.5-paper-reading-notes.html">深度解读 Kimi-K1.5，真正了解 RL 数据是怎么筛选的</a> *** <br>
<a href="https://mp.weixin.qq.com/s/E6_5_e2Td35h3j11c1V84Q">细节之王 Kimi K1.5，大模型算法工程师复现推理模型必读文章之一</a> <br>
由 Gemimi 辅助生成</p>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">





</div>



  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#论文">论文</a></li>
    <li><a href="#kimi-k15-技术报告深度解读-kimi-k15-paper-reading-notes">Kimi K1.5 技术报告深度解读 (Kimi K1.5 Paper Reading Notes)</a>
      <ul>
        <li>
          <ul>
            <li><a href="#0-背景-background">0. 背景 (Background)</a></li>
            <li><a href="#1-整体架构-overall-architecture">1. 整体架构 (Overall Architecture)</a></li>
            <li><a href="#2-预训练-pre-training">2. 预训练 (Pre-training)</a></li>
            <li><a href="#3-sft-训练-sft-training">3. SFT 训练 (SFT Training)</a></li>
            <li><a href="#4-强化学习-rl重点-2">4. 强化学习 (RL)（重点 2）</a></li>
            <li><a href="#5-实验结论-experimental-conclusions">5. 实验结论 (Experimental Conclusions)</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#参考">参考</a></li>
  </ul>
</nav>


 
      </div>
    </aside>
    
  </main>

  
</body>
</html>












