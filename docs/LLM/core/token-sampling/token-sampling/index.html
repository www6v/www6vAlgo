<!DOCTYPE html>
<html lang="en" dir="ltr">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="
  Token 采样方法（Token Sampling Methods）
  #



  概述
  #


生成式大语言模型（LLM）将输入和输出文本理解为“token”序列；这些 token 可以是单词，也可以是标点符号或单词的一部分。
LLM 提供若干 token 选择参数，用以控制推理/运行时输出的随机性。选择输出 token 的方法（具体称为 token 采样方法 或 解码策略），是语言模型文本生成中的一个核心概念。
从技术底层来看，token 采样的核心是：模型不断生成一个称为概率分布的数学函数，用于决定下一个 token（例如单词）——这一决策会考虑所有先前已输出的 token。简单来说，LLM 在生成文本时执行的是采样：即根据条件概率分布随机选择下一个单词。
以 OpenAI 托管的系统（例如 ChatGPT）为例：在生成概率分布后，OpenAI 的服务器会根据该分布进行 token 采样。该过程存在一定随机性，因此相同的输入提示可能产生不同的输出。
本指南将介绍不同的 token 采样方法及相关概念，包括：温度（Temperature）、贪心解码、穷举搜索解码、束搜索、Top-$k$、Top-$p$（核心采样）以及 Min-$p$。



  背景
  #


  自回归解码（Autoregressive Decoding）
  #


在使用语言模型生成文本序列时，我们通常从一段文本前缀（即提示 prompt）开始，然后按以下步骤循环：

使用语言模型预测下一个 token；
将该 token 加入当前输入序列；
重复上述过程。


通过这种持续生成下一个 token 的方式（即 自回归解码），我们可以生成整个文本序列（见下图；来源）。



  Token 概率
  #


那么，我们该如何选择/预测下一个 token（即上述第 1 步）？
语言模型并不直接输出下一个 token，而是输出一个所有可能 token 的概率分布。简言之，LLM 本质上是在词汇表（所有唯一 token 的集合）上进行分类任务的神经网络。
基于该概率分布，我们可以采用多种策略来选择下一个 token。例如，后文将介绍的贪心解码（greedy decoding）直接选择概率最高的 token 作为下一个输出。


  Logits 与 Softmax
  #


LLM 通过 logits 向量 $\mathbf{z} = (z_1, \dots, z_n)$ 表示类别打分，并使用 softmax 函数 将其转化为概率向量 $\mathbf{q} = (q_1, \dots, q_n)$：
$$
q_i = \frac{\exp(z_i)}{\sum_j \exp(z_j)}
$$
Softmax 函数通过对 logits 取指数并归一化，使得模型在每个时间步的输出均落在 $[0, 1]$ 区间，且总和为 1，从而便于将输出解释为概率（见下图；来源）。

">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="#343a40">
<meta name="color-scheme" content="light dark"><meta property="og:url" content="https://www6v.github.io/www6vAlgo/docs/LLM/Core/token-sampling/token-sampling/">
  <meta property="og:site_name" content="LLM 算法">
  <meta property="og:title" content="(翻译)token sampling">
  <meta property="og:description" content="Token 采样方法（Token Sampling Methods） # 概述 # 生成式大语言模型（LLM）将输入和输出文本理解为“token”序列；这些 token 可以是单词，也可以是标点符号或单词的一部分。 LLM 提供若干 token 选择参数，用以控制推理/运行时输出的随机性。选择输出 token 的方法（具体称为 token 采样方法 或 解码策略），是语言模型文本生成中的一个核心概念。 从技术底层来看，token 采样的核心是：模型不断生成一个称为概率分布的数学函数，用于决定下一个 token（例如单词）——这一决策会考虑所有先前已输出的 token。简单来说，LLM 在生成文本时执行的是采样：即根据条件概率分布随机选择下一个单词。 以 OpenAI 托管的系统（例如 ChatGPT）为例：在生成概率分布后，OpenAI 的服务器会根据该分布进行 token 采样。该过程存在一定随机性，因此相同的输入提示可能产生不同的输出。 本指南将介绍不同的 token 采样方法及相关概念，包括：温度（Temperature）、贪心解码、穷举搜索解码、束搜索、Top-$k$、Top-$p$（核心采样）以及 Min-$p$。 背景 # 自回归解码（Autoregressive Decoding） # 在使用语言模型生成文本序列时，我们通常从一段文本前缀（即提示 prompt）开始，然后按以下步骤循环： 使用语言模型预测下一个 token； 将该 token 加入当前输入序列； 重复上述过程。 通过这种持续生成下一个 token 的方式（即 自回归解码），我们可以生成整个文本序列（见下图；来源）。 Token 概率 # 那么，我们该如何选择/预测下一个 token（即上述第 1 步）？ 语言模型并不直接输出下一个 token，而是输出一个所有可能 token 的概率分布。简言之，LLM 本质上是在词汇表（所有唯一 token 的集合）上进行分类任务的神经网络。 基于该概率分布，我们可以采用多种策略来选择下一个 token。例如，后文将介绍的贪心解码（greedy decoding）直接选择概率最高的 token 作为下一个输出。 Logits 与 Softmax # LLM 通过 logits 向量 $\mathbf{z} = (z_1, \dots, z_n)$ 表示类别打分，并使用 softmax 函数 将其转化为概率向量 $\mathbf{q} = (q_1, \dots, q_n)$： $$ q_i = \frac{\exp(z_i)}{\sum_j \exp(z_j)} $$ Softmax 函数通过对 logits 取指数并归一化，使得模型在每个时间步的输出均落在 $[0, 1]$ 区间，且总和为 1，从而便于将输出解释为概率（见下图；来源）。">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="website">
<title>(翻译)token sampling | LLM 算法</title>
<link rel="icon" href="/www6vAlgo/favicon.png" >
<link rel="manifest" href="/www6vAlgo/manifest.json">
<link rel="canonical" href="https://www6v.github.io/www6vAlgo/docs/LLM/Core/token-sampling/token-sampling/">
<link rel="stylesheet" href="/www6vAlgo/book.min.6c8b9d2a1fc95075ed7da46ca81060b39add8fff6741ac51259f768929281e2c.css" integrity="sha256-bIudKh/JUHXtfaRsqBBgs5rdj/9nQaxRJZ92iSkoHiw=" crossorigin="anonymous">
  <script defer src="/www6vAlgo/fuse.min.js"></script>
  <script defer src="/www6vAlgo/en.search.min.ea12ef67c19b88b5e61887bfa4621533e23e4168c3d8169284162e3fc7caee6f.js" integrity="sha256-6hLvZ8GbiLXmGIe/pGIVM&#43;I&#43;QWjD2BaShBYuP8fK7m8=" crossorigin="anonymous"></script>
<link rel="alternate" type="application/rss+xml" href="https://www6v.github.io/www6vAlgo/docs/LLM/Core/token-sampling/token-sampling/index.xml" title="LLM 算法" />
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  
</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/www6vAlgo/"><span>LLM 算法</span>
  </a>
</h2>


<div class="book-search hidden">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>
<script>document.querySelector(".book-search").classList.remove("hidden")</script>















  
  <ul>
    
      
        <li class="book-section-flat" >
          
  
  

  
    <input type="checkbox" id="section-ca51f083a72ceb6f7ce7aac637ec4cff" class="toggle"  />
    <label for="section-ca51f083a72ceb6f7ce7aac637ec4cff" class="flex justify-between">
      <a role="button" class="">DeepLearning</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-ca800fece441ac3e580321c74f3e9d49" class="toggle"  />
    <label for="section-ca800fece441ac3e580321c74f3e9d49" class="flex justify-between">
      <a role="button" class="">basic</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/basic/DeepLearning/" class="">Deep Learning</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/basic/DeeplearningForwardBackward/" class="">(原理&amp;实战)前向/反向传播</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/basic/DeeplearningLoss/" class="">(原理&amp;实战)交叉熵损失</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/basic/DeeplearningOverfitting/" class="">(原理)过拟合</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/basic/Pytorch/" class="">(实战)PyTorch</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-1a190617d0c8a17ae9ae2d3ed30bd150" class="toggle"  />
    <label for="section-1a190617d0c8a17ae9ae2d3ed30bd150" class="flex justify-between">
      <a role="button" class="">正则化</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/%E6%AD%A3%E5%88%99%E5%8C%96/WeightDecay/" class="">(原理&amp;实战)权重衰减</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/%E6%AD%A3%E5%88%99%E5%8C%96/Dropout/" class="">(原理&amp;实战)Dropout</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-1424866912bd75b061251f3b3e940596" class="toggle"  />
    <label for="section-1424866912bd75b061251f3b3e940596" class="flex justify-between">
      <a role="button" class="">网络优化</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96/DeeplearningLearningRate/" class="">(原理)学习率</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96/DeeplearningBatchsize/" class="">(原理)Batchsize</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96/DeeplearningNorm/" class="">规范化 Norm</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96/DeeplearningGradOpt/" class="">(原理)梯度优化</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-d175a581e6d1d294c2886df9f4e638fd" class="toggle"  />
    <label for="section-d175a581e6d1d294c2886df9f4e638fd" class="flex justify-between">
      <a role="button" class="">Transformer</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/Transformer/Transformer/" class="">(原理)Transformer</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/Transformer/SelfAttention/" class="">(原理)Self-Attention</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/Transformer/ModelGQA/" class="">(原理)GQA</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/Transformer/TransformerCode/" class="">(实战)Transformer</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/Transformer/TrainTokenizer/" class="">Tokenizer</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-986dec1b5e65fdcdcaa6d6a6bdce0c55" class="toggle"  />
    <label for="section-986dec1b5e65fdcdcaa6d6a6bdce0c55" class="flex justify-between">
      <a role="button" class="">Embedding</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/Transformer/Embedding/survey/" class="">(Survey)Embedding</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/DeepLearning/Transformer/Embedding/Embedding/" class="">(原理)Embedding</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <input type="checkbox" id="section-47d8239bc563cf0526676851b768f952" class="toggle"  />
    <label for="section-47d8239bc563cf0526676851b768f952" class="flex justify-between">
      <a role="button" class="">机器学习</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/MLData/" class="">机器学习-数据</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/MLModel/" class="">机器学习-模型</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <input type="checkbox" id="section-8289f046e5a8f2479317b06c48dded09" class="toggle"  />
    <label for="section-8289f046e5a8f2479317b06c48dded09" class="flex justify-between">
      <a role="button" class="">强化学习</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-fd4324249788d4f101352645b9815095" class="toggle"  />
    <label for="section-fd4324249788d4f101352645b9815095" class="flex justify-between">
      <a role="button" class="">Core</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-a4b91a8ec30520aa20445e5046653468" class="toggle"  />
    <label for="section-a4b91a8ec30520aa20445e5046653468" class="flex justify-between">
      <a role="button" class="">PPO family</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/RL/core/PPO-family/PPO/" class="">(原理)PPO</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/RL/core/PPO-family/PPO1/" class="">(原理)PPO</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/RL/core/PPO-family/RewardModel/" class="">(原理|实现)PPO-RewardModel</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-792edea28c7fa6c149b193954c187e3e" class="toggle"  />
    <label for="section-792edea28c7fa6c149b193954c187e3e" class="flex justify-between">
      <a role="button" class="">GRPO Family</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/RL/core/GRPO-family/GRPODeepseek/" class="">(实战)GRPO</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/RL/core/GRPO-family/GRPO/" class="">(原理)GRPO</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/RL/core/GRPO-family/DAPO/" class="">(原理)DAPO</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/RL/core/compare/" class="">(原理) 综述</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/RL/core/DPO/" class="">(原理|实现)DPO</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/RL/core/unified/" class="">unified paradigm</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/RL/core/RLVR/" class="">RLVR</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-d720d571cb3e63953708e846bc3c9da9" class="toggle"  />
    <label for="section-d720d571cb3e63953708e846bc3c9da9" class="flex justify-between">
      <a role="button" class="">Framework</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/RL/framework/verl/" class="">HybridFlow[veRL]</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/RL/framework/veRLConfig/" class="">(原理&amp;实战)veRL Config</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <input type="checkbox" id="section-4e4529562f8a7b2d9d29129d5ea9bac5" class="toggle"  />
    <label for="section-4e4529562f8a7b2d9d29129d5ea9bac5" class="flex justify-between">
      <a role="button" class="">Agent</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-60b219d176761004985eb3d1d13b669b" class="toggle"  />
    <label for="section-60b219d176761004985eb3d1d13b669b" class="flex justify-between">
      <a role="button" class="">Deep Research</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-2b697507cc5afe0d0d3a9e33baa16d54" class="toggle"  />
    <label for="section-2b697507cc5afe0d0d3a9e33baa16d54" class="flex justify-between">
      <a role="button" class="">Search</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/Agent/Deep-Research/Search/Search-R1/" class="">Search-R1</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/Agent/Deep-Research/Search/websailer/" class="">WebSailor</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/Agent/Deep-Research/Search/Kimi-Researcher/" class="">Kimi-Researcher</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/Agent/Deep-Research/Search/websailerNT/" class="">WebSailor</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-f0f072a0394d584d8a25ad8b8d2e588d" class="toggle"  />
    <label for="section-f0f072a0394d584d8a25ad8b8d2e588d" class="flex justify-between">
      <a role="button" class="">Survey</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/Agent/Deep-Research/Survey/Survey/" class="">Survey</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/Agent/Deep-Research/Survey/TongyiDeepresearchNT/" class="">Tongyi DeepResearch</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-ea73c6f1ab732373f29d955cc823fb27" class="toggle"  />
    <label for="section-ea73c6f1ab732373f29d955cc823fb27" class="flex justify-between">
      <a role="button" class="">Agentic RL</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-0d41075c5b4525f04c44a1ab283f6633" class="toggle"  />
    <label for="section-0d41075c5b4525f04c44a1ab283f6633" class="flex justify-between">
      <a role="button" class="">Survey</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/Agent/Agentic-RL/survey/survey/" class="">(Survey)Agentic RL</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-e93f77db75a578ffc7c9756362505d3f" class="toggle"  />
    <label for="section-e93f77db75a578ffc7c9756362505d3f" class="flex justify-between">
      <a role="button" class="">Tool</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/Agent/Agentic-RL/Tool/OTC/" class="">OTC</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/Agent/Agentic-RL/Tool/ReTool/" class="">ReTool</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/Agent/Agentic-RL/Tool/ToolRL/" class="">ToolRL</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <input type="checkbox" id="section-fca7377f53eb51ab1d7b6d1f58ad9c91" class="toggle"  />
    <label for="section-fca7377f53eb51ab1d7b6d1f58ad9c91" class="flex justify-between">
      <a role="button" class="">Vision</a>
    </label>
  

          
  <ul>
    
      
        <li class="book-section-flat" >
          
  
  

  
    <input type="checkbox" id="section-9e1a963dfeb6e817c8f06c525517844e" class="toggle"  />
    <label for="section-9e1a963dfeb6e817c8f06c525517844e" class="flex justify-between">
      <a role="button" class="">Vision Encoder</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/Vision/Vision-Encoder/gptMultimodalVQVAE/" class="">VQ-VAE</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/Vision/Vision-Encoder/gptMultimodalDINO/" class="">DINO</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/Vision/Vision-Encoder/gptMultimodalCLIP/" class="">(原理)CLIP</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/Vision/Vision-Encoder/gptMultimodalVit/" class="">(原理|实战)ViT, ViLT</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/Vision/Vision-Encoder/gptMultimodalCLIPPractice/" class="">(实战)CLIP</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <input type="checkbox" id="section-dd16fd431323663dddc23925585a56f3" class="toggle"  />
    <label for="section-dd16fd431323663dddc23925585a56f3" class="flex justify-between">
      <a role="button" class="">Diffusion</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/Vision/Diffusion/gptDiffusionunCLIP/" class="">(原理)unCLIP</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/Vision/Diffusion/gptDiffusionGuidance/" class="">(原理)Guidance</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/Vision/Diffusion/gptDiffusionXL/" class="">(原理)SD XL</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/Vision/Diffusion/gptMultimodalDiffusion/" class="">(原理)Stable Diffusion</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/Vision/Diffusion/gptMultimodalDiffusionPractice/" class="">(实战)Stable Diffusion</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <input type="checkbox" id="section-949324082ef5fcbe8b53145be096f75a" class="toggle"  />
    <label for="section-949324082ef5fcbe8b53145be096f75a" class="flex justify-between">
      <a role="button" class="">Segmentation</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/Vision/seg/gptMultimodalSAM/" class="">(原理|实战) SAM</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/Vision/MultimodalConnector/" class="">(原理)Connector</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <input type="checkbox" id="section-74da2f7bc7a3fb6c948028291efa6462" class="toggle" checked />
    <label for="section-74da2f7bc7a3fb6c948028291efa6462" class="flex justify-between">
      <a role="button" class="">LLM</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-50717b22c392318484ed92082d544dd2" class="toggle"  />
    <label for="section-50717b22c392318484ed92082d544dd2" class="flex justify-between">
      <a role="button" class="">Survey</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Survey/LargeModelSurvey/" class="">(综述)大模型</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Survey/LargeModel/" class="">大模型</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Survey/LLM-Deep-Dive/" class="">LLM Deep Dive</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Survey/LLM-Compare/" class="">LLM架构演进</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Survey/LeaderBoard/" class="">大模型 排行榜</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-fb69e8f04a6f9bb8fb43ebdb9607c2d9" class="toggle"  />
    <label for="section-fb69e8f04a6f9bb8fb43ebdb9607c2d9" class="flex justify-between">
      <a role="button" class="">Dense</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Dense/Family/" class="">GPT 系列</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Dense/Llama/" class="">LLaMA</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Dense/LlamaFamily/" class="">LLaMA 家族</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Dense/Llama3-1/" class="">Llama3.1</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Dense/BERT/" class="">(原理)BERT</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-00115c923a3b56db78447633045b86e5" class="toggle"  />
    <label for="section-00115c923a3b56db78447633045b86e5" class="flex justify-between">
      <a role="button" class="">Reasoning</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-eb6efb7e57d9b3bd5d67d76eb45cf382" class="toggle"  />
    <label for="section-eb6efb7e57d9b3bd5d67d76eb45cf382" class="flex justify-between">
      <a role="button" class="">Survey</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Reasoning/Survey/ReasoningTTS/" class="">(Survey) Test-Time Scaling</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Reasoning/Survey/ReasoningPostTraining/" class="">(Survey)Reasoning LLM Post-Training</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-1a4f5c4ee7bee807e0e4278f7f7d8719" class="toggle"  />
    <label for="section-1a4f5c4ee7bee807e0e4278f7f7d8719" class="flex justify-between">
      <a role="button" class="">Qwen</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Reasoning/Qwen/Qwen3/" class="">Qwen3</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Reasoning/Qwen/Qwen3-report/" class="">Qwen3 Report</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Reasoning/Qwen/qwen-next/" class="">(原理)Qwen3-Next</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-4a652c2712b37ada613861578ed20563" class="toggle"  />
    <label for="section-4a652c2712b37ada613861578ed20563" class="flex justify-between">
      <a role="button" class="">Deepseek</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-48f04557895a93e37ea069284a46fb42" class="toggle"  />
    <label for="section-48f04557895a93e37ea069284a46fb42" class="flex justify-between">
      <a role="button" class="">Post-training</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Reasoning/Deepseek/post-training/DeepseekDistill/" class="">(实战)Deepseek 蒸馏</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Reasoning/Deepseek/post-training/DeepseekSFT/" class="">(实战)Deepseek R1 SFT</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-3e1c0837357e9aacf6d05cbed5dc4d1f" class="toggle"  />
    <label for="section-3e1c0837357e9aacf6d05cbed5dc4d1f" class="flex justify-between">
      <a role="button" class="">R1</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Reasoning/Deepseek/R1/DeepSeekExplain2/" class="">解读 DeepSeek[邱锡鹏]</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Reasoning/Deepseek/R1/DeepSeekExplain1/" class="">解读 DeepSeek[刘知远]</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Reasoning/Deepseek/R1/ReasoningLLM/" class="">(原理)Reasoning LLM</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Reasoning/Deepseek/R1/DeepSeekR1/" class="">(原理) DeepSeek R1</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-1e90ca9a2107f4bd9f4516a445b1bdcf" class="toggle"  />
    <label for="section-1e90ca9a2107f4bd9f4516a445b1bdcf" class="flex justify-between">
      <a role="button" class="">V3</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Reasoning/Deepseek/V3/DeepSeek/" class="">DeepSeek V3</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-d9743338127b6aab5ee87bc9bc97be5e" class="toggle"  />
    <label for="section-d9743338127b6aab5ee87bc9bc97be5e" class="flex justify-between">
      <a role="button" class="">kimi</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Reasoning/kimi/k2/" class="">(翻译)kimi k2</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Reasoning/kimi/k2-thinking/" class="">Kimi K2 Thinking</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Reasoning/kimi/1.5/" class="">Kimi1.5</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-6d0afc3f46dbf37aaf932c7a930559a9" class="toggle"  />
    <label for="section-6d0afc3f46dbf37aaf932c7a930559a9" class="flex justify-between">
      <a role="button" class="">Overthinking</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Reasoning/Overthinking/survey/" class="">(Survey)Overthinking</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-5366419f34f701d933f9513a09b5b014" class="toggle"  />
    <label for="section-5366419f34f701d933f9513a09b5b014" class="flex justify-between">
      <a role="button" class="">快慢思考</a>
    </label>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-69a7d42415bc536b90d48518db8c889c" class="toggle"  />
    <label for="section-69a7d42415bc536b90d48518db8c889c" class="flex justify-between">
      <a role="button" class="">MOE</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/MoE/ModelMOE/" class="">(原理)Visual  MOE</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/MoE/ModelMOECode/" class="">(代码)MOE</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/MoE/MoE/" class="">(原理)MoE</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-d3ad2ad02a69d9fe3f2c5be5fef9a925" class="toggle" checked />
    <label for="section-d3ad2ad02a69d9fe3f2c5be5fef9a925" class="flex justify-between">
      <a role="button" class="">Core</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Core/ScalingLaw/" class="">Scaling Law</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Core/Emergent/" class="">(原理)涌现现象</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Core/Eval/" class="">测评 *</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-49880184e06fd9cedeebad822a47bb36" class="toggle" checked />
    <label for="section-49880184e06fd9cedeebad822a47bb36" class="flex justify-between">
      <a role="button" class="">Token Sampling</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Core/token-sampling/token-sampling/" class="active">(翻译)token sampling</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/Core/token-sampling/temperature/" class="">Token Sampling Methods</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-dcc7208d3f790b5592723fa605667723" class="toggle"  />
    <label for="section-dcc7208d3f790b5592723fa605667723" class="flex justify-between">
      <a role="button" class="">Challenge</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/challenge/Hallucination/" class="">(原理)幻觉问题</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/www6vAlgo/docs/LLM/challenge/ImpossibleTriangle/" class="">(原理)不可能三角</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>














</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/www6vAlgo/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <h3>(翻译)token sampling</h3>

  <label for="toc-control">
    
    <img src="/www6vAlgo/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#token-采样方法token-sampling-methods">Token 采样方法（Token Sampling Methods）</a>
      <ul>
        <li><a href="#概述">概述</a></li>
        <li><a href="#背景">背景</a>
          <ul>
            <li><a href="#自回归解码autoregressive-decoding">自回归解码（Autoregressive Decoding）</a></li>
            <li><a href="#token-概率">Token 概率</a></li>
            <li><a href="#logits-与-softmax">Logits 与 Softmax</a></li>
          </ul>
        </li>
        <li><a href="#相关概念温度temperature">相关概念：温度（Temperature）</a>
          <ul>
            <li><a href="#温度在-softmax-中的作用">温度在 Softmax 中的作用</a></li>
            <li><a href="#不同温度范围及其影响">不同温度范围及其影响</a></li>
            <li><a href="#softmax-函数的深层理解引自维基百科">Softmax 函数的深层理解（引自维基百科）</a></li>
            <li><a href="#温度影响总结">温度影响总结</a></li>
          </ul>
        </li>
        <li><a href="#贪心解码greedy-decoding">贪心解码（Greedy Decoding）</a></li>
        <li><a href="#穷举搜索解码exhaustive-search-decoding">穷举搜索解码（Exhaustive Search Decoding）</a></li>
        <li><a href="#束搜索beam-search">束搜索（Beam Search）</a></li>
        <li><a href="#约束束搜索constrained-beam-search">约束束搜索（Constrained Beam Search）</a>
          <ul>
            <li><a href="#银行机制banking">银行机制（Banking）</a></li>
          </ul>
        </li>
        <li><a href="#top-k-采样">Top-$k$ 采样</a></li>
        <li><a href="#top-p核心采样--nucleus-sampling">Top-$p$（核心采样 / Nucleus Sampling）</a>
          <ul>
            <li><a href="#实用价值">实用价值</a></li>
            <li><a href="#与温度参数的关系">与温度参数的关系</a></li>
          </ul>
        </li>
        <li><a href="#贪心-vs-top-k-与-top-p">贪心 vs. Top-$k$ 与 Top-$p$</a></li>
        <li><a href="#min-p-采样">Min-$p$ 采样</a>
          <ul>
            <li><a href="#现有方法局限回顾">现有方法局限回顾</a></li>
            <li><a href="#min-p-核心思想">Min-$p$ 核心思想</a></li>
          </ul>
        </li>
        <li><a href="#参考文献">参考文献</a></li>
      </ul>
    </li>
    <li><a href="#参考">参考</a></li>
    <li><a href="#总结kimi">总结（Kimi）</a></li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown book-article"><h1 id="token-采样方法token-sampling-methods">
  Token 采样方法（Token Sampling Methods）
  <a class="anchor" href="#token-%e9%87%87%e6%a0%b7%e6%96%b9%e6%b3%95token-sampling-methods">#</a>
</h1>
<hr>
<h2 id="概述">
  概述
  <a class="anchor" href="#%e6%a6%82%e8%bf%b0">#</a>
</h2>
<ul>
<li>生成式大语言模型（LLM）将输入和输出文本理解为“token”序列；这些 token 可以是单词，也可以是标点符号或单词的一部分。</li>
<li>LLM 提供若干 token 选择参数，用以控制推理/运行时输出的随机性。选择输出 token 的方法（具体称为 <strong>token 采样方法</strong> 或 <strong>解码策略</strong>），是语言模型文本生成中的一个核心概念。</li>
<li>从技术底层来看，token 采样的核心是：模型不断生成一个称为<strong>概率分布</strong>的数学函数，用于决定下一个 token（例如单词）——这一决策会考虑所有先前已输出的 token。简单来说，LLM 在生成文本时执行的是<strong>采样</strong>：即根据条件概率分布<strong>随机选择</strong>下一个单词。</li>
<li>以 OpenAI 托管的系统（例如 ChatGPT）为例：在生成概率分布后，OpenAI 的服务器会根据该分布进行 token 采样。该过程存在一定随机性，因此相同的输入提示可能产生不同的输出。</li>
<li>本指南将介绍不同的 token 采样方法及相关概念，包括：温度（Temperature）、贪心解码、穷举搜索解码、束搜索、Top-$k$、Top-$p$（核心采样）以及 Min-$p$。</li>
</ul>
<hr>
<h2 id="背景">
  背景
  <a class="anchor" href="#%e8%83%8c%e6%99%af">#</a>
</h2>
<h3 id="自回归解码autoregressive-decoding">
  自回归解码（Autoregressive Decoding）
  <a class="anchor" href="#%e8%87%aa%e5%9b%9e%e5%bd%92%e8%a7%a3%e7%a0%81autoregressive-decoding">#</a>
</h3>
<ul>
<li>在使用语言模型生成文本序列时，我们通常从一段文本前缀（即提示 prompt）开始，然后按以下步骤循环：
<ol>
<li>使用语言模型预测下一个 token；</li>
<li>将该 token 加入当前输入序列；</li>
<li>重复上述过程。</li>
</ol>
</li>
<li>通过这种持续生成下一个 token 的方式（即 <strong>自回归解码</strong>），我们可以生成整个文本序列（见下图；来源）。</li>
</ul>
<p><img src="https://aman.ai/primers/ai/assets/token-sampling/ar.jpg" alt="自回归解码示意图" /></p>
<h3 id="token-概率">
  Token 概率
  <a class="anchor" href="#token-%e6%a6%82%e7%8e%87">#</a>
</h3>
<ul>
<li>那么，我们该如何选择/预测下一个 token（即上述第 1 步）？</li>
<li>语言模型并不直接输出下一个 token，而是输出一个<strong>所有可能 token 的概率分布</strong>。简言之，LLM 本质上是在词汇表（所有唯一 token 的集合）上进行分类任务的神经网络。</li>
<li>基于该概率分布，我们可以采用多种策略来选择下一个 token。例如，后文将介绍的<strong>贪心解码</strong>（greedy decoding）直接选择概率最高的 token 作为下一个输出。</li>
</ul>
<h3 id="logits-与-softmax">
  Logits 与 Softmax
  <a class="anchor" href="#logits-%e4%b8%8e-softmax">#</a>
</h3>
<ul>
<li>LLM 通过 logits 向量 $\mathbf{z} = (z_1, \dots, z_n)$ 表示类别打分，并使用 <strong>softmax 函数</strong> 将其转化为概率向量 $\mathbf{q} = (q_1, \dots, q_n)$：
$$
q_i = \frac{\exp(z_i)}{\sum_j \exp(z_j)}
$$</li>
<li>Softmax 函数通过对 logits 取指数并归一化，使得模型在每个时间步的输出均落在 $[0, 1]$ 区间，且总和为 1，从而便于将输出解释为概率（见下图；来源）。</li>
</ul>
<p><img src="https://aman.ai/primers/ai/assets/token-sampling/Softmax.jpg" alt="Softmax 示意图" /></p>
<hr>
<h2 id="相关概念温度temperature">
  相关概念：温度（Temperature）
  <a class="anchor" href="#%e7%9b%b8%e5%85%b3%e6%a6%82%e5%bf%b5%e6%b8%a9%e5%ba%a6temperature">#</a>
</h2>
<ul>
<li>尽管温度本身并非一种 token 采样方法，但它显著影响采样过程，因此本篇纳入讨论。</li>
<li>温度参数允许我们调整 token 的概率分布。它作为 softmax 变换中的一个超参数（见下图；来源），在应用 softmax 前对 logits 进行缩放，从而控制预测的随机性。</li>
</ul>
<p><img src="/primers/ai/assets/token-sampling/T.jpg" alt="温度对 softmax 的影响" /></p>
<ul>
<li>例如在 TensorFlow 的 Magenta 项目中（LSTM 实现），温度参数控制 logits 在 softmax 前被缩放（或除以）的程度。</li>
</ul>
<h3 id="温度在-softmax-中的作用">
  温度在 Softmax 中的作用
  <a class="anchor" href="#%e6%b8%a9%e5%ba%a6%e5%9c%a8-softmax-%e4%b8%ad%e7%9a%84%e4%bd%9c%e7%94%a8">#</a>
</h3>
<ul>
<li>
<p>标准 softmax 引入温度超参数 $T$ 后的形式为：
$$
q_i = \frac{\exp(z_i/T)}{\sum_j \exp(z_j/T)}
$$
其中 $T$ 为温度（默认为 1）。</p>
</li>
<li>
<p>当 $T=1$，即直接对 logits 计算 softmax；<br>
若 $T=0.6$，则对 $\frac{\text{logits}}{0.6}$ 计算 softmax —— 此时数值被放大，softmax 结果更“尖锐”；<br>
→ 模型更<strong>自信</strong>（更少输入即可激活输出层），但也更<strong>保守</strong>（不太可能采样低概率候选）。</p>
</li>
</ul>
<h3 id="不同温度范围及其影响">
  不同温度范围及其影响
  <a class="anchor" href="#%e4%b8%8d%e5%90%8c%e6%b8%a9%e5%ba%a6%e8%8c%83%e5%9b%b4%e5%8f%8a%e5%85%b6%e5%bd%b1%e5%93%8d">#</a>
</h3>
<h4 id="低温t-approx-0005">
  低温（$T \approx 0.0$–$0.5$）
  <a class="anchor" href="#%e4%bd%8e%e6%b8%a9t-approx-0005">#</a>
</h4>
<ul>
<li><strong>特征</strong>：
<ul>
<li>强烈偏好高概率 token；</li>
<li>输出确定性强、随机性低；</li>
<li>文本常重复，多样性差。</li>
</ul>
</li>
<li><strong>适用场景</strong>：
<ul>
<li>需要高精度或高置信度的场景（例如生成事实性回答）。</li>
</ul>
</li>
<li><strong>局限性</strong>：
<ul>
<li>可能过于保守，陷入重复环（repetitive loops）。</li>
</ul>
</li>
</ul>
<h4 id="中温t-approx-0610">
  中温（$T \approx 0.6$–$1.0$）
  <a class="anchor" href="#%e4%b8%ad%e6%b8%a9t-approx-0610">#</a>
</h4>
<ul>
<li><strong>特征</strong>：
<ul>
<li>在多样性与连贯性之间取得平衡；</li>
<li>允许探索较低概率选项，但不显著损伤文本合理性。</li>
</ul>
</li>
<li><strong>适用场景</strong>：
<ul>
<li>生成类人语句、代码补全、音乐作曲等需“有创意但合理”的任务。</li>
</ul>
</li>
<li><strong>局限性</strong>：
<ul>
<li>仍会偏向高概率 token，抑制极低概率创意探索。</li>
</ul>
</li>
</ul>
<h4 id="高温t--10">
  高温（$T &gt; 1.0$）
  <a class="anchor" href="#%e9%ab%98%e6%b8%a9t--10">#</a>
</h4>
<ul>
<li><strong>特征</strong>：
<ul>
<li>生成更“平缓”的概率分布；</li>
<li>输出更随机、多样；更倾向低概率选项；</li>
<li>有助于跳出重复环，探索更广空间。</li>
</ul>
</li>
<li><strong>适用场景</strong>：
<ul>
<li>头脑风暴、高度创意内容生成（如艺术、故事、诗歌）。</li>
</ul>
</li>
<li><strong>局限性</strong>：
<ul>
<li>易出现逻辑错误或语义混乱；</li>
<li>采样到不合理 token 的风险增大。</li>
</ul>
</li>
</ul>
<h3 id="softmax-函数的深层理解引自维基百科">
  Softmax 函数的深层理解（引自维基百科）
  <a class="anchor" href="#softmax-%e5%87%bd%e6%95%b0%e7%9a%84%e6%b7%b1%e5%b1%82%e7%90%86%e8%a7%a3%e5%bc%95%e8%87%aa%e7%bb%b4%e5%9f%ba%e7%99%be%e7%a7%91">#</a>
</h3>
<blockquote>
<p>当温度 $\tau \to \infty$ 时，所有样本概率趋近相等；温度越低（$\tau \to 0^+$），预期奖励最高的样本概率趋近于 1。</p></blockquote>
<h3 id="温度影响总结">
  温度影响总结
  <a class="anchor" href="#%e6%b8%a9%e5%ba%a6%e5%bd%b1%e5%93%8d%e6%80%bb%e7%bb%93">#</a>
</h3>
<ul>
<li><strong>低温</strong> → 更自信、更保守 → 适合确定性任务；</li>
<li><strong>中温</strong> → 平衡随机性与连贯性 → 通用推荐区间；</li>
<li><strong>高温</strong> → 更富创意、更随机 → 适合探索性任务。</li>
<li>通过调节温度，可依任务需求灵活调整模型行为，极大增强 LLM 的适用性。</li>
</ul>
<hr>
<h2 id="贪心解码greedy-decoding">
  贪心解码（Greedy Decoding）
  <a class="anchor" href="#%e8%b4%aa%e5%bf%83%e8%a7%a3%e7%a0%81greedy-decoding">#</a>
</h2>
<ul>
<li>贪心解码在每一步都使用 <code>argmax</code> 选择<strong>当前概率最高</strong>的 token 作为输出。</li>
<li><strong>问题</strong>：它无法回溯修正之前生成的 token。<br>
举例：输入法语 “il a m’entarté”（他用派砸了我），若贪心解码已生成 “he hit a”，即使后续发现应为 “me”，也无法回头修改。</li>
<li>模型逐 token 生成序列，每步仅考虑当前最优——不评估该选择对未来步骤的影响。</li>
<li>解码通常持续至生成 <code>&lt;END&gt;</code> token 为止。例如：<br>
<code>&lt;START&gt;</code> he hit me with a pie <code>&lt;END&gt;</code>（来源）</li>
<li>优点：计算高效、实现简单；<br>
缺点：不保证全局最优输出序列。</li>
<li>改进方向：采用穷举搜索或束搜索（beam search）。</li>
</ul>
<p><img src="https://aman.ai/primers/ai/assets/token-sampling/2.png" alt="贪心解码示意图" /></p>
<hr>
<h2 id="穷举搜索解码exhaustive-search-decoding">
  穷举搜索解码（Exhaustive Search Decoding）
  <a class="anchor" href="#%e7%a9%b7%e4%b8%be%e6%90%9c%e7%b4%a2%e8%a7%a3%e7%a0%81exhaustive-search-decoding">#</a>
</h2>
<ul>
<li>顾名思义，穷举搜索考察<strong>所有可能的输出序列组合</strong>，并选出评分最高的那个。</li>
<li>在序列到序列任务（如神经机器翻译）中，这意味着生成所有可能的译文，再用评分函数评估其与目标的匹配度。</li>
<li><strong>问题</strong>：计算复杂度极高——候选数量随输出长度呈指数级增长。</li>
<li>时间复杂度为 $O(V^T)$，其中 $V$ 为词表大小，$T$ 为输出长度；实际中几乎不可行。</li>
<li>尽管理论上可得最优解，但因其高昂开销，极少用于真实场景。</li>
</ul>
<hr>
<h2 id="束搜索beam-search">
  束搜索（Beam Search）
  <a class="anchor" href="#%e6%9d%9f%e6%90%9c%e7%b4%a2beam-search">#</a>
</h2>
<ul>
<li>束搜索是机器翻译等任务中常用的搜索算法，用于高效生成<strong>最可能的词序列</strong>。</li>
<li>核心思想：在每步解码时，仅保留 $k$ 个最高分的<strong>部分候选序列</strong>（partial hypotheses），$k$ 即为<strong>束宽（beam size）</strong>，通常取 5–10。</li>
<li>具体流程（见下图，束宽=2）：
<ul>
<li>每步计算若干候选项及其累积得分（通常为对数概率之和）；</li>
<li>保留 top-$k$ 路径继续扩展；</li>
<li>后续通过回溯获得完整输出。</li>
</ul>
</li>
</ul>
<p><img src="https://aman.ai/primers/ai/assets/token-sampling/1.png" alt="束搜索示意图" /></p>
<ul>
<li>不同候选可能在不同时间步生成 <code>&lt;END&gt;</code>：
<ul>
<li>一旦某候选产出 <code>&lt;END&gt;</code>，视为完成，暂存；</li>
<li>继续扩展其余候选，直至：
<ul>
<li>达到预设最大长度 $T$，或</li>
<li>已获得足够多（如 $n$ 个）完成候选。</li>
</ul>
</li>
</ul>
</li>
<li><strong>得分归一化问题</strong>：较长序列通常累积得分更低（因每步概率 &lt;1，连乘/求和后更小）→ 需按长度归一化（如使用平均对数概率）后再比较。</li>
<li>注意：束搜索<strong>不保证全局最优</strong>，但远优于穷举，兼顾质量与效率。<br>
详见：D2L.ai《动手学深度学习》— 束搜索章节。</li>
</ul>
<hr>
<h2 id="约束束搜索constrained-beam-search">
  约束束搜索（Constrained Beam Search）
  <a class="anchor" href="#%e7%ba%a6%e6%9d%9f%e6%9d%9f%e6%90%9c%e7%b4%a2constrained-beam-search">#</a>
</h2>
<ul>
<li>适用场景：需<strong>强制输出中包含特定词/短语</strong>（如机器翻译中必须包含某术语）。</li>
<li>基本思想：在束搜索过程中<strong>加入硬性约束条件</strong>，仅保留满足约束的候选路径。</li>
<li>实现方式：
<ul>
<li>修改评分函数，或</li>
<li>在每步生成后剔除违反约束的候选，</li>
<li>或引入惩罚项降低违规路径得分，</li>
<li>或用独立模块动态反馈约束满足情况。</li>
</ul>
</li>
<li>示例：生成句子时需包含短语 “is fast”；<br>
除常规高概率词（如 “dog”、“nice”）外，<strong>强制加入 “is”</strong> 以推进约束达成（见下图）。</li>
</ul>
<p><img src="https://aman.ai/primers/ai/assets/token-sampling/5.png" alt="约束束搜索 Step 1" /></p>
<h3 id="银行机制banking">
  银行机制（Banking）
  <a class="anchor" href="#%e9%93%b6%e8%a1%8c%e6%9c%ba%e5%88%b6banking">#</a>
</h3>
<ul>
<li>强制插入 token 是否会导致荒谬输出？<strong>银行机制</strong>可解决此问题：
<ul>
<li>将候选按<strong>满足约束的程度</strong>分为多个“银行”（Bank）；</li>
<li>Bank 2：已满足全部约束；<br>
Bank 1：接近满足；<br>
Bank 0：尚未开始满足。</li>
<li>采用<strong>轮询选择</strong>（round-robin）：依次从 Bank 2、1、0 中各选最高分候选，再从 Bank 2、1、0 选次高……<br>
（例：若用 3 束，则选出：<code>[&quot;The is fast&quot;, &quot;The dog is&quot;, &quot;The dog and&quot;]</code>）</li>
</ul>
</li>
</ul>
<p><img src="https://aman.ai/primers/ai/assets/token-sampling/6.png" alt="银行机制示意图" /></p>
<ul>
<li>这样既保证约束逐步满足，又维持高概率合理序列的竞争力。</li>
<li>下图为全流程结果：</li>
</ul>
<p><img src="https://aman.ai/primers/ai/assets/token-sampling/7.png" alt="约束束搜索全流程" /></p>
<hr>
<h2 id="top-k-采样">
  Top-$k$ 采样
  <a class="anchor" href="#top-k-%e9%87%87%e6%a0%b7">#</a>
</h2>
<ul>
<li>核心思想：每步从<strong>概率最高的 $k$ 个 token</strong>中采样，而非仅选最大者。</li>
<li>采样方式可为：
<ul>
<li><strong>均匀采样</strong>：top-$k$ 内各 token 等概率 → 提升多样性；</li>
<li><strong>按原概率采样</strong>：保持分布权重 → 提升连贯性。</li>
</ul>
</li>
<li>$k=1$ 时退化为贪心解码。</li>
<li>$k$ 越小 → 选择越窄 → 多样性↓、控制性↑；<br>
$k$ 越大 → 选择越宽 → 多样性↑、控制性↓。</li>
<li>适用于需平衡多样性与可控性的任务（如对话生成）。</li>
</ul>
<p><img src="https://aman.ai/primers/ai/assets/token-sampling/3.png" alt="Top-$k$ 示意图（$k=3$）" /></p>
<hr>
<h2 id="top-p核心采样--nucleus-sampling">
  Top-$p$（核心采样 / Nucleus Sampling）
  <a class="anchor" href="#top-p%e6%a0%b8%e5%bf%83%e9%87%87%e6%a0%b7--nucleus-sampling">#</a>
</h2>
<ul>
<li>动机：Top-$k$ 中 $k$ 难以选取 → 需动态调整候选集大小。</li>
<li>Top-$p$ 方法：
<ul>
<li>按概率降序排列所有 token；</li>
<li>取<strong>最小的前缀子集</strong>，使其<strong>累积概率 ≥ $p$</strong>（如 $p=0.9$）；</li>
<li>重新归一化该子集概率（使其和为 1）；</li>
<li>从中按新概率采样。</li>
</ul>
</li>
<li>与 Top-$k$ 关键区别：<br>
Top-$k$ 固定数量，Top-$p$ 固定<strong>概率质量</strong>；<br>
后者可根据分布“自适应”调整候选数。</li>
</ul>
<p><img src="https://aman.ai/primers/ai/assets/token-sampling/nucleus.jpg" alt="核心采样示意图" /></p>
<p><img src="https://aman.ai/primers/ai/assets/token-sampling/4.png" alt="Top-$p=0.15$ 示例" /></p>
<h3 id="实用价值">
  实用价值
  <a class="anchor" href="#%e5%ae%9e%e7%94%a8%e4%bb%b7%e5%80%bc">#</a>
</h3>
<ul>
<li>适合需精细调控多样性与流畅度的任务（如语言建模、摘要生成）；</li>
<li>实际中 $p$ 常设为 0.75 左右，以过滤长尾低概率噪声 token；</li>
<li>特殊情形：
<ul>
<li>若某 token 概率 &gt; $p$，则必然被选（退化为贪心）；</li>
<li>若概率分布平坦，则候选集变大 → 更富创意。</li>
</ul>
</li>
<li>注意：Top-$k$ 与 Top-$p$ 可<strong>联用</strong>（先取 top-$k$，再在其中做 top-$p$），但 $p$ 作用于 $k$ 之后。</li>
</ul>
<h3 id="与温度参数的关系">
  与温度参数的关系
  <a class="anchor" href="#%e4%b8%8e%e6%b8%a9%e5%ba%a6%e5%8f%82%e6%95%b0%e7%9a%84%e5%85%b3%e7%b3%bb">#</a>
</h3>
<ul>
<li>OpenAI GPT-3 API 提示：<strong>温度与 top-$p$ 互斥</strong>（见下图）；<br>
二者是<strong>不同且互斥</strong>的随机性控制机制。</li>
</ul>
<p><img src="https://aman.ai/primers/ai/assets/token-sampling/API.jpg" alt="GPT-3 API 参数说明" /></p>
<hr>
<h2 id="贪心-vs-top-k-与-top-p">
  贪心 vs. Top-$k$ 与 Top-$p$
  <a class="anchor" href="#%e8%b4%aa%e5%bf%83-vs-top-k-%e4%b8%8e-top-p">#</a>
</h2>
<table>
  <thead>
      <tr>
          <th>对比维度</th>
          <th>贪心解码</th>
          <th>Top-$k$/Top-$p$</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>确定性</strong></td>
          <td>确定性（总是选最高概率）</td>
          <td>随机性（引入采样）</td>
      </tr>
      <tr>
          <td><strong>采样方式</strong></td>
          <td>无（直接 argmax）</td>
          <td>可均匀或按概率</td>
      </tr>
      <tr>
          <td><strong>文本风格倾向</strong></td>
          <td>安全、保守、缺乏创意</td>
          <td>更新颖、多样，但可能不连贯</td>
      </tr>
  </tbody>
</table>
<hr>
<h2 id="min-p-采样">
  Min-$p$ 采样
  <a class="anchor" href="#min-p-%e9%87%87%e6%a0%b7">#</a>
</h2>
<ul>
<li>Min-$p$ 是 Hugging Face Transformers 库引入的<strong>新型解码策略</strong>，旨在改进 Top-$k$ 与 Top-$p$ 的不足。</li>
</ul>
<h3 id="现有方法局限回顾">
  现有方法局限回顾
  <a class="anchor" href="#%e7%8e%b0%e6%9c%89%e6%96%b9%e6%b3%95%e5%b1%80%e9%99%90%e5%9b%9e%e9%a1%be">#</a>
</h3>
<ul>
<li><strong>Top-$k$</strong>：
<ul>
<li>固定截断 → 可能丢弃高质量低频 token → 降低词汇多样性。</li>
</ul>
</li>
<li><strong>Top-$p$</strong>：
<ul>
<li>包含极低概率 token → 可能破坏连贯性。</li>
</ul>
</li>
</ul>
<h3 id="min-p-核心思想">
  Min-$p$ 核心思想
  <a class="anchor" href="#min-p-%e6%a0%b8%e5%bf%83%e6%80%9d%e6%83%b3">#</a>
</h3>
<ul>
<li>引入<strong>动态阈值</strong>：<br>
设定最小概率因子 <code>min_p</code>（如 0.05），<br>
计算阈值 = <code>min_p × 最高概率 token 的概率</code>；<br>
→ 仅保留概率 ≥ 该阈值的 token。</li>
<li>优势：
<ul>
<li>当存在<strong>绝对主导 token</strong>时 → 严格过滤，保证聚焦与连贯；</li>
<li>当概率分布<strong>较平坦</strong>时 → 宽松保留，支持创意发散。</li>
</ul>
</li>
<li><strong>推荐配置</strong>（尤其适合创意生成）：
<ul>
<li><code>min_p ∈ [0.05, 0.1]</code></li>
<li>配合<strong>高温</strong>（$T &gt; 1$）→ 充分激发创造力；</li>
<li>可<strong>减少甚至无需</strong>使用“重复惩罚（repetition penalty）”等补丁技巧。</li>
</ul>
</li>
</ul>
<p><img src="https://aman.ai/primers/ai/assets/token-sampling/min-p.jpeg" alt="Min-$p$ 示意图" /></p>
<ul>
<li>简言之，Min-$p$ 通过<strong>自适应概率截断</strong>，在多样性与连贯性间取得更优平衡，有望成为新一代解码标准。</li>
</ul>
<hr>
<h2 id="参考文献">
  参考文献
  <a class="anchor" href="#%e5%8f%82%e8%80%83%e6%96%87%e7%8c%ae">#</a>
</h2>
<ul>
<li>Hinton, Geoffrey, Oriol Vinyals, and Jeff Dean. “Distilling the knowledge in a neural network.” <em>arXiv preprint arXiv:1503.02531</em> (2015).</li>
<li>What is Temperature in LSTM (and neural networks generally)?</li>
<li>Stanford CS224n</li>
<li>Ketan Doshi, <em>Foundations of NLP Explained Visually</em>: Beam Search, How it Works</li>
<li>Cohere: Top-k and Top-p</li>
<li>HuggingFace: Constrained Beam Search</li>
</ul>
<hr>
<p>如需 PDF 或 Markdown 格式文档，我可为您整理输出。</p>
<h1 id="参考">
  参考
  <a class="anchor" href="#%e5%8f%82%e8%80%83">#</a>
</h1>
<p><a href="https://aman.ai/primers/ai/token-sampling/">Token Sampling Methods</a>   qwen 翻译</p>
<h1 id="总结kimi">
  总结（Kimi）
  <a class="anchor" href="#%e6%80%bb%e7%bb%93kimi">#</a>
</h1>
<table>
  <thead>
      <tr>
          <th>方法</th>
          <th>是否随机</th>
          <th>控制方式</th>
          <th>优点</th>
          <th>缺点</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Greedy</td>
          <td>否</td>
          <td>argmax</td>
          <td>快速、确定</td>
          <td>易重复、局部最优</td>
      </tr>
      <tr>
          <td>Beam Search</td>
          <td>否</td>
          <td>保留 top-k 序列</td>
          <td>比贪心更优</td>
          <td>不保证全局最优</td>
      </tr>
      <tr>
          <td>Top-k</td>
          <td>是</td>
          <td>固定数量</td>
          <td>简单有效</td>
          <td>可能包含低质量词</td>
      </tr>
      <tr>
          <td>Top-p</td>
          <td>是</td>
          <td>动态累积概率</td>
          <td>更灵活</td>
          <td>可能引入低概率词</td>
      </tr>
      <tr>
          <td>Min-p</td>
          <td>是</td>
          <td>动态阈值</td>
          <td>高温度下更稳定</td>
          <td>新方法，需调参</td>
      </tr>
  </tbody>
</table>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">





</div>



  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#token-采样方法token-sampling-methods">Token 采样方法（Token Sampling Methods）</a>
      <ul>
        <li><a href="#概述">概述</a></li>
        <li><a href="#背景">背景</a>
          <ul>
            <li><a href="#自回归解码autoregressive-decoding">自回归解码（Autoregressive Decoding）</a></li>
            <li><a href="#token-概率">Token 概率</a></li>
            <li><a href="#logits-与-softmax">Logits 与 Softmax</a></li>
          </ul>
        </li>
        <li><a href="#相关概念温度temperature">相关概念：温度（Temperature）</a>
          <ul>
            <li><a href="#温度在-softmax-中的作用">温度在 Softmax 中的作用</a></li>
            <li><a href="#不同温度范围及其影响">不同温度范围及其影响</a></li>
            <li><a href="#softmax-函数的深层理解引自维基百科">Softmax 函数的深层理解（引自维基百科）</a></li>
            <li><a href="#温度影响总结">温度影响总结</a></li>
          </ul>
        </li>
        <li><a href="#贪心解码greedy-decoding">贪心解码（Greedy Decoding）</a></li>
        <li><a href="#穷举搜索解码exhaustive-search-decoding">穷举搜索解码（Exhaustive Search Decoding）</a></li>
        <li><a href="#束搜索beam-search">束搜索（Beam Search）</a></li>
        <li><a href="#约束束搜索constrained-beam-search">约束束搜索（Constrained Beam Search）</a>
          <ul>
            <li><a href="#银行机制banking">银行机制（Banking）</a></li>
          </ul>
        </li>
        <li><a href="#top-k-采样">Top-$k$ 采样</a></li>
        <li><a href="#top-p核心采样--nucleus-sampling">Top-$p$（核心采样 / Nucleus Sampling）</a>
          <ul>
            <li><a href="#实用价值">实用价值</a></li>
            <li><a href="#与温度参数的关系">与温度参数的关系</a></li>
          </ul>
        </li>
        <li><a href="#贪心-vs-top-k-与-top-p">贪心 vs. Top-$k$ 与 Top-$p$</a></li>
        <li><a href="#min-p-采样">Min-$p$ 采样</a>
          <ul>
            <li><a href="#现有方法局限回顾">现有方法局限回顾</a></li>
            <li><a href="#min-p-核心思想">Min-$p$ 核心思想</a></li>
          </ul>
        </li>
        <li><a href="#参考文献">参考文献</a></li>
      </ul>
    </li>
    <li><a href="#参考">参考</a></li>
    <li><a href="#总结kimi">总结（Kimi）</a></li>
  </ul>
</nav>


 
      </div>
    </aside>
    
  </main>

  
</body>
</html>












